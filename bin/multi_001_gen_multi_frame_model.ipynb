{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.HIGHEST_PROTOCOL = 4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import func_proc_filepath as mFILE\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, GRU, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.utils import Sequence\n",
    "from keras import backend as K\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Callback(Callback):\n",
    "    def __init__(self, model, X_val, y_val, path):\n",
    "        self.model = model\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        self.path = path\n",
    "        self.best_score = -1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pred = self.model.predict(self.X_val)\n",
    "        f1_val = f1_score(self.y_val, np.round(pred), average='macro')\n",
    "        acc_val = accuracy_score(self.y_val, np.round(pred))\n",
    "        score = f1_val*0.67 + acc_val*0.33\n",
    "        log = \"Score = {0}, F1 = {1}, ACC = {2}\".format(score, f1_val, acc_val)\n",
    "        print(log)\n",
    "        # 以下チェックポイントなど必要なら書く\n",
    "        if score > self.best_score:\n",
    "            self.best_score = score\n",
    "            self.model.save(self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y: after one hot encoding\n",
    "def create_gru_model(np_train_x, np_train_y, np_val_x, np_val_y, n_class, n_units=64, drop=0.5, lr=1e-4, \n",
    "                     batch=128, model_path=\"\"):\n",
    "    # ** fix random seed **\n",
    "    FIX_SEED = 49\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(FIX_SEED)\n",
    "    random.seed(FIX_SEED)\n",
    "    session_conf = tf.compat.v1.ConfigProto()\n",
    "    tf.compat.v1.set_random_seed(FIX_SEED)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    # *********************\n",
    "    \n",
    "    #*********************************************    \n",
    "    # モデルの定義\n",
    "    model = Sequential()\n",
    "    \n",
    "    n_rnn = np_train_x.shape[1]\n",
    "    n_feat = np_train_x.shape[2]\n",
    "    adam = Adam(lr=lr)\n",
    "    \n",
    "    #model.add(Bidirectional(GRU(units=n_units, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=False)))\n",
    "    #model.add(GRU(units=128, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=True))\n",
    "    #model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(GRU(units=n_units, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=False))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=[\"accuracy\", f1])\n",
    "\n",
    "    #model_path = dir_out + \"\\\\model_multi_image\" + footer + \".h5\"\n",
    "    #cb_early = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "    cb_early = EarlyStopping(monitor='val_f1', patience=8, verbose=0, mode='max')\n",
    "    \n",
    "    model.fit(np_train_x, np_train_y,\n",
    "              epochs=30,\n",
    "              batch_size=batch,\n",
    "              validation_data=(np_val_x, np_val_y),\n",
    "              callbacks=[F1Callback(model, np_val_x, np_val_y, model_path), cb_early])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # bestモデルを読み込んで、重みやオプティマイザーを含むモデル全体を再作成\n",
    "    new_model = keras.models.load_model(model_path, custom_objects={'f1':f1})\n",
    "    \n",
    "    pred_nn = new_model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    \n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    del model\n",
    "    del new_model\n",
    "    \n",
    "    return scores_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predict data\n",
    "def eval_pred_each_class(np_true, np_pred, num_class):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    # calc\n",
    "    for i in range(num_class):\n",
    "        # i以外を0、iを1に置き換える\n",
    "        y_true_i = np.where(np_true == i, 1, 0)\n",
    "        y_pred_i = np.where(np_pred == i, 1, 0)\n",
    "\n",
    "        recall_i = recall_score(y_true_i, y_pred_i, average='binary')\n",
    "        precision_i = precision_score(y_true_i, y_pred_i, average='binary')\n",
    "        f1_i = f1_score(y_true_i, y_pred_i, average='binary')\n",
    "        acc_i = accuracy_score(y_true_i, y_pred_i)\n",
    "\n",
    "        df_reslut = pd.DataFrame({\"class\":[i], \"recall\":[recall_i], \"precision\":[precision_i], \n",
    "                                 \"f1\":[f1_i], \"accuracy\":[acc_i]})\n",
    "        #result_i = [recall_i, precision_i, f1_i, acc_i]\n",
    "\n",
    "        result.append(df_reslut)\n",
    "\n",
    "    df_out = pd.concat([x for x in result], axis=0, ignore_index=True)\n",
    "    f1_all = df_out.loc[:, \"f1\"].mean()\n",
    "    recall_all = df_out.loc[:, \"recall\"].mean()\n",
    "    precision_all = df_out.loc[:, \"precision\"].mean()\n",
    "    accuracy_all = df_out.loc[:, \"accuracy\"].mean()\n",
    "    df_all = pd.DataFrame({\"class\":[\"all\"], \"recall\":[recall_all], \"precision\":[precision_all], \n",
    "                                 \"f1\":[f1_all], \"accuracy\":[accuracy_all]})\n",
    "    df_out = pd.concat([df_out, df_all], axis=0, ignore_index=True)\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_train_balance(np_x, np_y):\n",
    "    \n",
    "    ny = np_y.ravel()\n",
    "    \n",
    "    np_x0 = np_x[ny==0,:,:]\n",
    "    np_x0 = np_x0[::2,:,:]\n",
    "    \n",
    "    np_y0 = ny[ny==0]\n",
    "    np_y0 = np_y0[::2]\n",
    "    \n",
    "    np_x1 = np_x[ny==1,:,:]\n",
    "    np_x1 = np.append(np_x1, np_x1, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x1, axis=0)\n",
    "    np_x1 = None\n",
    "    \n",
    "    \n",
    "    np_y1 = ny[ny==1]\n",
    "    np_y1 = np.append(np_y1, np_y1)\n",
    "    np_y0 =  np.append(np_y0, np_y1)\n",
    "    np_y1 = None\n",
    "    \n",
    "    np_x2 = np_x[ny==2,:,:]\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x2, axis=0)\n",
    "    np_x2 = None\n",
    "    \n",
    "    np_y2 = ny[ny==2]\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y0 =  np.append(np_y0, np_y2)\n",
    "    np_y2 = None\n",
    "    \n",
    "    np_x3 = np_x[ny==3,:,:]\n",
    "    np_x3 = np.append(np_x3, np_x3, axis=0)\n",
    "    np_x3 = np.append(np_x3, np_x3, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x3, axis=0)\n",
    "    np_x3 = None\n",
    "    \n",
    "    np_y3 = ny[ny==3]\n",
    "    np_y3 = np.append(np_y3, np_y3)\n",
    "    np_y3 = np.append(np_y3, np_y3)\n",
    "    np_y0 =  np.append(np_y0, np_y3)\n",
    "    np_y3 = None\n",
    "    \n",
    "    np_x4 = np_x[ny==4,:,:]\n",
    "    np_x4 = np_x4[::3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x4, axis=0)\n",
    "    np_x4 = None\n",
    "    \n",
    "    np_y4 = ny[ny==4]\n",
    "    np_y4 = np_y4[::3]\n",
    "    np_y0 =  np.append(np_y0, np_y4)\n",
    "    np_y4 = None\n",
    "    \n",
    "    np_x5 = np_x[ny==5,:,:]\n",
    "    np_x5 = np_x5[::2,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x5, axis=0)\n",
    "    np_x5 = None\n",
    "    \n",
    "    np_y5 = ny[ny==5]\n",
    "    np_y5 = np_y5[::2]\n",
    "    np_y0 =  np.append(np_y0, np_y5)\n",
    "    np_y5 = None\n",
    "    \n",
    "    np_x6 = np_x[ny==6,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x6, axis=0)\n",
    "    np_x6 = None\n",
    "    \n",
    "    np_y6 = ny[ny==6]\n",
    "    np_y0 =  np.append(np_y0, np_y6)\n",
    "    np_y6 = None\n",
    "    \n",
    "    np_x = None\n",
    "    np_y = None\n",
    "    ny = None\n",
    "    \n",
    "    p =np.random.RandomState(seed=49).permutation(len(np_x0))\n",
    "    np_x0 = np_x0[p]\n",
    "    np_y0 = np_y0[p]\n",
    "    \n",
    "    \n",
    "    return np_x0, np_y0.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_val_balance(np_x, np_y): #::7, 1, *2, 1, ::4, ::3, ::2\n",
    "    \n",
    "    ny = np_y.ravel()\n",
    "    \n",
    "    np_x0 = np_x[ny==0,:,:]\n",
    "    np_x0 = np_x0[::3,:,:]\n",
    "    \n",
    "    np_y0 = ny[ny==0]\n",
    "    np_y0 = np_y0[::3]\n",
    "    \n",
    "    np_x1 = np_x[ny==1,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x1, axis=0)\n",
    "    np_x1 = None\n",
    "    \n",
    "    \n",
    "    np_y1 = ny[ny==1]\n",
    "    np_y0 =  np.append(np_y0, np_y1)\n",
    "    np_y1 = None\n",
    "    \n",
    "    np_x2 = np_x[ny==2,:,:]\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x2, axis=0)\n",
    "    np_x2 = None\n",
    "    \n",
    "    np_y2 = ny[ny==2]\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y0 =  np.append(np_y0, np_y2)\n",
    "    np_y2 = None\n",
    "    \n",
    "    np_x3 = np_x[ny==3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x3, axis=0)\n",
    "    np_x3 = None\n",
    "    \n",
    "    np_y3 = ny[ny==3]\n",
    "    np_y0 =  np.append(np_y0, np_y3)\n",
    "    np_y3 = None\n",
    "    \n",
    "    np_x4 = np_x[ny==4,:,:]\n",
    "    np_x4 = np_x4[::4,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x4, axis=0)\n",
    "    np_x4 = None\n",
    "    \n",
    "    np_y4 = ny[ny==4]\n",
    "    np_y4 = np_y4[::4]\n",
    "    np_y0 =  np.append(np_y0, np_y4)\n",
    "    np_y4 = None\n",
    "    \n",
    "    np_x5 = np_x[ny==5,:,:]\n",
    "    np_x5 = np_x5[::3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x5, axis=0)\n",
    "    np_x5 = None\n",
    "    \n",
    "    np_y5 = ny[ny==5]\n",
    "    np_y5 = np_y5[::3]\n",
    "    np_y0 =  np.append(np_y0, np_y5)\n",
    "    np_y5 = None\n",
    "    \n",
    "    np_x6 = np_x[ny==6,:,:]\n",
    "    np_x6 = np_x6[::2,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x6, axis=0)\n",
    "    np_x6 = None\n",
    "    \n",
    "    np_y6 = ny[ny==6]\n",
    "    np_y6 = np_y6[::2]\n",
    "    np_y0 =  np.append(np_y0, np_y6)\n",
    "    np_y6 = None\n",
    "    \n",
    "    np_x = None\n",
    "    np_y = None\n",
    "    ny = None\n",
    "    \n",
    "    #p = np.random.permutation(len(np_x0))\n",
    "    p =np.random.RandomState(seed=49).permutation(len(np_x0))\n",
    "    np_x0 = np_x0[p]\n",
    "    np_y0 = np_y0[p]\n",
    "    \n",
    "    \n",
    "    return np_x0, np_y0.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_read_separate2(file_list, dir_data, dir_audio, pre_model, transformer, balance=0, sep_num=5, ignore_feat=False):\n",
    "    \n",
    "    step = -(-len(file_list) // sep_num)\n",
    "    \n",
    "    np_x_out_list = []\n",
    "    np_y_out_list = []\n",
    "    \n",
    "    for s in range(sep_num):\n",
    "        \n",
    "        start = step*s\n",
    "        stop = step*(s+1)\n",
    "        if stop>len(file_list):\n",
    "            stop = len(file_list)\n",
    "            \n",
    "        file_list_sep = file_list[start:stop]\n",
    "        \n",
    "        np_x_list = []\n",
    "        np_y_list = []\n",
    "\n",
    "        for i in tqdm(range(len(file_list_sep))):\n",
    "            name = os.path.splitext(os.path.basename(file_list_sep[i]))[0]\n",
    "\n",
    "            df_label = pd.read_csv(file_list_sep[i])\n",
    "            #display(df_label)\n",
    "            df_label = df_label.drop([\"Anger\",\"Disgust\",\"Fear\",\"Happiness\",\"Sadness\",\"Surprise\"],axis=1)\n",
    "            df_label.columns = [\"expr\"]\n",
    "            #df_label[\"frame\"] = df_label.index\n",
    "            df_label.index.name = \"frame\"\n",
    "\n",
    "            df_data = pd.read_hdf(dir_data + \"\\\\\" + name + \".h5\")\n",
    "            df_data.set_index(\"frame\", drop=True, inplace=True)\n",
    "            #display(df_data)\n",
    "            df_audio = pd.read_hdf(dir_audio + \"\\\\\" + name + \".h5\")\n",
    "            df_audio.set_index(\"frame\", drop=True, inplace=True)\n",
    "\n",
    "            #df_merge = pd.merge(df_label, df_data, on=\"frame\", how=\"outer\")\n",
    "            #df_merge = pd.merge(df_merge, df_audio, on=\"frame\", how=\"outer\")\n",
    "            df_merge = df_label.join([df_data, df_audio], how=\"outer\")\n",
    "            # interpolate 30 frame back\n",
    "            df_merge.interpolate(method=\"index\", limit=30, limit_direction='backward', inplace=True)\n",
    "            #df_merge.fillna(0, inplace=True)\n",
    "            #df_merge = df_merge.loc[df_merge.loc[:,\"expr\"]>=0,:]\n",
    "            #display(df_merge)\n",
    "\n",
    "            np_x = df_merge.loc[:, df_merge.columns.str.contains(\"AU|pose_R|gaze|vgg-\")].values\n",
    "            np_y = df_merge.loc[:, df_merge.columns.str.contains(\"expr\")].values\n",
    "            pre_x = pre_model.predict(np_x)\n",
    "            \"\"\"\n",
    "            # normalize by single subject\n",
    "            np_mean_sub = np.nanmean(pre_x, axis=0)\n",
    "            np_std_sub = np.nanstd(pre_x, axis=0, ddof=1)\n",
    "            np_x_sub = (pre_x - np_mean_sub)/np_std_sub\n",
    "            df_sub = pd.DataFrame(np_x_sub)\n",
    "            df_sub.replace(np.inf, 9999, inplace=True)\n",
    "            df_sub.fillna(0, inplace=True)\n",
    "            df_sub.mask(df_sub > 5, 5, inplace=True)\n",
    "            df_sub.columns = [\"sub-\" + str(n) for n in df_sub.columns.values]\n",
    "            # ***************\n",
    "            \"\"\"\n",
    "            df = pd.DataFrame(pre_x)\n",
    "            #df = pd.concat([df, df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "            df = pd.concat([df, df_merge.loc[:, df_merge.columns.str.contains(\"audio\")],\n",
    "                            df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "            \n",
    "            batch_length = 90\n",
    "            feat_size = 600\n",
    "            np_x_tmp_list = []\n",
    "            np_y_tmp_list = []\n",
    "            for i in range(len(df)):\n",
    "                label = df.at[i, \"expr\"]\n",
    "                if label >= 0:         \n",
    "                    if ignore_feat==True:\n",
    "                        np_tmp = np.zeros((batch_length, feat_size))\n",
    "                        #np_tmp2 = df_feat.iloc[i-batch_length+1:i+1, :].values\n",
    "                        if i-batch_length+1 < 0:\n",
    "                            np_tmp = np.zeros((batch_length-i-1, feat_size))\n",
    "                            np_tmp2 = df.iloc[0:i+1, 0:feat_size].values\n",
    "                            np_tmp = np.append(np_tmp, np_tmp2, axis=0)\n",
    "                        else:\n",
    "                            np_tmp = df.iloc[i-batch_length+1:i+1, 0:feat_size].values\n",
    "\n",
    "                        np_tmp = np_tmp.astype(np.float32)\n",
    "                        #np_tmp = np_tmp[::5,:]\n",
    "                        np_tmp = np_tmp[np.newaxis, ::6, :]\n",
    "                        np_tmp = np.nan_to_num(np_tmp)\n",
    "\n",
    "                        np_x_tmp_list.append(np_tmp)\n",
    "                        np_y_tmp_list.append(label)\n",
    "                    else:\n",
    "                        if df.at[i,0]!=np.nan:\n",
    "                            np_tmp = np.zeros((batch_length, feat_size))\n",
    "                            #np_tmp2 = df_feat.iloc[i-batch_length+1:i+1, :].values\n",
    "                            if i-batch_length+1 < 0:\n",
    "                                np_tmp = np.zeros((batch_length-i-1, feat_size))\n",
    "                                np_tmp2 = df.iloc[0:i+1, 0:feat_size].values\n",
    "                                np_tmp = np.append(np_tmp, np_tmp2, axis=0)\n",
    "                            else:\n",
    "                                np_tmp = df.iloc[i-batch_length+1:i+1, 0:feat_size].values\n",
    "\n",
    "                            np_tmp = np_tmp.astype(np.float32)\n",
    "                            #np_tmp = np_tmp[::5,:]\n",
    "                            np_tmp = np_tmp[np.newaxis, ::6, :]\n",
    "                            np_tmp = np.nan_to_num(np_tmp)\n",
    "\n",
    "                            np_x_tmp_list.append(np_tmp)\n",
    "                            np_y_tmp_list.append(label)\n",
    "\n",
    "            if len(np_x_tmp_list) > 0:\n",
    "                np_x_tmp = np.concatenate([x for x in np_x_tmp_list], 0)\n",
    "                np_y_tmp = np.array(np_y_tmp_list)\n",
    "                np_x_list.append(np_x_tmp)\n",
    "                np_y_list.append(np_y_tmp)\n",
    "\n",
    "        # finish\n",
    "        np_data_x = np.concatenate([x for x in np_x_list], 0)\n",
    "        np_data_y = np.concatenate([x for x in np_y_list], 0).reshape(-1,1)\n",
    "        #np_data_y = np.concatenate([x for x in np_y_list], 0)\n",
    "\n",
    "        if balance == 1:\n",
    "            # balance and shuffle\n",
    "            np_data_x, np_data_y = np_train_balance(np_data_x, np_data_y)\n",
    "        elif balance == 2:\n",
    "            # balance and shuffle\n",
    "            np_data_x, np_data_y = np_val_balance(np_data_x, np_data_y)\n",
    "        \n",
    "        np_x_out_list.append(np_data_x)\n",
    "        np_y_out_list.append(np_data_y)\n",
    "        \n",
    "    np_data_x = np.concatenate([x for x in np_x_out_list], 0)\n",
    "    np_data_y = np.concatenate([x for x in np_y_out_list], 0).reshape(-1,1) \n",
    "        \n",
    "    np_data_y = transformer.transform(np_data_y).toarray()\n",
    "    \n",
    "    return np_data_x, np_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # root folder\n",
    "    dir_root = str(Path(Path().resolve()).parent)\n",
    "\n",
    "    # input: folder path including original images\n",
    "    dir_data = dir_root + \"\\\\dataset\\\\aff2_images\\\\dataset\"\n",
    "    dir_audio = dir_root + \"\\\\dataset\\\\aff2_audio\\\\dataset\"\n",
    "\n",
    "    # input: expr labels\n",
    "    dir_label_train = dir_root + \"\\\\src\\\\annotations\\\\EXPR_Set\\\\Train_Set\"\n",
    "    dir_label_val = dir_root + \"\\\\src\\\\annotations\\\\EXPR_Set\\\\Validation_Set\"\n",
    "    \n",
    "    dir_model = dir_root + \"\\\\model_expr\\\\model_image\"\n",
    "    \n",
    "    # output: folder path\n",
    "    dir_out = dir_root + \"\\\\model_expr\\\\model_mix\"\n",
    "    if os.path.isdir(dir_out) == False:\n",
    "        os.makedirs(dir_out)\n",
    "    \n",
    "    model_path_base = \"model_modal_multi\"\n",
    "    model_path_base_pre = \"model_image_single_pseudo\"\n",
    "    \n",
    "    # pre_model\n",
    "    file_pre_model = dir_model + \"\\\\\" + model_path_base_pre + \"_best.h5\"\n",
    "    base_model = keras.models.load_model(file_pre_model, custom_objects={'f1':f1})\n",
    "    layer_name = 'vgg_au'\n",
    "    pre_model = Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)  \n",
    "    # *****\n",
    "    \n",
    "    train_list = mFILE.search_files(dir_label_train, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)    \n",
    "    val_list = mFILE.search_files(dir_label_val, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)\n",
    "    \n",
    "    dummy = [[0],[1],[2],[3],[4],[5],[6]]\n",
    "    transformer = OneHotEncoder().fit(dummy)\n",
    "    #np_train_y_hot = transformer.transform(np_train_y).toarray()\n",
    "    #np_val_y_hot = transformer.transform(np_val_y).toarray()\n",
    "    \n",
    "    len_train = len(train_list)\n",
    "    len_val = len(val_list)\n",
    "    #train_list = train_list[0:20]\n",
    "    #val_list = val_list[0:10]\n",
    "    \n",
    "    np_train_x, np_train_y = data_read_separate2(train_list, dir_data, dir_audio,\n",
    "                                            pre_model, transformer, balance=1, sep_num=5, ignore_feat=False)\n",
    "    \n",
    "    print(np_train_x.shape)\n",
    "    print(np_train_y.shape)\n",
    "    print(np_train_x.nbytes, np_train_y.nbytes)\n",
    "    \n",
    "    np_val_x, np_val_y = data_read_separate2(val_list, dir_data, dir_audio,\n",
    "                                            pre_model, transformer, balance=2, sep_num=5, ignore_feat=False)\n",
    "    \n",
    "    print(np_val_x.shape)\n",
    "    print(np_val_y.shape)\n",
    "    print(np_val_x.nbytes, np_val_y.nbytes)\n",
    "    \n",
    "\n",
    "    len_feat = np_val_x.shape[2]\n",
    "    len_class = np_val_y.shape[1]\n",
    "    display(len_class)\n",
    "    \n",
    "    # search parameter\n",
    "    score_list = []\n",
    "    #***\n",
    "    \n",
    "    l_units = [64, 128]\n",
    "    l_drop = [0.3, 0.5]\n",
    "    l_lr = [1e-4, 1e-3]\n",
    "    l_batch = [128, 256]\n",
    "    MAX_COUNT = len(l_units)*len(l_drop)*len(l_lr)*len(l_batch)\n",
    "    COUNT = 0\n",
    "    \n",
    "    for _units in l_units:\n",
    "        for _drop in l_drop:\n",
    "            for _lr in l_lr:\n",
    "                for _batch in l_batch:\n",
    "                    model_path = dir_out + \"\\\\\" + model_path_base + \"_{0:02d}.h5\".format(COUNT)\n",
    "                    scores = create_gru_model(np_train_x, np_train_y, np_val_x, np_val_y, len_class,\n",
    "                                              n_units=_units, drop=_drop, lr=_lr, batch=_batch,\n",
    "                                              model_path=model_path)\n",
    "                    param = [COUNT, _units, _drop, _lr, _batch]\n",
    "                    param.extend(scores)\n",
    "                    score_list.append(param)\n",
    "                    COUNT = COUNT + 1\n",
    "        \n",
    "        \n",
    "    # ******************* validation balances frames  ********************\n",
    "    print(score_list)\n",
    "    \n",
    "    df_res = pd.DataFrame(score_list, columns = [\"id\", \"units\", \"drop\", \"lr\", \"batch\", \"score\", \"f1\", \"acc\"])\n",
    "    display(df_res)\n",
    "    file_out = dir_out + \"\\\\res0_\" + model_path_base + \".csv\"\n",
    "    df_res.to_csv(file_out, index=False)\n",
    "    \n",
    "    best_id = df_res.loc[:,\"score\"].idxmax()\n",
    "    \n",
    "    best_path = dir_out + \"\\\\\" + model_path_base + \"_{0:02d}.h5\".format(best_id)\n",
    "    out_path = dir_out + \"\\\\\" + model_path_base + \"_best.h5\"\n",
    "    #best_path = dir_out + \"\\\\model_image_multi_b2\" + \"_{0:02d}.h5\".format(best_id)\n",
    "    #out_path = dir_out + \"\\\\model_image_multi_b2_best.h5\"\n",
    "    shutil.copy(best_path, out_path)\n",
    "    \n",
    "    \n",
    "    np_x_list = None\n",
    "    np_y_list = None\n",
    "    np_train_x = None\n",
    "    np_train_y = None\n",
    "    np_val_x = None\n",
    "    np_val_y = None\n",
    "    \n",
    "    # ******************* validation all frames  ********************\n",
    "    \n",
    "    #file_model = dir_out + \"\\\\model_image_multi_best.h5\"\n",
    "    model = keras.models.load_model(out_path, custom_objects={'f1':f1})\n",
    "    model.summary()\n",
    "    # ******\n",
    "    \n",
    "    np_val_x, np_val_y = data_read_separate2(val_list, dir_data, dir_audio,\n",
    "                                            pre_model, transformer, balance=0, sep_num=5, ignore_feat=True)\n",
    "    \n",
    "    print(np_val_x.shape)\n",
    "    print(np_val_y.shape)\n",
    "    print(np_val_x.nbytes, np_val_y.nbytes)\n",
    "\n",
    "    len_feat = np_val_x.shape[2]\n",
    "    len_class = np_val_y.shape[1]\n",
    "    display(len_class)\n",
    "    \n",
    "    pred_nn = model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    df_out = eval_pred_each_class(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), 7)\n",
    "    display(df_out)\n",
    "    \n",
    "    file_out = dir_out + \"\\\\res1_\" + model_path_base + \".csv\"\n",
    "    df_out.to_csv(file_out, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [02:40<00:00,  3.14s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [01:39<00:00,  1.95s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [01:21<00:00,  1.61s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [02:19<00:00,  2.74s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [02:16<00:00,  2.79s/it]\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327818, 10, 600)\n",
      "(327818, 7)\n",
      "7867632000 18357808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:54<00:00,  3.90s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:59<00:00,  4.26s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:39<00:00,  2.85s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:49<00:00,  3.51s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:45<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88136, 10, 600)\n",
      "(88136, 7)\n",
      "2115264000 4935616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.8248 - accuracy: 0.7217 - f1: 0.6787 - val_loss: 1.5694 - val_accuracy: 0.4943 - val_f1: 0.4772\n",
      "Score = 0.40730864233693886, F1 = 0.3959840982018368, ACC = 0.43030089861123716\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.4669 - accuracy: 0.8456 - f1: 0.8434 - val_loss: 1.7759 - val_accuracy: 0.5027 - val_f1: 0.4932\n",
      "Score = 0.42798276924350986, F1 = 0.4109979514367548, ACC = 0.46246709630570937\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 73s 222us/step - loss: 0.3874 - accuracy: 0.8710 - f1: 0.8705 - val_loss: 1.9074 - val_accuracy: 0.5012 - val_f1: 0.4943\n",
      "Score = 0.43092729440243305, F1 = 0.41216827080422586, ACC = 0.4690137968593991\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 71s 217us/step - loss: 0.3395 - accuracy: 0.8868 - f1: 0.8866 - val_loss: 1.9811 - val_accuracy: 0.5118 - val_f1: 0.5079\n",
      "Score = 0.4443315092301626, F1 = 0.4233505121919721, ACC = 0.4869292910955796\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 71s 217us/step - loss: 0.3041 - accuracy: 0.8982 - f1: 0.8986 - val_loss: 2.1063 - val_accuracy: 0.5031 - val_f1: 0.4983\n",
      "Score = 0.43290803374456716, F1 = 0.4101174111873097, ACC = 0.4791799037850595\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.2792 - accuracy: 0.9070 - f1: 0.9070 - val_loss: 2.1786 - val_accuracy: 0.5068 - val_f1: 0.5045\n",
      "Score = 0.4413688450444116, F1 = 0.4186268529171718, ACC = 0.48754198057547427\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 69s 211us/step - loss: 0.2558 - accuracy: 0.9143 - f1: 0.9146 - val_loss: 2.3014 - val_accuracy: 0.4998 - val_f1: 0.4965\n",
      "Score = 0.4294586845618542, F1 = 0.40401910450713857, ACC = 0.48110874103657986\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 69s 211us/step - loss: 0.2392 - accuracy: 0.9204 - f1: 0.9206 - val_loss: 2.4053 - val_accuracy: 0.4950 - val_f1: 0.4935\n",
      "Score = 0.42655985370993943, F1 = 0.4003630966962052, ACC = 0.47974720885903605\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 70s 215us/step - loss: 0.2245 - accuracy: 0.9250 - f1: 0.9253 - val_loss: 2.4909 - val_accuracy: 0.4951 - val_f1: 0.4940\n",
      "Score = 0.4254212584418534, F1 = 0.3982389840197983, ACC = 0.48060951257148044\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 69s 212us/step - loss: 0.2105 - accuracy: 0.9298 - f1: 0.9300 - val_loss: 2.5734 - val_accuracy: 0.4918 - val_f1: 0.4918\n",
      "Score = 0.4228457353338941, F1 = 0.394802871298429, ACC = 0.47978124716347464\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 69s 212us/step - loss: 0.1982 - accuracy: 0.9336 - f1: 0.9338 - val_loss: 2.6416 - val_accuracy: 0.4898 - val_f1: 0.4900\n",
      "Score = 0.4181921783594295, F1 = 0.3883937481945588, ACC = 0.4786920214214396\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.1887 - accuracy: 0.9367 - f1: 0.9370 - val_loss: 2.7668 - val_accuracy: 0.4846 - val_f1: 0.4846\n",
      "Score = 0.4107226513116573, F1 = 0.3796705565619115, ACC = 0.4737678133793229\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.45733390263744733, 0.4305017558151997, 0.5118112916401925]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 39s 120us/step - loss: 0.9574 - accuracy: 0.6745 - f1: 0.6124 - val_loss: 1.4842 - val_accuracy: 0.4985 - val_f1: 0.4730\n",
      "Score = 0.3978872550268623, F1 = 0.3900981236096374, ACC = 0.4137015521466824\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.5343 - accuracy: 0.8244 - f1: 0.8194 - val_loss: 1.6314 - val_accuracy: 0.5041 - val_f1: 0.4894\n",
      "Score = 0.42457031459763983, F1 = 0.41178370956177596, ACC = 0.4505309975492421\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.4411 - accuracy: 0.8536 - f1: 0.8523 - val_loss: 1.7333 - val_accuracy: 0.5055 - val_f1: 0.4941\n",
      "Score = 0.43490884518225265, F1 = 0.42085477767370066, ACC = 0.46344286103294907\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 39s 119us/step - loss: 0.3868 - accuracy: 0.8710 - f1: 0.8708 - val_loss: 1.8540 - val_accuracy: 0.5098 - val_f1: 0.5017\n",
      "Score = 0.44080308614093966, F1 = 0.4234937593074925, ACC = 0.4759462648633929\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.3504 - accuracy: 0.8834 - f1: 0.8834 - val_loss: 1.9533 - val_accuracy: 0.5110 - val_f1: 0.5038\n",
      "Score = 0.44270972034690703, F1 = 0.42348382067088647, ACC = 0.4817441227194336\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.3230 - accuracy: 0.8929 - f1: 0.8926 - val_loss: 2.0362 - val_accuracy: 0.5091 - val_f1: 0.5041\n",
      "Score = 0.44364548907174184, F1 = 0.42398076149659875, ACC = 0.4835708450576382\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.2984 - accuracy: 0.9001 - f1: 0.9005 - val_loss: 2.1334 - val_accuracy: 0.5062 - val_f1: 0.5023\n",
      "Score = 0.43941773147354646, F1 = 0.4170894841817138, ACC = 0.4847508396115095\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.2798 - accuracy: 0.9066 - f1: 0.9071 - val_loss: 2.1675 - val_accuracy: 0.5058 - val_f1: 0.5023\n",
      "Score = 0.44135123011513067, F1 = 0.41961764683594754, ACC = 0.4854769901061995\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.2649 - accuracy: 0.9118 - f1: 0.9121 - val_loss: 2.2238 - val_accuracy: 0.5041 - val_f1: 0.5013\n",
      "Score = 0.4385318667121902, F1 = 0.41515816473160194, ACC = 0.4859875646727784\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.2491 - accuracy: 0.9167 - f1: 0.9171 - val_loss: 2.3169 - val_accuracy: 0.5045 - val_f1: 0.5006\n",
      "Score = 0.43767570369420383, F1 = 0.413762953535722, ACC = 0.4862258328038486\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.2362 - accuracy: 0.9212 - f1: 0.9216 - val_loss: 2.3789 - val_accuracy: 0.5022 - val_f1: 0.4982\n",
      "Score = 0.4336096149117224, F1 = 0.40858830484264413, ACC = 0.48441045656712356\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.2248 - accuracy: 0.9252 - f1: 0.9254 - val_loss: 2.4600 - val_accuracy: 0.4998 - val_f1: 0.4977\n",
      "Score = 0.43085770933460205, F1 = 0.4043245084922095, ACC = 0.4847281474085504\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.2163 - accuracy: 0.9276 - f1: 0.9279 - val_loss: 2.4721 - val_accuracy: 0.5015 - val_f1: 0.4980\n",
      "Score = 0.4332960429504853, F1 = 0.407276441860611, ACC = 0.4861237178905328\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.2055 - accuracy: 0.9314 - f1: 0.9316 - val_loss: 2.5739 - val_accuracy: 0.4944 - val_f1: 0.4914\n",
      "Score = 0.4243990077242114, F1 = 0.3968026507334847, ACC = 0.4804279749478079\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.45729219482968025, 0.4317527742659021, 0.5091449577925025]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.4325 - accuracy: 0.8541 - f1: 0.8495 - val_loss: 1.9790 - val_accuracy: 0.5291 - val_f1: 0.5243\n",
      "Score = 0.46960898258692296, F1 = 0.45300846604232126, ACC = 0.5033130616320233\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.2822 - accuracy: 0.9046 - f1: 0.9051 - val_loss: 2.3007 - val_accuracy: 0.5174 - val_f1: 0.5142\n",
      "Score = 0.4517135309664607, F1 = 0.4286515440394692, ACC = 0.49853635290914045\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 67s 205us/step - loss: 0.2480 - accuracy: 0.9168 - f1: 0.9170 - val_loss: 2.5444 - val_accuracy: 0.5017 - val_f1: 0.4995\n",
      "Score = 0.43832509664526276, F1 = 0.414726608367917, ACC = 0.48623717890532814\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 67s 205us/step - loss: 0.2312 - accuracy: 0.9225 - f1: 0.9231 - val_loss: 2.6905 - val_accuracy: 0.5011 - val_f1: 0.4996\n",
      "Score = 0.43626094102132473, F1 = 0.4113440066480614, ACC = 0.4868498683852228\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.2193 - accuracy: 0.9261 - f1: 0.9268 - val_loss: 2.9394 - val_accuracy: 0.4776 - val_f1: 0.4742\n",
      "Score = 0.4054298581760053, F1 = 0.3762862750139269, ACC = 0.4646001633838613\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 68s 206us/step - loss: 0.2106 - accuracy: 0.9289 - f1: 0.9295 - val_loss: 2.6599 - val_accuracy: 0.4989 - val_f1: 0.4975\n",
      "Score = 0.4387508269058801, F1 = 0.41517202180376334, ACC = 0.4866229463556322\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.2048 - accuracy: 0.9311 - f1: 0.9316 - val_loss: 2.7956 - val_accuracy: 0.4797 - val_f1: 0.4785\n",
      "Score = 0.414272007400887, F1 = 0.3879131783492772, ACC = 0.4677884178996097\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 67s 205us/step - loss: 0.2020 - accuracy: 0.9324 - f1: 0.9329 - val_loss: 2.8668 - val_accuracy: 0.4804 - val_f1: 0.4791\n",
      "Score = 0.4102231767863662, F1 = 0.38159631704264324, ACC = 0.4683443768721067\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.1988 - accuracy: 0.9335 - f1: 0.9341 - val_loss: 2.9086 - val_accuracy: 0.4928 - val_f1: 0.4920\n",
      "Score = 0.428965935949697, F1 = 0.40298747476529645, ACC = 0.481710084414995\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4824649802459078, 0.45949413828143015, 0.5291027502949986]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 39s 119us/step - loss: 0.4623 - accuracy: 0.8454 - f1: 0.8378 - val_loss: 2.1626 - val_accuracy: 0.4959 - val_f1: 0.4918\n",
      "Score = 0.4365251940239821, F1 = 0.4190312478492818, ACC = 0.47204320595443405\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.2791 - accuracy: 0.9057 - f1: 0.9063 - val_loss: 2.4732 - val_accuracy: 0.4832 - val_f1: 0.4826\n",
      "Score = 0.4196642828178694, F1 = 0.39653136520417787, ACC = 0.46663111554869746\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.2369 - accuracy: 0.9203 - f1: 0.9206 - val_loss: 2.6786 - val_accuracy: 0.4816 - val_f1: 0.4794\n",
      "Score = 0.4188228188497065, F1 = 0.39557163288584085, ACC = 0.4660297721702823\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.2162 - accuracy: 0.9275 - f1: 0.9277 - val_loss: 2.7738 - val_accuracy: 0.5034 - val_f1: 0.5032\n",
      "Score = 0.44198824190011243, F1 = 0.4175842166602141, ACC = 0.4915358082962694\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 40s 123us/step - loss: 0.1995 - accuracy: 0.9328 - f1: 0.9333 - val_loss: 2.7597 - val_accuracy: 0.4833 - val_f1: 0.4825\n",
      "Score = 0.42550619733387596, F1 = 0.4032332360202226, ACC = 0.4707270581828084\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 39s 119us/step - loss: 0.1924 - accuracy: 0.9355 - f1: 0.9361 - val_loss: 2.8500 - val_accuracy: 0.4931 - val_f1: 0.4914\n",
      "Score = 0.4290701315579466, F1 = 0.40327711167868074, ACC = 0.4814377779794862\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 39s 119us/step - loss: 0.1835 - accuracy: 0.9385 - f1: 0.9388 - val_loss: 3.1222 - val_accuracy: 0.4639 - val_f1: 0.4620\n",
      "Score = 0.3960894737916154, F1 = 0.36768230411375463, ACC = 0.4537646364709086\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.1790 - accuracy: 0.9408 - f1: 0.9411 - val_loss: 3.0174 - val_accuracy: 0.4919 - val_f1: 0.4897\n",
      "Score = 0.4355836334808416, F1 = 0.41287581201622353, ACC = 0.48168739221203594\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.1744 - accuracy: 0.9420 - f1: 0.9424 - val_loss: 3.1344 - val_accuracy: 0.4879 - val_f1: 0.4856\n",
      "Score = 0.4296014376133629, F1 = 0.4055063190247932, ACC = 0.47852182989924663\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.1718 - accuracy: 0.9429 - f1: 0.9433 - val_loss: 3.1837 - val_accuracy: 0.4862 - val_f1: 0.4839\n",
      "Score = 0.42388775631123576, F1 = 0.3980346399906907, ACC = 0.47637741671961514\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.1696 - accuracy: 0.9432 - f1: 0.9438 - val_loss: 3.2541 - val_accuracy: 0.4793 - val_f1: 0.4772\n",
      "Score = 0.41009714024427807, F1 = 0.38058112280630224, ACC = 0.47002359989107745\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.1674 - accuracy: 0.9442 - f1: 0.9445 - val_loss: 3.2951 - val_accuracy: 0.4870 - val_f1: 0.4850\n",
      "Score = 0.4194068717930687, F1 = 0.3898155369848006, ACC = 0.4794862485250068\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4465752964194626, 0.41859629970144097, 0.5033811382409005]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 71s 215us/step - loss: 1.1782 - accuracy: 0.5845 - f1: 0.5203 - val_loss: 1.4715 - val_accuracy: 0.4988 - val_f1: 0.4690\n",
      "Score = 0.400367574627274, F1 = 0.39661663584618584, ACC = 0.40798311700099843\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.7348 - accuracy: 0.7531 - f1: 0.7430 - val_loss: 1.6226 - val_accuracy: 0.5059 - val_f1: 0.4903\n",
      "Score = 0.4302210473506374, F1 = 0.420882656066401, ACC = 0.44918081147317784\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.6320 - accuracy: 0.7898 - f1: 0.7848 - val_loss: 1.7161 - val_accuracy: 0.5093 - val_f1: 0.4959\n",
      "Score = 0.4380807544927511, F1 = 0.42624281094030236, ACC = 0.46211536715984386\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.5753 - accuracy: 0.8090 - f1: 0.8058 - val_loss: 1.8162 - val_accuracy: 0.5087 - val_f1: 0.5002\n",
      "Score = 0.4417953194274288, F1 = 0.4270871115239789, ACC = 0.47165743850413\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.5328 - accuracy: 0.8236 - f1: 0.8215 - val_loss: 1.8845 - val_accuracy: 0.5077 - val_f1: 0.4971\n",
      "Score = 0.4414023730071878, F1 = 0.4266515105447874, ACC = 0.4713510937641826\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 69s 210us/step - loss: 0.4986 - accuracy: 0.8353 - f1: 0.8341 - val_loss: 1.9432 - val_accuracy: 0.5032 - val_f1: 0.4944\n",
      "Score = 0.4387023412828167, F1 = 0.42282838244731563, ACC = 0.47093128800943995\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 69s 211us/step - loss: 0.4704 - accuracy: 0.8444 - f1: 0.8439 - val_loss: 2.0016 - val_accuracy: 0.5050 - val_f1: 0.4982\n",
      "Score = 0.44286141853531874, F1 = 0.4254091028930332, ACC = 0.478294907869656\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 69s 212us/step - loss: 0.4469 - accuracy: 0.8530 - f1: 0.8525 - val_loss: 2.0996 - val_accuracy: 0.5015 - val_f1: 0.4952\n",
      "Score = 0.4363796683559079, F1 = 0.4163495705113857, ACC = 0.4770468367069075\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.4264 - accuracy: 0.8596 - f1: 0.8593 - val_loss: 2.1595 - val_accuracy: 0.4943 - val_f1: 0.4895\n",
      "Score = 0.4290242295718854, F1 = 0.4078134250044316, ACC = 0.47208859036035217\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 69s 209us/step - loss: 0.4077 - accuracy: 0.8668 - f1: 0.8662 - val_loss: 2.1733 - val_accuracy: 0.5000 - val_f1: 0.4950\n",
      "Score = 0.4368980471319891, F1 = 0.41622912964267217, ACC = 0.47886221294363257\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.3893 - accuracy: 0.8724 - f1: 0.8720 - val_loss: 2.2785 - val_accuracy: 0.4960 - val_f1: 0.4906\n",
      "Score = 0.43205214526128205, F1 = 0.4105108908137281, ACC = 0.4757874194426795\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 69s 211us/step - loss: 0.3733 - accuracy: 0.8770 - f1: 0.8769 - val_loss: 2.2413 - val_accuracy: 0.4997 - val_f1: 0.4952\n",
      "Score = 0.438751987747091, F1 = 0.41853795816366585, ACC = 0.47979259326495416\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.45854363249596974, 0.4356379962592544, 0.5050490151583916]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 1.3234 - accuracy: 0.5289 - f1: 0.4451 - val_loss: 1.4360 - val_accuracy: 0.4929 - val_f1: 0.4565\n",
      "Score = 0.37809926037301655, F1 = 0.37596537393763546, ACC = 0.3824316964690932\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.8243 - accuracy: 0.7219 - f1: 0.7030 - val_loss: 1.5414 - val_accuracy: 0.5068 - val_f1: 0.4861\n",
      "Score = 0.41918012025158, F1 = 0.40995292008844625, ACC = 0.4379141327040029\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 35s 106us/step - loss: 0.6995 - accuracy: 0.7663 - f1: 0.7586 - val_loss: 1.6199 - val_accuracy: 0.5105 - val_f1: 0.4957\n",
      "Score = 0.435824998577918, F1 = 0.4255360791575737, ACC = 0.45671462285558684\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.6342 - accuracy: 0.7886 - f1: 0.7844 - val_loss: 1.7067 - val_accuracy: 0.5152 - val_f1: 0.5018\n",
      "Score = 0.4418073569089982, F1 = 0.42841275844609655, ACC = 0.4690024507579196\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 35s 106us/step - loss: 0.5895 - accuracy: 0.8039 - f1: 0.8013 - val_loss: 1.7597 - val_accuracy: 0.5169 - val_f1: 0.5046\n",
      "Score = 0.4456605396838398, F1 = 0.43143664888278, ACC = 0.474539348279931\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 35s 106us/step - loss: 0.5545 - accuracy: 0.8172 - f1: 0.8148 - val_loss: 1.8304 - val_accuracy: 0.5128 - val_f1: 0.5024\n",
      "Score = 0.4451212933907285, F1 = 0.43019032178026834, ACC = 0.47543569029681404\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.5256 - accuracy: 0.8265 - f1: 0.8243 - val_loss: 1.8835 - val_accuracy: 0.5093 - val_f1: 0.5015\n",
      "Score = 0.44282057802489827, F1 = 0.42566668447274897, ACC = 0.47764818008532267\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 35s 106us/step - loss: 0.5032 - accuracy: 0.8341 - f1: 0.8330 - val_loss: 1.9338 - val_accuracy: 0.5099 - val_f1: 0.5020\n",
      "Score = 0.4449123333221571, F1 = 0.4276766200146862, ACC = 0.47990605427974947\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.4818 - accuracy: 0.8410 - f1: 0.8400 - val_loss: 1.9956 - val_accuracy: 0.5092 - val_f1: 0.5024\n",
      "Score = 0.44281761819071797, F1 = 0.4241366395227916, ACC = 0.48074566578923483\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 35s 106us/step - loss: 0.4631 - accuracy: 0.8475 - f1: 0.8467 - val_loss: 2.0317 - val_accuracy: 0.5092 - val_f1: 0.5025\n",
      "Score = 0.44212820497106, F1 = 0.42218558214186863, ACC = 0.4826177725333575\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 37s 111us/step - loss: 0.4458 - accuracy: 0.8529 - f1: 0.8529 - val_loss: 2.0583 - val_accuracy: 0.5125 - val_f1: 0.5061\n",
      "Score = 0.4474521532120094, F1 = 0.42752200086118014, ACC = 0.4879164019242988\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.4279 - accuracy: 0.8595 - f1: 0.8590 - val_loss: 2.0919 - val_accuracy: 0.5103 - val_f1: 0.5041\n",
      "Score = 0.4464287822222531, F1 = 0.42657577282091336, ACC = 0.4867364073704275\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 36s 111us/step - loss: 0.4139 - accuracy: 0.8636 - f1: 0.8637 - val_loss: 2.1248 - val_accuracy: 0.5118 - val_f1: 0.5056\n",
      "Score = 0.44686455869332153, F1 = 0.42618115871459483, ACC = 0.48885812834709996\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.3989 - accuracy: 0.8692 - f1: 0.8692 - val_loss: 2.1841 - val_accuracy: 0.5088 - val_f1: 0.5041\n",
      "Score = 0.4442515118713828, F1 = 0.42251580072141204, ACC = 0.4883815920849596\n",
      "Epoch 15/30\n",
      "327818/327818 [==============================] - 36s 110us/step - loss: 0.3873 - accuracy: 0.8738 - f1: 0.8734 - val_loss: 2.2512 - val_accuracy: 0.5068 - val_f1: 0.5027\n",
      "Score = 0.44114919854975054, F1 = 0.418069898816158, ACC = 0.4880071707361351\n",
      "Epoch 16/30\n",
      "327818/327818 [==============================] - 36s 111us/step - loss: 0.3748 - accuracy: 0.8775 - f1: 0.8772 - val_loss: 2.2777 - val_accuracy: 0.5067 - val_f1: 0.5016\n",
      "Score = 0.44055022555044987, F1 = 0.4172709116967544, ACC = 0.487814287010983\n",
      "Epoch 17/30\n",
      "327818/327818 [==============================] - 36s 110us/step - loss: 0.3624 - accuracy: 0.8811 - f1: 0.8812 - val_loss: 2.3165 - val_accuracy: 0.5102 - val_f1: 0.5065\n",
      "Score = 0.4480468979654675, F1 = 0.42564343231905577, ACC = 0.493532722156667\n",
      "Epoch 18/30\n",
      "327818/327818 [==============================] - 36s 110us/step - loss: 0.3532 - accuracy: 0.8845 - f1: 0.8847 - val_loss: 2.3383 - val_accuracy: 0.5115 - val_f1: 0.5075\n",
      "Score = 0.44585705529075303, F1 = 0.4218105842040898, ACC = 0.49467867840609964\n",
      "Epoch 19/30\n",
      "327818/327818 [==============================] - 36s 109us/step - loss: 0.3440 - accuracy: 0.8879 - f1: 0.8877 - val_loss: 2.3880 - val_accuracy: 0.5058 - val_f1: 0.5012\n",
      "Score = 0.4416802834262808, F1 = 0.4183931390303635, ACC = 0.4889602432604157\n",
      "Epoch 20/30\n",
      "327818/327818 [==============================] - 36s 110us/step - loss: 0.3343 - accuracy: 0.8915 - f1: 0.8916 - val_loss: 2.4620 - val_accuracy: 0.5026 - val_f1: 0.4990\n",
      "Score = 0.43741663299743294, F1 = 0.4124430216710834, ACC = 0.4881206317509304\n",
      "Epoch 21/30\n",
      "327818/327818 [==============================] - 36s 110us/step - loss: 0.3276 - accuracy: 0.8935 - f1: 0.8932 - val_loss: 2.4346 - val_accuracy: 0.5085 - val_f1: 0.5048\n",
      "Score = 0.44533014150831424, F1 = 0.4215997486919263, ACC = 0.4935100299537079\n",
      "Epoch 22/30\n",
      "327818/327818 [==============================] - 36s 110us/step - loss: 0.3178 - accuracy: 0.8964 - f1: 0.8969 - val_loss: 2.4999 - val_accuracy: 0.5047 - val_f1: 0.5007\n",
      "Score = 0.44069823978807576, F1 = 0.41667033685325267, ACC = 0.48948216392847416\n",
      "Epoch 23/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.3114 - accuracy: 0.8989 - f1: 0.8991 - val_loss: 2.5426 - val_accuracy: 0.5062 - val_f1: 0.5030\n",
      "Score = 0.4415478100879582, F1 = 0.4163903714258472, ACC = 0.49262503403830443\n",
      "Epoch 24/30\n",
      "327818/327818 [==============================] - 36s 110us/step - loss: 0.3049 - accuracy: 0.9010 - f1: 0.9015 - val_loss: 2.5340 - val_accuracy: 0.5075 - val_f1: 0.5047\n",
      "Score = 0.443451350269386, F1 = 0.41851616374664197, ACC = 0.49407733502768447\n",
      "Epoch 25/30\n",
      "327818/327818 [==============================] - 36s 110us/step - loss: 0.2984 - accuracy: 0.9033 - f1: 0.9035 - val_loss: 2.5705 - val_accuracy: 0.5044 - val_f1: 0.5015\n",
      "Score = 0.4374770119132795, F1 = 0.41086780271041085, ACC = 0.4915017699918308\n",
      "Epoch 26/30\n",
      "327818/327818 [==============================] - 36s 109us/step - loss: 0.2924 - accuracy: 0.9054 - f1: 0.9056 - val_loss: 2.6201 - val_accuracy: 0.4979 - val_f1: 0.4948\n",
      "Score = 0.42883409626235314, F1 = 0.40103035993523495, ACC = 0.48528410638104746\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4575978889066116, 0.43166696138317306, 0.5102455296360171]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 71s 217us/step - loss: 0.6670 - accuracy: 0.7760 - f1: 0.7644 - val_loss: 1.8887 - val_accuracy: 0.4989 - val_f1: 0.4926\n",
      "Score = 0.4345444031672824, F1 = 0.4184051973536081, ACC = 0.46731188163746934\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.4819 - accuracy: 0.8407 - f1: 0.8397 - val_loss: 1.9405 - val_accuracy: 0.5198 - val_f1: 0.5152\n",
      "Score = 0.47008080326523377, F1 = 0.4576189524700741, ACC = 0.4953821366978306\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.4368 - accuracy: 0.8562 - f1: 0.8561 - val_loss: 2.0514 - val_accuracy: 0.5150 - val_f1: 0.5108\n",
      "Score = 0.4651432322390109, F1 = 0.4521047850848122, ACC = 0.49161523100662613\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.4152 - accuracy: 0.8646 - f1: 0.8642 - val_loss: 2.1707 - val_accuracy: 0.5119 - val_f1: 0.5076\n",
      "Score = 0.457441278283952, F1 = 0.4410116946610731, ACC = 0.49079831170009985\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.3982 - accuracy: 0.8701 - f1: 0.8701 - val_loss: 2.3100 - val_accuracy: 0.5005 - val_f1: 0.4991\n",
      "Score = 0.45096503061856974, F1 = 0.4341230774047683, ACC = 0.48515929926477264\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.3897 - accuracy: 0.8739 - f1: 0.8740 - val_loss: 2.4229 - val_accuracy: 0.4922 - val_f1: 0.4880\n",
      "Score = 0.4326224572623738, F1 = 0.4119377057247445, ACC = 0.47461877099028776\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 70s 215us/step - loss: 0.3832 - accuracy: 0.8763 - f1: 0.8762 - val_loss: 2.4321 - val_accuracy: 0.4859 - val_f1: 0.4830\n",
      "Score = 0.43041523289579786, F1 = 0.41072780611957976, ACC = 0.4703866751384224\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.3813 - accuracy: 0.8763 - f1: 0.8762 - val_loss: 2.4808 - val_accuracy: 0.4839 - val_f1: 0.4828\n",
      "Score = 0.42323927060889766, F1 = 0.400023003024935, ACC = 0.4703753290369429\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 71s 215us/step - loss: 0.3779 - accuracy: 0.8769 - f1: 0.8771 - val_loss: 2.2412 - val_accuracy: 0.5121 - val_f1: 0.5093\n",
      "Score = 0.46526655949101986, F1 = 0.4498970296803943, ACC = 0.49647136243986567\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 71s 217us/step - loss: 0.3742 - accuracy: 0.8789 - f1: 0.8792 - val_loss: 2.3664 - val_accuracy: 0.5000 - val_f1: 0.4961\n",
      "Score = 0.4495232668006419, F1 = 0.43314475056089324, ACC = 0.482776617954071\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4842634673777254, 0.46674974091606053, 0.5198216392847418]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 40s 122us/step - loss: 0.7099 - accuracy: 0.7597 - f1: 0.7457 - val_loss: 1.7937 - val_accuracy: 0.5261 - val_f1: 0.5173\n",
      "Score = 0.4641953348746032, F1 = 0.451008550464547, ACC = 0.4909685032222928\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 39s 120us/step - loss: 0.4850 - accuracy: 0.8400 - f1: 0.8390 - val_loss: 2.0306 - val_accuracy: 0.5221 - val_f1: 0.5156\n",
      "Score = 0.4649546744199616, F1 = 0.44933652714254585, ACC = 0.4966642461650177\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.4289 - accuracy: 0.8594 - f1: 0.8591 - val_loss: 2.2377 - val_accuracy: 0.5115 - val_f1: 0.5067\n",
      "Score = 0.44931440299292147, F1 = 0.42850760869877025, ACC = 0.49155850049922845\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 39s 119us/step - loss: 0.3986 - accuracy: 0.8701 - f1: 0.8705 - val_loss: 2.3357 - val_accuracy: 0.5226 - val_f1: 0.5200\n",
      "Score = 0.46336001510093816, F1 = 0.4415133581028824, ACC = 0.5077153490060815\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 39s 120us/step - loss: 0.3798 - accuracy: 0.8760 - f1: 0.8763 - val_loss: 2.5720 - val_accuracy: 0.5010 - val_f1: 0.4992\n",
      "Score = 0.43765045076753384, F1 = 0.41240081693365616, ACC = 0.4889148588544976\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.3659 - accuracy: 0.8819 - f1: 0.8822 - val_loss: 2.6287 - val_accuracy: 0.5090 - val_f1: 0.5064\n",
      "Score = 0.44346533812915107, F1 = 0.41732436304935205, ACC = 0.49653943904874287\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.3577 - accuracy: 0.8839 - f1: 0.8842 - val_loss: 2.8551 - val_accuracy: 0.4995 - val_f1: 0.4968\n",
      "Score = 0.4372207093261071, F1 = 0.41181529558060503, ACC = 0.4888013978397023\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.3539 - accuracy: 0.8861 - f1: 0.8863 - val_loss: 2.9078 - val_accuracy: 0.4980 - val_f1: 0.4965\n",
      "Score = 0.427438234311384, F1 = 0.39704693525318635, ACC = 0.4891417808840882\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 39s 119us/step - loss: 0.3471 - accuracy: 0.8885 - f1: 0.8889 - val_loss: 2.6254 - val_accuracy: 0.5083 - val_f1: 0.5050\n",
      "Score = 0.4508604347607982, F1 = 0.42861329773385676, ACC = 0.49602886448216393\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 39s 119us/step - loss: 0.3400 - accuracy: 0.8910 - f1: 0.8912 - val_loss: 2.7146 - val_accuracy: 0.5088 - val_f1: 0.5074\n",
      "Score = 0.4510815596514741, F1 = 0.42766918462244785, ACC = 0.49861577561949716\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 39s 119us/step - loss: 0.3399 - accuracy: 0.8910 - f1: 0.8913 - val_loss: 2.7721 - val_accuracy: 0.5106 - val_f1: 0.5097\n",
      "Score = 0.4504000217766523, F1 = 0.42517104365348235, ACC = 0.501622492511573\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 40s 123us/step - loss: 0.3358 - accuracy: 0.8923 - f1: 0.8929 - val_loss: 2.7523 - val_accuracy: 0.5166 - val_f1: 0.5136\n",
      "Score = 0.4563133791832643, F1 = 0.43202425267626055, ACC = 0.5056276663338477\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_8 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.47986203960725515, 0.4590460049330994, 0.5221248978850866]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 73s 224us/step - loss: 0.6710 - accuracy: 0.7718 - f1: 0.7515 - val_loss: 1.6706 - val_accuracy: 0.5032 - val_f1: 0.4957\n",
      "Score = 0.44204203123923613, F1 = 0.43309401185449675, ACC = 0.46020922211128257\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 73s 223us/step - loss: 0.3715 - accuracy: 0.8743 - f1: 0.8738 - val_loss: 1.9670 - val_accuracy: 0.4948 - val_f1: 0.4926\n",
      "Score = 0.4371735795002327, F1 = 0.42171461951665795, ACC = 0.46855995280021784\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 73s 222us/step - loss: 0.2970 - accuracy: 0.8992 - f1: 0.8992 - val_loss: 2.1685 - val_accuracy: 0.4991 - val_f1: 0.4972\n",
      "Score = 0.4405549750069007, F1 = 0.42137428176143316, ACC = 0.47949759462648633\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 73s 222us/step - loss: 0.2502 - accuracy: 0.9151 - f1: 0.9153 - val_loss: 2.3959 - val_accuracy: 0.5033 - val_f1: 0.5027\n",
      "Score = 0.4439020924533565, F1 = 0.4223072283890471, ACC = 0.48774621040210586\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 74s 224us/step - loss: 0.2191 - accuracy: 0.9250 - f1: 0.9256 - val_loss: 2.4583 - val_accuracy: 0.4965 - val_f1: 0.4964\n",
      "Score = 0.43824561657158945, F1 = 0.41597713408574816, ACC = 0.4834573840428429\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 71s 218us/step - loss: 0.1946 - accuracy: 0.9337 - f1: 0.9340 - val_loss: 2.6727 - val_accuracy: 0.4956 - val_f1: 0.4949\n",
      "Score = 0.43522148469420374, F1 = 0.4111952622576564, ACC = 0.4840019969138604\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 70s 215us/step - loss: 0.1766 - accuracy: 0.9402 - f1: 0.9404 - val_loss: 2.7306 - val_accuracy: 0.4932 - val_f1: 0.4928\n",
      "Score = 0.4344078351053522, F1 = 0.41060116988205, ACC = 0.4827425796496324\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 71s 215us/step - loss: 0.1622 - accuracy: 0.9442 - f1: 0.9445 - val_loss: 2.8155 - val_accuracy: 0.4941 - val_f1: 0.4933\n",
      "Score = 0.43397881411713124, F1 = 0.4093908254581365, ACC = 0.4838998820005446\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 72s 220us/step - loss: 0.1498 - accuracy: 0.9492 - f1: 0.9495 - val_loss: 2.8886 - val_accuracy: 0.4940 - val_f1: 0.4935\n",
      "Score = 0.43207410679605274, F1 = 0.40598355249785095, ACC = 0.4850458382499773\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 72s 220us/step - loss: 0.1398 - accuracy: 0.9522 - f1: 0.9524 - val_loss: 2.8936 - val_accuracy: 0.4937 - val_f1: 0.4932\n",
      "Score = 0.43316612120637976, F1 = 0.4075240106986199, ACC = 0.48522737587364984\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 72s 219us/step - loss: 0.1322 - accuracy: 0.9549 - f1: 0.9552 - val_loss: 3.1150 - val_accuracy: 0.4896 - val_f1: 0.4887\n",
      "Score = 0.4276600477420396, F1 = 0.4008204411329099, ACC = 0.48215258237269676\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 72s 220us/step - loss: 0.1230 - accuracy: 0.9581 - f1: 0.9582 - val_loss: 3.0427 - val_accuracy: 0.4924 - val_f1: 0.4925\n",
      "Score = 0.4367519734253831, F1 = 0.41290955920598227, ACC = 0.48515929926477264\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_9 (GRU)                  (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.449533891353607, 0.42304564330602884, 0.5033130616320233]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.7787 - accuracy: 0.7341 - f1: 0.7042 - val_loss: 1.5858 - val_accuracy: 0.4947 - val_f1: 0.4826\n",
      "Score = 0.42586452671133684, F1 = 0.4197843483109276, ACC = 0.43820913134247075\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.4287 - accuracy: 0.8557 - f1: 0.8540 - val_loss: 1.7963 - val_accuracy: 0.4993 - val_f1: 0.4939\n",
      "Score = 0.4405506006523095, F1 = 0.42850970039335323, ACC = 0.4649972769356449\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3469 - accuracy: 0.8830 - f1: 0.8828 - val_loss: 1.9834 - val_accuracy: 0.4976 - val_f1: 0.4941\n",
      "Score = 0.4409386255016097, F1 = 0.42547874955140347, ACC = 0.47232685849142236\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.2958 - accuracy: 0.8998 - f1: 0.9001 - val_loss: 2.1564 - val_accuracy: 0.4976 - val_f1: 0.4955\n",
      "Score = 0.44151892807176274, F1 = 0.42391392821224855, ACC = 0.4772624126350186\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.2619 - accuracy: 0.9107 - f1: 0.9109 - val_loss: 2.2834 - val_accuracy: 0.4969 - val_f1: 0.4948\n",
      "Score = 0.4392497293522041, F1 = 0.4195546866204376, ACC = 0.4792366342924571\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.2333 - accuracy: 0.9210 - f1: 0.9213 - val_loss: 2.4418 - val_accuracy: 0.5028 - val_f1: 0.5015\n",
      "Score = 0.44454449664396234, F1 = 0.4231766265603813, ACC = 0.4879277480257783\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.2136 - accuracy: 0.9274 - f1: 0.9279 - val_loss: 2.5205 - val_accuracy: 0.4959 - val_f1: 0.4944\n",
      "Score = 0.4360690478381775, F1 = 0.41364501808374865, ACC = 0.4815966234001997\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.1964 - accuracy: 0.9328 - f1: 0.9333 - val_loss: 2.5690 - val_accuracy: 0.4967 - val_f1: 0.4959\n",
      "Score = 0.43939286771549957, F1 = 0.41731502787708796, ACC = 0.4842175728419715\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.1820 - accuracy: 0.9383 - f1: 0.9384 - val_loss: 2.6852 - val_accuracy: 0.4963 - val_f1: 0.4950\n",
      "Score = 0.4360609928377687, F1 = 0.4121911940831873, ACC = 0.4845239175819189\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.1684 - accuracy: 0.9426 - f1: 0.9429 - val_loss: 2.7717 - val_accuracy: 0.4962 - val_f1: 0.4961\n",
      "Score = 0.4359751760684927, F1 = 0.4112416177368467, ACC = 0.48619179449941\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.1594 - accuracy: 0.9457 - f1: 0.9460 - val_loss: 2.8693 - val_accuracy: 0.4930 - val_f1: 0.4919\n",
      "Score = 0.43092883501665113, F1 = 0.40501185757404035, ACC = 0.4835481528546791\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.1497 - accuracy: 0.9489 - f1: 0.9492 - val_loss: 2.9558 - val_accuracy: 0.4926 - val_f1: 0.4919\n",
      "Score = 0.4306557850008998, F1 = 0.4044813759136034, ACC = 0.4837977670872288\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.1426 - accuracy: 0.9514 - f1: 0.9516 - val_loss: 3.1141 - val_accuracy: 0.4924 - val_f1: 0.4915\n",
      "Score = 0.42969527241788197, F1 = 0.4026789420729436, ACC = 0.4845466097848779\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.1348 - accuracy: 0.9537 - f1: 0.9539 - val_loss: 3.1663 - val_accuracy: 0.4896 - val_f1: 0.4877\n",
      "Score = 0.4235574197848233, F1 = 0.3952559536576984, ACC = 0.4810179722247436\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.449452134700129, 0.42316950709708084, 0.5028138331669239]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.3526 - accuracy: 0.8798 - f1: 0.8780 - val_loss: 2.2841 - val_accuracy: 0.4994 - val_f1: 0.4968\n",
      "Score = 0.45021607657171747, F1 = 0.43519587985333535, ACC = 0.48071162748479623\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.2195 - accuracy: 0.9252 - f1: 0.9254 - val_loss: 2.6688 - val_accuracy: 0.4860 - val_f1: 0.4843\n",
      "Score = 0.43341111969508406, F1 = 0.4157637051667424, ACC = 0.4692407188889897\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.1912 - accuracy: 0.9343 - f1: 0.9346 - val_loss: 3.1393 - val_accuracy: 0.4811 - val_f1: 0.4789\n",
      "Score = 0.4163624806590909, F1 = 0.39074828039450626, ACC = 0.4683670690750658\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.1756 - accuracy: 0.9404 - f1: 0.9407 - val_loss: 3.0660 - val_accuracy: 0.4895 - val_f1: 0.4878\n",
      "Score = 0.4266810751492055, F1 = 0.40147169502204816, ACC = 0.4778637560134338\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.1655 - accuracy: 0.9435 - f1: 0.9440 - val_loss: 2.8725 - val_accuracy: 0.4996 - val_f1: 0.4979\n",
      "Score = 0.44571684280453716, F1 = 0.42446256154702366, ACC = 0.4888694744485795\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 68s 209us/step - loss: 0.1576 - accuracy: 0.9462 - f1: 0.9466 - val_loss: 2.9714 - val_accuracy: 0.5004 - val_f1: 0.4997\n",
      "Score = 0.4417379106645287, F1 = 0.41792590037799277, ACC = 0.4900835073068894\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.1525 - accuracy: 0.9480 - f1: 0.9482 - val_loss: 2.9203 - val_accuracy: 0.5091 - val_f1: 0.5072\n",
      "Score = 0.4523538800340571, F1 = 0.4298811194551713, ACC = 0.4979803939366434\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.1515 - accuracy: 0.9483 - f1: 0.9484 - val_loss: 3.3370 - val_accuracy: 0.4927 - val_f1: 0.4918\n",
      "Score = 0.42620173091744395, F1 = 0.3977497083228877, ACC = 0.4839679586094218\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 69s 210us/step - loss: 0.1469 - accuracy: 0.9497 - f1: 0.9499 - val_loss: 3.3837 - val_accuracy: 0.4809 - val_f1: 0.4794\n",
      "Score = 0.41832327531419555, F1 = 0.3917468490537003, ACC = 0.4722814740855042\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.1434 - accuracy: 0.9512 - f1: 0.9514 - val_loss: 3.3891 - val_accuracy: 0.4772 - val_f1: 0.4774\n",
      "Score = 0.41693403201569534, F1 = 0.3912883929337042, ACC = 0.4690024507579196\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 68s 209us/step - loss: 0.1441 - accuracy: 0.9510 - f1: 0.9512 - val_loss: 3.5006 - val_accuracy: 0.4711 - val_f1: 0.4690\n",
      "Score = 0.4007221328327717, F1 = 0.3704222019726157, ACC = 0.46224017427611874\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.1411 - accuracy: 0.9522 - f1: 0.9523 - val_loss: 3.6397 - val_accuracy: 0.4739 - val_f1: 0.4731\n",
      "Score = 0.4015952785352339, F1 = 0.36982535587777804, ACC = 0.4660978487791595\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 67s 205us/step - loss: 0.1389 - accuracy: 0.9529 - f1: 0.9531 - val_loss: 3.6039 - val_accuracy: 0.4794 - val_f1: 0.4787\n",
      "Score = 0.41084343264485834, F1 = 0.3805102558526787, ACC = 0.4724289734047381\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 67s 203us/step - loss: 0.1383 - accuracy: 0.9532 - f1: 0.9535 - val_loss: 3.5249 - val_accuracy: 0.4799 - val_f1: 0.4796\n",
      "Score = 0.4156223221768493, F1 = 0.38671525599139844, ACC = 0.47431242625034037\n",
      "Epoch 15/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.1358 - accuracy: 0.9539 - f1: 0.9542 - val_loss: 3.4640 - val_accuracy: 0.4732 - val_f1: 0.4723\n",
      "Score = 0.4141386260550165, F1 = 0.38887089603016733, ACC = 0.46543977489334665\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_11 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.45891441570793456, 0.4342131181057111, 0.5090655350821458]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.3766 - accuracy: 0.8721 - f1: 0.8697 - val_loss: 2.4659 - val_accuracy: 0.4796 - val_f1: 0.4777\n",
      "Score = 0.4199217015230937, F1 = 0.39926269112998003, ACC = 0.4618657529272942\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 38s 114us/step - loss: 0.2153 - accuracy: 0.9264 - f1: 0.9269 - val_loss: 2.8128 - val_accuracy: 0.4776 - val_f1: 0.4749\n",
      "Score = 0.41643152702349373, F1 = 0.393874647352034, ACC = 0.4622288281746392\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.1790 - accuracy: 0.9386 - f1: 0.9390 - val_loss: 3.1186 - val_accuracy: 0.4661 - val_f1: 0.4660\n",
      "Score = 0.4050593798337456, F1 = 0.38069580223079597, ACC = 0.45452482527003724\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.1596 - accuracy: 0.9453 - f1: 0.9455 - val_loss: 3.1319 - val_accuracy: 0.4988 - val_f1: 0.4983\n",
      "Score = 0.4386449710215583, F1 = 0.4138516452517084, ACC = 0.4889829354633748\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.1499 - accuracy: 0.9489 - f1: 0.9491 - val_loss: 3.3269 - val_accuracy: 0.4740 - val_f1: 0.4719\n",
      "Score = 0.41343640543360427, F1 = 0.38877282986836054, ACC = 0.46351093764182627\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.1403 - accuracy: 0.9522 - f1: 0.9525 - val_loss: 3.4291 - val_accuracy: 0.4833 - val_f1: 0.4822\n",
      "Score = 0.4136641474032917, F1 = 0.38380378383232217, ACC = 0.47428973404738134\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.1344 - accuracy: 0.9540 - f1: 0.9542 - val_loss: 3.4057 - val_accuracy: 0.4951 - val_f1: 0.4944\n",
      "Score = 0.43355866087669026, F1 = 0.40672397297507595, ACC = 0.48804120904057363\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.1315 - accuracy: 0.9550 - f1: 0.9553 - val_loss: 3.3142 - val_accuracy: 0.4873 - val_f1: 0.4858\n",
      "Score = 0.4213331835777288, F1 = 0.3933165275748657, ACC = 0.4782154851592993\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.1270 - accuracy: 0.9573 - f1: 0.9575 - val_loss: 3.3031 - val_accuracy: 0.5011 - val_f1: 0.5008\n",
      "Score = 0.43929603478970647, F1 = 0.41231420034413524, ACC = 0.49407733502768447\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.1228 - accuracy: 0.9582 - f1: 0.9584 - val_loss: 3.4771 - val_accuracy: 0.4891 - val_f1: 0.4888\n",
      "Score = 0.42462746453322425, F1 = 0.3962774324026411, ACC = 0.48218662067713536\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.1206 - accuracy: 0.9593 - f1: 0.9594 - val_loss: 3.5250 - val_accuracy: 0.4828 - val_f1: 0.4828\n",
      "Score = 0.41916566771893576, F1 = 0.39048379251868753, ACC = 0.47739856585277296\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.1191 - accuracy: 0.9596 - f1: 0.9599 - val_loss: 3.5968 - val_accuracy: 0.4855 - val_f1: 0.4852\n",
      "Score = 0.4265916100209841, F1 = 0.400449612823761, ACC = 0.47966778614867933\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.1172 - accuracy: 0.9603 - f1: 0.9605 - val_loss: 3.5978 - val_accuracy: 0.4878 - val_f1: 0.4878\n",
      "Score = 0.4255595886371816, F1 = 0.3971880618712504, ACC = 0.48316238540437506\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.1161 - accuracy: 0.9607 - f1: 0.9607 - val_loss: 3.5772 - val_accuracy: 0.4800 - val_f1: 0.4794\n",
      "Score = 0.41002592557967443, F1 = 0.3786362557880389, ACC = 0.4737564672778433\n",
      "Epoch 15/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.1153 - accuracy: 0.9608 - f1: 0.9610 - val_loss: 3.5363 - val_accuracy: 0.4866 - val_f1: 0.4857\n",
      "Score = 0.42234463054025084, F1 = 0.3940381885609544, ACC = 0.47981528546791324\n",
      "Epoch 16/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.1142 - accuracy: 0.9611 - f1: 0.9613 - val_loss: 3.4686 - val_accuracy: 0.4805 - val_f1: 0.4801\n",
      "Score = 0.41654544370447233, F1 = 0.3888251268788361, ACC = 0.47282608695652173\n",
      "Epoch 17/30\n",
      "327818/327818 [==============================] - 38s 114us/step - loss: 0.1117 - accuracy: 0.9621 - f1: 0.9623 - val_loss: 3.6332 - val_accuracy: 0.4804 - val_f1: 0.4812\n",
      "Score = 0.419830783354758, F1 = 0.3927338875495493, ACC = 0.4748456930198784\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_12 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4421424630627243, 0.4131257480721156, 0.5010551874375965]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 72s 219us/step - loss: 0.9858 - accuracy: 0.6570 - f1: 0.6253 - val_loss: 1.6059 - val_accuracy: 0.5085 - val_f1: 0.4921\n",
      "Score = 0.43904122696066594, F1 = 0.432499122445184, ACC = 0.45232368158300806\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 72s 219us/step - loss: 0.6096 - accuracy: 0.7921 - f1: 0.7887 - val_loss: 1.7930 - val_accuracy: 0.5050 - val_f1: 0.4976\n",
      "Score = 0.44951437834019303, F1 = 0.4391278141615477, ACC = 0.47060225106653353\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 71s 217us/step - loss: 0.5169 - accuracy: 0.8241 - f1: 0.8225 - val_loss: 1.9389 - val_accuracy: 0.5076 - val_f1: 0.5016\n",
      "Score = 0.4497075063204804, F1 = 0.4350850716643792, ACC = 0.47939547971317054\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 71s 217us/step - loss: 0.4580 - accuracy: 0.8445 - f1: 0.8443 - val_loss: 2.0991 - val_accuracy: 0.5060 - val_f1: 0.5017\n",
      "Score = 0.4478098579070585, F1 = 0.4303583003420851, ACC = 0.4832418081147318\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.4152 - accuracy: 0.8591 - f1: 0.8590 - val_loss: 2.2432 - val_accuracy: 0.5003 - val_f1: 0.4958\n",
      "Score = 0.4392858261871996, F1 = 0.4200053373557524, ACC = 0.47843106108741035\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 71s 215us/step - loss: 0.3814 - accuracy: 0.8709 - f1: 0.8711 - val_loss: 2.3525 - val_accuracy: 0.4980 - val_f1: 0.4934\n",
      "Score = 0.43673168363883086, F1 = 0.41565111159944124, ACC = 0.47953163293092493\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.3533 - accuracy: 0.8805 - f1: 0.8811 - val_loss: 2.3982 - val_accuracy: 0.4963 - val_f1: 0.4936\n",
      "Score = 0.43819876317624396, F1 = 0.41758930552547413, ACC = 0.48004220749750387\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.3300 - accuracy: 0.8887 - f1: 0.8891 - val_loss: 2.4853 - val_accuracy: 0.5025 - val_f1: 0.4997\n",
      "Score = 0.4406234123078036, F1 = 0.41764279944496524, ACC = 0.48728102024144504\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.3079 - accuracy: 0.8965 - f1: 0.8973 - val_loss: 2.6384 - val_accuracy: 0.4934 - val_f1: 0.4911\n",
      "Score = 0.4311502564881211, F1 = 0.4063370687268427, ACC = 0.4815285467913225\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.2915 - accuracy: 0.9018 - f1: 0.9022 - val_loss: 2.6865 - val_accuracy: 0.4937 - val_f1: 0.4908\n",
      "Score = 0.4311884604799123, F1 = 0.4059861379912447, ACC = 0.4823568121993283\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.2775 - accuracy: 0.9072 - f1: 0.9075 - val_loss: 2.6940 - val_accuracy: 0.4907 - val_f1: 0.4873\n",
      "Score = 0.42852336654390133, F1 = 0.403405480433111, ACC = 0.4795202868294454\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 71s 218us/step - loss: 0.2628 - accuracy: 0.9118 - f1: 0.9121 - val_loss: 2.7725 - val_accuracy: 0.4876 - val_f1: 0.4843\n",
      "Score = 0.42518087601542137, F1 = 0.39980819480638424, ACC = 0.47669510756104205\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_13 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.464298377776835, 0.4429586064369165, 0.5076245801942453]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 1.1150 - accuracy: 0.6095 - f1: 0.5666 - val_loss: 1.4906 - val_accuracy: 0.5148 - val_f1: 0.4900\n",
      "Score = 0.43443670696856074, F1 = 0.43143861802081096, ACC = 0.4405237360442952\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.6818 - accuracy: 0.7683 - f1: 0.7622 - val_loss: 1.6243 - val_accuracy: 0.5231 - val_f1: 0.5105\n",
      "Score = 0.46508709011106686, F1 = 0.45929147108520524, ACC = 0.4768539529817555\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.5808 - accuracy: 0.8027 - f1: 0.8006 - val_loss: 1.7597 - val_accuracy: 0.5163 - val_f1: 0.5073\n",
      "Score = 0.4616870768860476, F1 = 0.4526073715185874, ACC = 0.4801216302078606\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.5172 - accuracy: 0.8240 - f1: 0.8228 - val_loss: 1.9068 - val_accuracy: 0.5048 - val_f1: 0.4999\n",
      "Score = 0.4507163594142837, F1 = 0.43771408659712646, ACC = 0.4771149133157847\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.4745 - accuracy: 0.8383 - f1: 0.8384 - val_loss: 1.9403 - val_accuracy: 0.5135 - val_f1: 0.5085\n",
      "Score = 0.45909825512694297, F1 = 0.4449880682003702, ACC = 0.48774621040210586\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.4393 - accuracy: 0.8516 - f1: 0.8514 - val_loss: 2.0700 - val_accuracy: 0.5071 - val_f1: 0.5014\n",
      "Score = 0.44891951372057765, F1 = 0.43191391223869813, ACC = 0.48344603794136337\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.4103 - accuracy: 0.8609 - f1: 0.8604 - val_loss: 2.1261 - val_accuracy: 0.5078 - val_f1: 0.5030\n",
      "Score = 0.4490183119008023, F1 = 0.43047986113877457, ACC = 0.4866569846600708\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.3865 - accuracy: 0.8694 - f1: 0.8694 - val_loss: 2.2433 - val_accuracy: 0.5083 - val_f1: 0.5039\n",
      "Score = 0.44716440794776324, F1 = 0.42650016221341885, ACC = 0.4891190886811292\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.3627 - accuracy: 0.8774 - f1: 0.8777 - val_loss: 2.3616 - val_accuracy: 0.5020 - val_f1: 0.4968\n",
      "Score = 0.43685072060953156, F1 = 0.41404608602921794, ACC = 0.48315103930289555\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.3442 - accuracy: 0.8838 - f1: 0.8844 - val_loss: 2.4222 - val_accuracy: 0.4992 - val_f1: 0.4960\n",
      "Score = 0.4349826992300705, F1 = 0.4108947498259388, ACC = 0.4838885358990651\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_14 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.49333775224289944, 0.47865605481623685, 0.5231460470182445]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 72s 218us/step - loss: 0.5557 - accuracy: 0.8100 - f1: 0.8063 - val_loss: 2.2291 - val_accuracy: 0.4830 - val_f1: 0.4779\n",
      "Score = 0.42387531600965156, F1 = 0.4055212644878988, ACC = 0.46113960243260416\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.3802 - accuracy: 0.8716 - f1: 0.8715 - val_loss: 2.2061 - val_accuracy: 0.5048 - val_f1: 0.4999\n",
      "Score = 0.44217561732522287, F1 = 0.4229045987370916, ACC = 0.4813016247617319\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.3393 - accuracy: 0.8857 - f1: 0.8860 - val_loss: 2.5679 - val_accuracy: 0.4909 - val_f1: 0.4889\n",
      "Score = 0.4303448346544125, F1 = 0.40738706305826705, ACC = 0.4769560678950713\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 69s 211us/step - loss: 0.3170 - accuracy: 0.8935 - f1: 0.8938 - val_loss: 2.7119 - val_accuracy: 0.4776 - val_f1: 0.4765\n",
      "Score = 0.4132255282296052, F1 = 0.38699393264758536, ACC = 0.46648361622946355\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.3052 - accuracy: 0.8981 - f1: 0.8987 - val_loss: 2.8123 - val_accuracy: 0.4889 - val_f1: 0.4856\n",
      "Score = 0.41058432703625497, F1 = 0.3787040829651896, ACC = 0.47531088318053916\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.2959 - accuracy: 0.9013 - f1: 0.9018 - val_loss: 2.7233 - val_accuracy: 0.4903 - val_f1: 0.4885\n",
      "Score = 0.4224026239853758, F1 = 0.3945438743172878, ACC = 0.47896432785694837\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 71s 215us/step - loss: 0.2923 - accuracy: 0.9029 - f1: 0.9033 - val_loss: 3.0410 - val_accuracy: 0.4637 - val_f1: 0.4615\n",
      "Score = 0.3933015573424543, F1 = 0.36325299262629657, ACC = 0.4543092493419261\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 71s 217us/step - loss: 0.2860 - accuracy: 0.9044 - f1: 0.9052 - val_loss: 3.0569 - val_accuracy: 0.4658 - val_f1: 0.4650\n",
      "Score = 0.3891760672121506, F1 = 0.3551452006297273, ACC = 0.4582690387582827\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 70s 215us/step - loss: 0.2831 - accuracy: 0.9057 - f1: 0.9063 - val_loss: 2.8022 - val_accuracy: 0.4907 - val_f1: 0.4883\n",
      "Score = 0.4212235382240471, F1 = 0.3920743207735029, ACC = 0.4804052827448489\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 69s 210us/step - loss: 0.2787 - accuracy: 0.9076 - f1: 0.9079 - val_loss: 2.9157 - val_accuracy: 0.4887 - val_f1: 0.4876\n",
      "Score = 0.43074597863402586, F1 = 0.4063986859671501, ACC = 0.4801783607152582\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_15 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4548981384047761, 0.4303366697607657, 0.5047653626214033]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 39s 120us/step - loss: 0.5901 - accuracy: 0.7991 - f1: 0.7930 - val_loss: 2.0152 - val_accuracy: 0.5205 - val_f1: 0.5168\n",
      "Score = 0.4683671937173586, F1 = 0.45470925844375365, ACC = 0.49609694109104113\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.3815 - accuracy: 0.8706 - f1: 0.8710 - val_loss: 2.3845 - val_accuracy: 0.5046 - val_f1: 0.5023\n",
      "Score = 0.4470846646934528, F1 = 0.42708527810178964, ACC = 0.4876894798947082\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.3290 - accuracy: 0.8896 - f1: 0.8898 - val_loss: 2.4929 - val_accuracy: 0.5125 - val_f1: 0.5106\n",
      "Score = 0.4560388825685475, F1 = 0.4351855299960695, ACC = 0.49837750748842696\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.3003 - accuracy: 0.8995 - f1: 0.8999 - val_loss: 2.8252 - val_accuracy: 0.5052 - val_f1: 0.5045\n",
      "Score = 0.4434375903783009, F1 = 0.41816591227366934, ACC = 0.49474675501497684\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.2836 - accuracy: 0.9055 - f1: 0.9059 - val_loss: 2.9882 - val_accuracy: 0.4936 - val_f1: 0.4925\n",
      "Score = 0.43600662705212767, F1 = 0.41221623030801646, ACC = 0.48430834165380776\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.2722 - accuracy: 0.9092 - f1: 0.9099 - val_loss: 2.9439 - val_accuracy: 0.4959 - val_f1: 0.4963\n",
      "Score = 0.44166581708564395, F1 = 0.419058918013076, ACC = 0.48756467277843335\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 39s 117us/step - loss: 0.2626 - accuracy: 0.9124 - f1: 0.9130 - val_loss: 3.1361 - val_accuracy: 0.4780 - val_f1: 0.4767\n",
      "Score = 0.4193270462484845, F1 = 0.39482093731933326, ACC = 0.4690818734682763\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.2565 - accuracy: 0.9147 - f1: 0.9149 - val_loss: 3.0742 - val_accuracy: 0.4828 - val_f1: 0.4817\n",
      "Score = 0.42579595936826575, F1 = 0.4016091934392009, ACC = 0.474902423527276\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.2521 - accuracy: 0.9160 - f1: 0.9163 - val_loss: 3.2101 - val_accuracy: 0.4853 - val_f1: 0.4850\n",
      "Score = 0.4230529288362022, F1 = 0.3957938974892859, ACC = 0.47839702278297175\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_16 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4786476951856945, 0.458015923540254, 0.5205364436779523]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 64, 0.3, 0.0001, 128, 0.45733390263744733, 0.4305017558151997, 0.5118112916401925], [1, 64, 0.3, 0.0001, 256, 0.45729219482968025, 0.4317527742659021, 0.5091449577925025], [2, 64, 0.3, 0.001, 128, 0.4824649802459078, 0.45949413828143015, 0.5291027502949986], [3, 64, 0.3, 0.001, 256, 0.4465752964194626, 0.41859629970144097, 0.5033811382409005], [4, 64, 0.5, 0.0001, 128, 0.45854363249596974, 0.4356379962592544, 0.5050490151583916], [5, 64, 0.5, 0.0001, 256, 0.4575978889066116, 0.43166696138317306, 0.5102455296360171], [6, 64, 0.5, 0.001, 128, 0.4842634673777254, 0.46674974091606053, 0.5198216392847418], [7, 64, 0.5, 0.001, 256, 0.47986203960725515, 0.4590460049330994, 0.5221248978850866], [8, 128, 0.3, 0.0001, 128, 0.449533891353607, 0.42304564330602884, 0.5033130616320233], [9, 128, 0.3, 0.0001, 256, 0.449452134700129, 0.42316950709708084, 0.5028138331669239], [10, 128, 0.3, 0.001, 128, 0.45891441570793456, 0.4342131181057111, 0.5090655350821458], [11, 128, 0.3, 0.001, 256, 0.4421424630627243, 0.4131257480721156, 0.5010551874375965], [12, 128, 0.5, 0.0001, 128, 0.464298377776835, 0.4429586064369165, 0.5076245801942453], [13, 128, 0.5, 0.0001, 256, 0.49333775224289944, 0.47865605481623685, 0.5231460470182445], [14, 128, 0.5, 0.001, 128, 0.4548981384047761, 0.4303366697607657, 0.5047653626214033], [15, 128, 0.5, 0.001, 256, 0.4786476951856945, 0.458015923540254, 0.5205364436779523]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>units</th>\n",
       "      <th>drop</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch</th>\n",
       "      <th>score</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.457334</td>\n",
       "      <td>0.430502</td>\n",
       "      <td>0.511811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.457292</td>\n",
       "      <td>0.431753</td>\n",
       "      <td>0.509145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.482465</td>\n",
       "      <td>0.459494</td>\n",
       "      <td>0.529103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.446575</td>\n",
       "      <td>0.418596</td>\n",
       "      <td>0.503381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.458544</td>\n",
       "      <td>0.435638</td>\n",
       "      <td>0.505049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.457598</td>\n",
       "      <td>0.431667</td>\n",
       "      <td>0.510246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.484263</td>\n",
       "      <td>0.466750</td>\n",
       "      <td>0.519822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.479862</td>\n",
       "      <td>0.459046</td>\n",
       "      <td>0.522125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.449534</td>\n",
       "      <td>0.423046</td>\n",
       "      <td>0.503313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.449452</td>\n",
       "      <td>0.423170</td>\n",
       "      <td>0.502814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.458914</td>\n",
       "      <td>0.434213</td>\n",
       "      <td>0.509066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.442142</td>\n",
       "      <td>0.413126</td>\n",
       "      <td>0.501055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.464298</td>\n",
       "      <td>0.442959</td>\n",
       "      <td>0.507625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.493338</td>\n",
       "      <td>0.478656</td>\n",
       "      <td>0.523146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.454898</td>\n",
       "      <td>0.430337</td>\n",
       "      <td>0.504765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.478648</td>\n",
       "      <td>0.458016</td>\n",
       "      <td>0.520536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  units  drop      lr  batch     score        f1       acc\n",
       "0    0     64   0.3  0.0001    128  0.457334  0.430502  0.511811\n",
       "1    1     64   0.3  0.0001    256  0.457292  0.431753  0.509145\n",
       "2    2     64   0.3  0.0010    128  0.482465  0.459494  0.529103\n",
       "3    3     64   0.3  0.0010    256  0.446575  0.418596  0.503381\n",
       "4    4     64   0.5  0.0001    128  0.458544  0.435638  0.505049\n",
       "5    5     64   0.5  0.0001    256  0.457598  0.431667  0.510246\n",
       "6    6     64   0.5  0.0010    128  0.484263  0.466750  0.519822\n",
       "7    7     64   0.5  0.0010    256  0.479862  0.459046  0.522125\n",
       "8    8    128   0.3  0.0001    128  0.449534  0.423046  0.503313\n",
       "9    9    128   0.3  0.0001    256  0.449452  0.423170  0.502814\n",
       "10  10    128   0.3  0.0010    128  0.458914  0.434213  0.509066\n",
       "11  11    128   0.3  0.0010    256  0.442142  0.413126  0.501055\n",
       "12  12    128   0.5  0.0001    128  0.464298  0.442959  0.507625\n",
       "13  13    128   0.5  0.0001    256  0.493338  0.478656  0.523146\n",
       "14  14    128   0.5  0.0010    128  0.454898  0.430337  0.504765\n",
       "15  15    128   0.5  0.0010    256  0.478648  0.458016  0.520536"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_14 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:58<00:00,  4.15s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:03<00:00,  4.55s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:43<00:00,  3.14s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:49<00:00,  3.53s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:47<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243006, 10, 600)\n",
      "(243006, 7)\n",
      "5832144000 13608336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.5105859788690337, 0.46471720544120465, 0.6037134885558382]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.741926</td>\n",
       "      <td>0.671588</td>\n",
       "      <td>0.705007</td>\n",
       "      <td>0.749681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.528605</td>\n",
       "      <td>0.307637</td>\n",
       "      <td>0.388927</td>\n",
       "      <td>0.944680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.262444</td>\n",
       "      <td>0.235630</td>\n",
       "      <td>0.248315</td>\n",
       "      <td>0.961906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.182117</td>\n",
       "      <td>0.474304</td>\n",
       "      <td>0.263181</td>\n",
       "      <td>0.959170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.661021</td>\n",
       "      <td>0.671147</td>\n",
       "      <td>0.666045</td>\n",
       "      <td>0.849576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.343874</td>\n",
       "      <td>0.597304</td>\n",
       "      <td>0.436468</td>\n",
       "      <td>0.854049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.617994</td>\n",
       "      <td>0.487550</td>\n",
       "      <td>0.545076</td>\n",
       "      <td>0.888365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all</td>\n",
       "      <td>0.476854</td>\n",
       "      <td>0.492166</td>\n",
       "      <td>0.464717</td>\n",
       "      <td>0.886775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class    recall  precision        f1  accuracy\n",
       "0     0  0.741926   0.671588  0.705007  0.749681\n",
       "1     1  0.528605   0.307637  0.388927  0.944680\n",
       "2     2  0.262444   0.235630  0.248315  0.961906\n",
       "3     3  0.182117   0.474304  0.263181  0.959170\n",
       "4     4  0.661021   0.671147  0.666045  0.849576\n",
       "5     5  0.343874   0.597304  0.436468  0.854049\n",
       "6     6  0.617994   0.487550  0.545076  0.888365\n",
       "7   all  0.476854   0.492166  0.464717  0.886775"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
