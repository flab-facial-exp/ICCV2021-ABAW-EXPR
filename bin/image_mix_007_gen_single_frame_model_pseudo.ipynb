{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.HIGHEST_PROTOCOL = 4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import func_proc_filepath as mFILE\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Callback(Callback):\n",
    "    def __init__(self, model, X_val, y_val, path):\n",
    "        self.model = model\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        self.path = path\n",
    "        self.best_score = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pred = self.model.predict(self.X_val)\n",
    "        f1_val = f1_score(self.y_val, np.round(pred), average='macro')\n",
    "        acc_val = accuracy_score(self.y_val, np.round(pred))\n",
    "        score = f1_val*0.67 + acc_val*0.33\n",
    "        log = \"Score = {0}, F1 = {1}, ACC = {2}\".format(score, f1_val, acc_val)\n",
    "        print(log)\n",
    "        # 以下チェックポイントなど必要なら書く\n",
    "        if score > self.best_score:\n",
    "            self.best_score = score\n",
    "            self.model.save(self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_expw_with_balance(df_data):\n",
    "    #df_data = pd.read_hdf(fp)\n",
    "    df_data.dropna(how='any', inplace=True)\n",
    "    #display(df_data)\n",
    "    \n",
    "    df_0 = df_data.loc[df_data.loc[:,\"Neutral\"]==1,:]\n",
    "    df_1 = df_data.loc[df_data.loc[:,\"Anger\"]==1,:]\n",
    "    df_2 = df_data.loc[df_data.loc[:,\"Disgust\"]==1,:]\n",
    "    df_3 = df_data.loc[df_data.loc[:,\"Fear\"]==1,:]\n",
    "    df_4 = df_data.loc[df_data.loc[:,\"Happiness\"]==1,:]\n",
    "    df_5 = df_data.loc[df_data.loc[:,\"Sadness\"]==1,:]\n",
    "    df_6 = df_data.loc[df_data.loc[:,\"Surprise\"]==1,:]\n",
    "\n",
    "    df_0 = df_0[::2]\n",
    "    df_1 = pd.concat([df_1,df_1,df_1],axis=0)\n",
    "    df_2 = pd.concat([df_2,df_2,df_2],axis=0)\n",
    "    df_3 = pd.concat([df_3,df_3,df_3,df_3,df_3,df_3,df_3,df_3,df_3,df_3,df_3],axis=0)\n",
    "    df_4 = df_4[::2]\n",
    "    df_6 = pd.concat([df_6,df_6],axis=0)\n",
    "    df_m = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6],axis=0)\n",
    "    \n",
    "    return df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_aff2_with_balance(df_data):\n",
    "    df_data.dropna(how='any', inplace=True)\n",
    "    #display(df_data)  \n",
    "    \n",
    "    df_0 = df_data.loc[df_data.loc[:,\"expr\"]==0,:]\n",
    "    df_1 = df_data.loc[df_data.loc[:,\"expr\"]==1,:]\n",
    "    df_2 = df_data.loc[df_data.loc[:,\"expr\"]==2,:]\n",
    "    df_3 = df_data.loc[df_data.loc[:,\"expr\"]==3,:]\n",
    "    df_4 = df_data.loc[df_data.loc[:,\"expr\"]==4,:]\n",
    "    df_5 = df_data.loc[df_data.loc[:,\"expr\"]==5,:]\n",
    "    df_6 = df_data.loc[df_data.loc[:,\"expr\"]==6,:]\n",
    "\n",
    "    df_0 = df_0[::2]\n",
    "    df_1 = pd.concat([df_1,df_1],axis=0)\n",
    "    df_2 = pd.concat([df_2,df_2,df_2,df_2],axis=0)\n",
    "    df_3 = pd.concat([df_3,df_3,df_3,df_3],axis=0)\n",
    "    df_4 = df_4[::3]\n",
    "    df_5 = df_5[::2]\n",
    "    df_m = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6],axis=0)\n",
    "    \n",
    "    return df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_val_with_balance(df_data):\n",
    "    df_data.dropna(how='any', inplace=True)\n",
    "    #display(df_data)\n",
    "\n",
    "    df_0 = df_data.loc[df_data.loc[:,\"expr\"]==0,:]\n",
    "    df_1 = df_data.loc[df_data.loc[:,\"expr\"]==1,:]\n",
    "    df_2 = df_data.loc[df_data.loc[:,\"expr\"]==2,:]\n",
    "    df_3 = df_data.loc[df_data.loc[:,\"expr\"]==3,:]\n",
    "    df_4 = df_data.loc[df_data.loc[:,\"expr\"]==4,:]\n",
    "    df_5 = df_data.loc[df_data.loc[:,\"expr\"]==5,:]\n",
    "    df_6 = df_data.loc[df_data.loc[:,\"expr\"]==6,:]\n",
    "\n",
    "    df_0 = df_0[::3]\n",
    "    #df_1 = pd.concat([df_1,df_1],axis=0)\n",
    "    df_2 = pd.concat([df_2,df_2],axis=0)\n",
    "    #df_3 = pd.concat([df_3,df_3,df_3,df_3],axis=0)\n",
    "    df_4 = df_4[::4]\n",
    "    df_5 = df_5[::3]\n",
    "    df_6 = df_5[::2]\n",
    "    df_m = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6],axis=0)\n",
    "    \n",
    "    return df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pseudo_label(df_data, pre_model):\n",
    "    \n",
    "    df_data.dropna(how='any', inplace=True)\n",
    "    np_x = df_data.loc[:, df_data.columns.str.contains(\"AU|pose_R|gaze|vgg-\")].values\n",
    "    pred_ = pre_model.predict(np_x)\n",
    "    pred_p = np.argmax(pred_, axis=1)\n",
    "\n",
    "    df_data[\"expr\"] = pred_p\n",
    "    df_0 = df_data.loc[((df_data.loc[:,\"valence\"]**2)<0.25)&((df_data.loc[:,\"arousal\"]**2)<0.25)&(df_data.loc[:,\"expr\"]==0),:]\n",
    "    df_1 = df_data.loc[(df_data.loc[:,\"valence\"]<0)&(df_data.loc[:,\"arousal\"]>0)&(df_data.loc[:,\"expr\"]==1),:]\n",
    "    df_2 = df_data.loc[(df_data.loc[:,\"valence\"]<0)&(df_data.loc[:,\"arousal\"]>0)&(df_data.loc[:,\"expr\"]==2),:]\n",
    "    df_3 = df_data.loc[(df_data.loc[:,\"valence\"]<0)&(df_data.loc[:,\"arousal\"]>0)&(df_data.loc[:,\"expr\"]==3),:]\n",
    "    df_4 = df_data.loc[(df_data.loc[:,\"valence\"]>0)&(df_data.loc[:,\"arousal\"]>0)&(df_data.loc[:,\"expr\"]==4),:]\n",
    "    df_5 = df_data.loc[(df_data.loc[:,\"valence\"]<0)&(df_data.loc[:,\"arousal\"]<0)&(df_data.loc[:,\"expr\"]==5),:]\n",
    "    df_6 = df_data.loc[(df_data.loc[:,\"arousal\"]>0)&(df_data.loc[:,\"expr\"]==6),:]\n",
    "    \n",
    "    df_data = None\n",
    "    \n",
    "    \"\"\"\n",
    "    ・0: V<0.5, A<0.5\n",
    "　　・1: V<0,   A>0\n",
    "　　・2: V<0,   A>0\n",
    "　　・3: V<0,   A>0\n",
    "　　・4: V>0,   A>0\n",
    "　　・5: V<0,   A<0\n",
    "　　・6:        A>0\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"balance\", len(df_0), len(df_1), len(df_2), len(df_3), len(df_4), len(df_5), len(df_6))\n",
    "    # 212377 10569 14561 1531 213667 210 67275\n",
    "    df_0 = df_0[::10]\n",
    "    #df_1 = df_1[::1]\n",
    "    #df_2 = df_2[::1]\n",
    "    df_3 = pd.concat([df_3,df_3,df_3,df_3,df_3],axis=0)\n",
    "    df_4 = df_4[::20]\n",
    "    df_5 = pd.concat([df_5,df_5,df_5,df_5,df_5,df_5,df_5,df_5,df_5,df_5,\n",
    "                      df_5,df_5,df_5,df_5,df_5,df_5,df_5,df_5,df_5,df_5],axis=0)\n",
    "    df_6 = df_6[::5]\n",
    "    \n",
    "    df_out = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6], axis=0)\n",
    "    df_out.drop([\"valence\", \"arousal\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y: after one hot encoding\n",
    "def create_model(np_train_x, np_train_y, np_val_x, np_val_y, n_class, drop=0.5, lr=1e-4, batch=128, \n",
    "                 model_path=\"\"):\n",
    "    \n",
    "    # ** fix random seed **\n",
    "    FIX_SEED = 49\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(FIX_SEED)\n",
    "    random.seed(FIX_SEED)\n",
    "    session_conf = tf.compat.v1.ConfigProto()\n",
    "    tf.compat.v1.set_random_seed(FIX_SEED)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    # *********************\n",
    "    \n",
    "    #*********************************************    \n",
    "    # モデルの定義\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(300, name='vgg_au')) #\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    adam = Adam(lr=lr)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=[\"accuracy\", f1])\n",
    "    #model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "    #model_path = dir_out + \"\\\\model_single_image_pseudo\" + footer + \".h5\"\n",
    "    #cb_early = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "    cb_early = EarlyStopping(monitor='val_f1', patience=8, verbose=0, mode='max')\n",
    "    \n",
    "    model.fit(np_train_x, np_train_y,\n",
    "              epochs=30,\n",
    "              batch_size=batch,\n",
    "              validation_data=(np_val_x, np_val_y),\n",
    "              callbacks=[F1Callback(model, np_val_x, np_val_y, model_path), cb_early])\n",
    "    \n",
    "    #score = model.evaluate(np_val_x, np_val_y_hot, batch_size=128)\n",
    "    #display(score)\n",
    "    model.summary()\n",
    "    \n",
    "    # bestモデルを読み込んで、重みやオプティマイザーを含むモデル全体を再作成\n",
    "    new_model = keras.models.load_model(model_path, custom_objects={'f1':f1})\n",
    "    \n",
    "    pred_nn = new_model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    \n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    del model\n",
    "    del new_model\n",
    "    \n",
    "    return scores_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predict data\n",
    "def eval_pred_each_class(np_true, np_pred, num_class):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    # calc\n",
    "    for i in range(num_class):\n",
    "        # i以外を0、iを1に置き換える\n",
    "        y_true_i = np.where(np_true == i, 1, 0)\n",
    "        y_pred_i = np.where(np_pred == i, 1, 0)\n",
    "\n",
    "        recall_i = recall_score(y_true_i, y_pred_i, average='binary')\n",
    "        precision_i = precision_score(y_true_i, y_pred_i, average='binary')\n",
    "        f1_i = f1_score(y_true_i, y_pred_i, average='binary')\n",
    "        acc_i = accuracy_score(y_true_i, y_pred_i)\n",
    "\n",
    "        df_reslut = pd.DataFrame({\"class\":[i], \"recall\":[recall_i], \"precision\":[precision_i], \n",
    "                                 \"f1\":[f1_i], \"accuracy\":[acc_i]})\n",
    "        #result_i = [recall_i, precision_i, f1_i, acc_i]\n",
    "\n",
    "        result.append(df_reslut)\n",
    "\n",
    "    df_out = pd.concat([x for x in result], axis=0, ignore_index=True)\n",
    "    f1_all = df_out.loc[:, \"f1\"].mean()\n",
    "    recall_all = df_out.loc[:, \"recall\"].mean()\n",
    "    precision_all = df_out.loc[:, \"precision\"].mean()\n",
    "    accuracy_all = df_out.loc[:, \"accuracy\"].mean()\n",
    "    df_all = pd.DataFrame({\"class\":[\"all\"], \"recall\":[recall_all], \"precision\":[precision_all], \n",
    "                                 \"f1\":[f1_all], \"accuracy\":[accuracy_all]})\n",
    "    df_out = pd.concat([df_out, df_all], axis=0, ignore_index=True)\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # root folder\n",
    "    dir_root = str(Path(Path().resolve()).parent)\n",
    "\n",
    "    # input: folder path including original images\n",
    "    dir_data = dir_root + \"\\\\dataset\\\\aff2_images\\\\dataset\"    \n",
    "\n",
    "    # input: expr labels\n",
    "    dir_label_train = dir_root + \"\\\\src\\\\annotations\\\\EXPR_Set\\\\Train_Set\"\n",
    "    dir_label_val = dir_root + \"\\\\src\\\\annotations\\\\EXPR_Set\\\\Validation_Set\"\n",
    "    \n",
    "    file_data_expw = dir_root + \"\\\\dataset\\\\expw_images\\\\dataset\\\\expw_with_label.h5\"\n",
    "    \n",
    "    # output: folder path\n",
    "    dir_out = dir_root + \"\\\\model_expr\\\\model_image\"\n",
    "    if os.path.isdir(dir_out) == False:\n",
    "        os.makedirs(dir_out)\n",
    "        \n",
    "    model_path_base = \"model_image_single_pseudo\"\n",
    "    model_path_base_pre = \"model_image_single\"\n",
    "        \n",
    "    # for pseudo label ***************\n",
    "    file_valid_va = dir_root + \"\\\\parameters\\\\vaid_va_list.txt\"\n",
    "    dir_valid_va = dir_root + \"\\\\parameters\\\\va_label\"\n",
    "    file_va_list = pd.read_csv(file_valid_va).loc[:, \"file\"].values.ravel()\n",
    "    file_pre_model = dir_out + \"\\\\\" + model_path_base_pre + \"_best.h5\"\n",
    "    pre_model = keras.models.load_model(file_pre_model, custom_objects={'f1':f1})\n",
    "    \n",
    "    log = \"create pseudo label\"\n",
    "    print(log)\n",
    "    df_pseudo_list = []\n",
    "    for i in tqdm(range(len(file_va_list))):\n",
    "        fp_label = dir_valid_va + \"\\\\\" + file_va_list[i]\n",
    "        df_va_label = pd.read_csv(fp_label)\n",
    "        df_va_label[\"frame\"] = df_va_label.index\n",
    "        name = os.path.splitext(os.path.basename(file_va_list[i]))[0]\n",
    "        fp_va_data = dir_data + \"\\\\\" + name + \".h5\"\n",
    "        df_va_data = pd.read_hdf(fp_va_data)\n",
    "        df_va_merge = pd.merge(df_va_label, df_va_data, on=\"frame\")\n",
    "        df_pseudo_list.append(df_va_merge)\n",
    "    df_va_merge = pd.concat([x for x in df_pseudo_list], axis=0)\n",
    "    df_va = create_pseudo_label(df_va_merge, pre_model)\n",
    "    df_pseudo_list = None\n",
    "    df_va_merge = None\n",
    "    log = \"pseudo label data: {0}\".format(df_va.shape)\n",
    "    print(log)\n",
    "    # *****\n",
    "    \n",
    "    train_list = mFILE.search_files(dir_label_train, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)    \n",
    "    val_list = mFILE.search_files(dir_label_val, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)\n",
    "    \n",
    "    len_train = len(train_list)\n",
    "    len_val = len(val_list)\n",
    "    #len_train = 75\n",
    "    #len_val = 25\n",
    "    \n",
    "    df_train_list = []\n",
    "    for i in tqdm(range(len_train)):\n",
    "        name = os.path.splitext(os.path.basename(train_list[i]))[0]\n",
    "        \n",
    "        df_label = pd.read_csv(train_list[i])\n",
    "        #display(df_label)\n",
    "        df_label = df_label.drop([\"Anger\",\"Disgust\",\"Fear\",\"Happiness\",\"Sadness\",\"Surprise\"],axis=1)\n",
    "        df_label.columns = [\"expr\"]\n",
    "        df_label[\"frame\"] = df_label.index\n",
    "        \n",
    "        df_data = pd.read_hdf(dir_data + \"\\\\\" + name + \".h5\")\n",
    "        \n",
    "        df_merge = pd.merge(df_label, df_data, on=\"frame\")\n",
    "        df_merge = df_merge.loc[df_merge.loc[:,\"expr\"]>=0,:]\n",
    "        \n",
    "        df_train_list.append(df_merge)\n",
    "\n",
    "    df_train = pd.concat([x for x in df_train_list],axis=0)\n",
    "    df_train_list = None #clear memory ***************\n",
    "    df_train = df_aff2_with_balance(df_train)\n",
    "    \n",
    "    df_expr = pd.read_hdf(file_data_expw)\n",
    "    df_expr = df_expw_with_balance(df_expr)\n",
    "    \n",
    "    #df_train = pd.concat([df_train, df_expr], axis=0)\n",
    "    df_train = pd.concat([df_train, df_expr, df_va], axis=0)\n",
    "    df_train = df_train.sample(frac=1, random_state=49)\n",
    "    \n",
    "    df_val_list = []\n",
    "    for i in tqdm(range(len_val)):\n",
    "        name = os.path.splitext(os.path.basename(val_list[i]))[0]\n",
    "        \n",
    "        df_label = pd.read_csv(val_list[i])\n",
    "        df_label = df_label.drop([\"Anger\",\"Disgust\",\"Fear\",\"Happiness\",\"Sadness\",\"Surprise\"],axis=1)\n",
    "        df_label.columns = [\"expr\"]\n",
    "        df_label[\"frame\"] = df_label.index\n",
    "        \n",
    "        df_data = pd.read_hdf(dir_data + \"\\\\\" + name + \".h5\")\n",
    "        \n",
    "        df_merge = pd.merge(df_label, df_data, on=\"frame\")\n",
    "        df_merge = df_merge.loc[df_merge.loc[:,\"expr\"]>=0,:]\n",
    "        \n",
    "        df_val_list.append(df_merge)\n",
    "    \n",
    "    df_val = pd.concat([x for x in df_val_list],axis=0)\n",
    "    df_val = df_val_with_balance(df_val)\n",
    "    df_val = df_val.sample(frac=1, random_state=49)\n",
    "        \n",
    "    #df_train.dropna(how='any', inplace=True)\n",
    "    #df_val.dropna(how='any', inplace=True)\n",
    "    df_val.fillna(0, inplace=True)\n",
    "    #display(df_train.shape)\n",
    "    #display(df_val.shape)\n",
    "    display(df_train)\n",
    "    display(df_val)\n",
    "    \n",
    "    np_train_x = df_train.loc[:, df_train.columns.str.contains(\"AU|pose_R|gaze|vgg-\")].values\n",
    "    np_train_y = df_train.loc[:, df_train.columns.str.contains(\"expr\")].astype(\"int\").values #.ravel()\n",
    "    np_val_x = df_val.loc[:, df_val.columns.str.contains(\"AU|pose_R|gaze|vgg-\")].values\n",
    "    np_val_y = df_val.loc[:, df_val.columns.str.contains(\"expr\")].astype(\"int\").values #.ravel()\n",
    "    \n",
    "    display(np_train_x.shape, np_train_y.shape)\n",
    "    display(np_val_x.shape, np_val_y.shape)\n",
    "       \n",
    "    df_train = None #clear memory ***************\n",
    "    df_val = None #clear memory ***************\n",
    "        \n",
    "    dummy = [[0],[1],[2],[3],[4],[5],[6]]\n",
    "    transformer = OneHotEncoder().fit(dummy)\n",
    "    np_train_y_hot = transformer.transform(np_train_y).toarray()\n",
    "    np_val_y_hot = transformer.transform(np_val_y).toarray()\n",
    "\n",
    "    #\\src\\annotations\\EXPR_Set\\Train_Set\n",
    "    \n",
    "    len_feat = len(np_train_x[0])\n",
    "    len_class = len(np_train_y_hot[0])\n",
    "    display(len_feat)\n",
    "    display(len_class)\n",
    "    \n",
    "    \n",
    "    # search parameter\n",
    "    score_list = []\n",
    "    #***\n",
    "    #l_units = [64, 128]\n",
    "    l_drop = [0.3, 0.5]\n",
    "    l_lr = [1e-4, 1e-3]\n",
    "    l_batch = [128, 256]\n",
    "    MAX_COUNT = len(l_drop)*len(l_lr)*len(l_batch)\n",
    "    COUNT = 0\n",
    "    \n",
    "    for _drop in l_drop:\n",
    "        for _lr in l_lr:\n",
    "            for _batch in l_batch:\n",
    "                model_path = dir_out + \"\\\\\" + model_path_base + \"_{0:02d}.h5\".format(COUNT)\n",
    "                scores = create_model(np_train_x, np_train_y_hot, np_val_x, np_val_y_hot, len_class,\n",
    "                                      drop=_drop, lr=_lr, batch=_batch, model_path=model_path)\n",
    "                param = [COUNT, _drop, _lr, _batch]\n",
    "                param.extend(scores)\n",
    "                score_list.append(param)\n",
    "                COUNT = COUNT + 1\n",
    "\n",
    "    # ******************* validation balances frames  ********************\n",
    "    \n",
    "    print(score_list)\n",
    "    \n",
    "    df_res = pd.DataFrame(score_list, columns = [\"id\", \"drop\", \"lr\", \"batch\", \"score\", \"f1\", \"acc\"])\n",
    "    display(df_res)\n",
    "    file_out = dir_out + \"\\\\res0_\" + model_path_base + \".csv\"\n",
    "    df_res.to_csv(file_out, index=False)\n",
    "    \n",
    "    best_id = df_res.loc[:,\"score\"].idxmax()\n",
    "    \n",
    "    best_path = dir_out + \"\\\\\" + model_path_base + \"_{0:02d}.h5\".format(best_id)\n",
    "    out_path = dir_out + \"\\\\\" + model_path_base + \"_best.h5\"\n",
    "    #best_path = dir_out + \"\\\\model_image_single_b2_pseudo\" + \"_{0:02d}.h5\".format(best_id)\n",
    "    #out_path = dir_out + \"\\\\model_image_single_b2_pseudo_best.h5\"\n",
    "    shutil.copy(best_path, out_path)\n",
    "\n",
    "    df_train_list = None\n",
    "    df_train = None\n",
    "    df_val = None\n",
    "    df_val_list = None\n",
    "    np_train_x = None\n",
    "    np_train_y = None\n",
    "    np_val_x = None\n",
    "    np_val_y = None\n",
    "    \n",
    "    # ******************* validation all frames  ********************\n",
    "    \n",
    "    #file_model = dir_out + \"\\\\model_image_single_pseudo_best.h5\"\n",
    "    #file_model = dir_out + \"\\\\model_image_single_best.h5\"\n",
    "    model = keras.models.load_model(out_path, custom_objects={'f1':f1})\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    #val_list = mFILE.search_files(dir_label_val, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)\n",
    "    #len_val = len(val_list)\n",
    "    \n",
    "    # ******* not interpolate ********\n",
    "    df_val_list = []\n",
    "    for i in tqdm(range(len_val)):\n",
    "        name = os.path.splitext(os.path.basename(val_list[i]))[0]\n",
    "        \n",
    "        df_label = pd.read_csv(val_list[i])\n",
    "        df_label = df_label.drop([\"Anger\",\"Disgust\",\"Fear\",\"Happiness\",\"Sadness\",\"Surprise\"],axis=1)\n",
    "        df_label.columns = [\"expr\"]\n",
    "        df_label[\"frame\"] = df_label.index\n",
    "        \n",
    "        df_data = pd.read_hdf(dir_data + \"\\\\\" + name + \".h5\")\n",
    "        \n",
    "        df_merge = pd.merge(df_label, df_data, on=\"frame\", how='outer')\n",
    "        # interpolate 20 frame back\n",
    "        #df_merge.interpolate(method=\"index\", limit=20, limit_direction='backward', inplace=True)\n",
    "        df_merge = df_merge.loc[df_merge.loc[:,\"expr\"]>=0,:]\n",
    "                \n",
    "        df_val_list.append(df_merge)\n",
    "    \n",
    "    df_val = pd.concat([x for x in df_val_list],axis=0)\n",
    "    df_val_list = None #clear memory ***************\n",
    "    df_val.fillna(0, inplace=True)\n",
    "    display(df_val)\n",
    "    \n",
    "    np_val_x = df_val.loc[:, df_val.columns.str.contains(\"AU|pose_R|gaze|vgg-\")].values\n",
    "    np_val_y = df_val.loc[:, df_val.columns.str.contains(\"expr\")].astype(\"int\").values #.ravel()\n",
    "    \n",
    "    display(np_val_x.shape, np_val_y.shape)\n",
    "       \n",
    "    dummy = [[0],[1],[2],[3],[4],[5],[6]]\n",
    "    transformer = OneHotEncoder().fit(dummy)\n",
    "    np_val_y_hot = transformer.transform(np_val_y).toarray()\n",
    "    \n",
    "    pred_nn = model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y_hot, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y_hot, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    display(\"w/o interpolate\")\n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    df_out = eval_pred_each_class(np.argmax(np_val_y_hot, axis=1), np.argmax(pred_nn, axis=1), 7)\n",
    "    display(df_out)\n",
    "    \n",
    "    file_out = dir_out + \"\\\\res1_\" + model_path_base + \".csv\"\n",
    "    df_out.to_csv(file_out, index=False)\n",
    "    \n",
    "    # ******* with interpolate ********\n",
    "    df_val_list = []\n",
    "    for i in tqdm(range(len_val)):\n",
    "        name = os.path.splitext(os.path.basename(val_list[i]))[0]\n",
    "        \n",
    "        df_label = pd.read_csv(val_list[i])\n",
    "        df_label = df_label.drop([\"Anger\",\"Disgust\",\"Fear\",\"Happiness\",\"Sadness\",\"Surprise\"],axis=1)\n",
    "        df_label.columns = [\"expr\"]\n",
    "        df_label[\"frame\"] = df_label.index\n",
    "        \n",
    "        df_data = pd.read_hdf(dir_data + \"\\\\\" + name + \".h5\")\n",
    "        \n",
    "        df_merge = pd.merge(df_label, df_data, on=\"frame\", how='outer')\n",
    "        # interpolate 30 frame back\n",
    "        df_merge.interpolate(method=\"index\", limit=30, limit_direction='backward', inplace=True)\n",
    "        df_merge = df_merge.loc[df_merge.loc[:,\"expr\"]>=0,:]\n",
    "                \n",
    "        df_val_list.append(df_merge)\n",
    "    \n",
    "    df_val = pd.concat([x for x in df_val_list],axis=0)\n",
    "    df_val_list = None #clear memory ***************\n",
    "    df_val.fillna(0, inplace=True)\n",
    "    display(df_val)\n",
    "    \n",
    "    np_val_x = df_val.loc[:, df_val.columns.str.contains(\"AU|pose_R|gaze|vgg-\")].values\n",
    "    np_val_y = df_val.loc[:, df_val.columns.str.contains(\"expr\")].astype(\"int\").values #.ravel()\n",
    "    \n",
    "    display(np_val_x.shape, np_val_y.shape)\n",
    "       \n",
    "    dummy = [[0],[1],[2],[3],[4],[5],[6]]\n",
    "    transformer = OneHotEncoder().fit(dummy)\n",
    "    np_val_y_hot = transformer.transform(np_val_y).toarray()\n",
    "    \n",
    "    pred_nn = model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y_hot, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y_hot, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    display(\"with interpolate\")\n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    df_out = eval_pred_each_class(np.argmax(np_val_y_hot, axis=1), np.argmax(pred_nn, axis=1), 7)\n",
    "    display(df_out)\n",
    "    \n",
    "    file_out = dir_out + \"\\\\res2_\" + model_path_base + \".csv\"\n",
    "    df_out.to_csv(file_out, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
