{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.HIGHEST_PROTOCOL = 4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import func_proc_filepath as mFILE\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, GRU, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.utils import Sequence\n",
    "from keras import backend as K\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Callback(Callback):\n",
    "    def __init__(self, model, X_val, y_val, path):\n",
    "        self.model = model\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        self.path = path\n",
    "        self.best_score = -1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pred = self.model.predict(self.X_val)\n",
    "        f1_val = f1_score(self.y_val, np.round(pred), average='macro')\n",
    "        acc_val = accuracy_score(self.y_val, np.round(pred))\n",
    "        score = f1_val*0.67 + acc_val*0.33\n",
    "        log = \"Score = {0}, F1 = {1}, ACC = {2}\".format(score, f1_val, acc_val)\n",
    "        print(log)\n",
    "        # 以下チェックポイントなど必要なら書く\n",
    "        if score > self.best_score:\n",
    "            self.best_score = score\n",
    "            self.model.save(self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y: after one hot encoding\n",
    "def create_gru_model(np_train_x, np_train_y, np_val_x, np_val_y, n_class, n_units=64, drop=0.5, lr=1e-4, \n",
    "                     batch=128, model_path=\"\"):\n",
    "    # ** fix random seed **\n",
    "    FIX_SEED = 49\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(FIX_SEED)\n",
    "    random.seed(FIX_SEED)\n",
    "    session_conf = tf.compat.v1.ConfigProto()\n",
    "    tf.compat.v1.set_random_seed(FIX_SEED)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    # *********************\n",
    "    \n",
    "    #*********************************************    \n",
    "    # モデルの定義\n",
    "    model = Sequential()\n",
    "    \n",
    "    n_rnn = np_train_x.shape[1]\n",
    "    n_feat = np_train_x.shape[2]\n",
    "    adam = Adam(lr=lr)\n",
    "    \n",
    "    #model.add(Bidirectional(GRU(units=n_units, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=False)))\n",
    "    #model.add(GRU(units=128, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=True))\n",
    "    #model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(GRU(units=n_units, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=False))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=[\"accuracy\", f1])\n",
    "\n",
    "    #model_path = dir_out + \"\\\\model_multi_image\" + footer + \".h5\"\n",
    "    #cb_early = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "    cb_early = EarlyStopping(monitor='val_f1', patience=8, verbose=0, mode='max')\n",
    "    \n",
    "    model.fit(np_train_x, np_train_y,\n",
    "              epochs=30,\n",
    "              batch_size=batch,\n",
    "              validation_data=(np_val_x, np_val_y),\n",
    "              callbacks=[F1Callback(model, np_val_x, np_val_y, model_path), cb_early])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # bestモデルを読み込んで、重みやオプティマイザーを含むモデル全体を再作成\n",
    "    new_model = keras.models.load_model(model_path, custom_objects={'f1':f1})\n",
    "    \n",
    "    pred_nn = new_model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    \n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    del model\n",
    "    del new_model\n",
    "    \n",
    "    return scores_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predict data\n",
    "def eval_pred_each_class(np_true, np_pred, num_class):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    # calc\n",
    "    for i in range(num_class):\n",
    "        # i以外を0、iを1に置き換える\n",
    "        y_true_i = np.where(np_true == i, 1, 0)\n",
    "        y_pred_i = np.where(np_pred == i, 1, 0)\n",
    "\n",
    "        recall_i = recall_score(y_true_i, y_pred_i, average='binary')\n",
    "        precision_i = precision_score(y_true_i, y_pred_i, average='binary')\n",
    "        f1_i = f1_score(y_true_i, y_pred_i, average='binary')\n",
    "        acc_i = accuracy_score(y_true_i, y_pred_i)\n",
    "\n",
    "        df_reslut = pd.DataFrame({\"class\":[i], \"recall\":[recall_i], \"precision\":[precision_i], \n",
    "                                 \"f1\":[f1_i], \"accuracy\":[acc_i]})\n",
    "        #result_i = [recall_i, precision_i, f1_i, acc_i]\n",
    "\n",
    "        result.append(df_reslut)\n",
    "\n",
    "    df_out = pd.concat([x for x in result], axis=0, ignore_index=True)\n",
    "    f1_all = df_out.loc[:, \"f1\"].mean()\n",
    "    recall_all = df_out.loc[:, \"recall\"].mean()\n",
    "    precision_all = df_out.loc[:, \"precision\"].mean()\n",
    "    accuracy_all = df_out.loc[:, \"accuracy\"].mean()\n",
    "    df_all = pd.DataFrame({\"class\":[\"all\"], \"recall\":[recall_all], \"precision\":[precision_all], \n",
    "                                 \"f1\":[f1_all], \"accuracy\":[accuracy_all]})\n",
    "    df_out = pd.concat([df_out, df_all], axis=0, ignore_index=True)\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_train_balance(np_x, np_y):\n",
    "    \n",
    "    ny = np_y.ravel()\n",
    "    \n",
    "    np_x0 = np_x[ny==0,:,:]\n",
    "    np_x0 = np_x0[::2,:,:]\n",
    "    \n",
    "    np_y0 = ny[ny==0]\n",
    "    np_y0 = np_y0[::2]\n",
    "    \n",
    "    np_x1 = np_x[ny==1,:,:]\n",
    "    np_x1 = np.append(np_x1, np_x1, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x1, axis=0)\n",
    "    np_x1 = None\n",
    "    \n",
    "    \n",
    "    np_y1 = ny[ny==1]\n",
    "    np_y1 = np.append(np_y1, np_y1)\n",
    "    np_y0 =  np.append(np_y0, np_y1)\n",
    "    np_y1 = None\n",
    "    \n",
    "    np_x2 = np_x[ny==2,:,:]\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x2, axis=0)\n",
    "    np_x2 = None\n",
    "    \n",
    "    np_y2 = ny[ny==2]\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y0 =  np.append(np_y0, np_y2)\n",
    "    np_y2 = None\n",
    "    \n",
    "    np_x3 = np_x[ny==3,:,:]\n",
    "    np_x3 = np.append(np_x3, np_x3, axis=0)\n",
    "    np_x3 = np.append(np_x3, np_x3, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x3, axis=0)\n",
    "    np_x3 = None\n",
    "    \n",
    "    np_y3 = ny[ny==3]\n",
    "    np_y3 = np.append(np_y3, np_y3)\n",
    "    np_y3 = np.append(np_y3, np_y3)\n",
    "    np_y0 =  np.append(np_y0, np_y3)\n",
    "    np_y3 = None\n",
    "    \n",
    "    np_x4 = np_x[ny==4,:,:]\n",
    "    np_x4 = np_x4[::3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x4, axis=0)\n",
    "    np_x4 = None\n",
    "    \n",
    "    np_y4 = ny[ny==4]\n",
    "    np_y4 = np_y4[::3]\n",
    "    np_y0 =  np.append(np_y0, np_y4)\n",
    "    np_y4 = None\n",
    "    \n",
    "    np_x5 = np_x[ny==5,:,:]\n",
    "    np_x5 = np_x5[::2,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x5, axis=0)\n",
    "    np_x5 = None\n",
    "    \n",
    "    np_y5 = ny[ny==5]\n",
    "    np_y5 = np_y5[::2]\n",
    "    np_y0 =  np.append(np_y0, np_y5)\n",
    "    np_y5 = None\n",
    "    \n",
    "    np_x6 = np_x[ny==6,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x6, axis=0)\n",
    "    np_x6 = None\n",
    "    \n",
    "    np_y6 = ny[ny==6]\n",
    "    np_y0 =  np.append(np_y0, np_y6)\n",
    "    np_y6 = None\n",
    "    \n",
    "    np_x = None\n",
    "    np_y = None\n",
    "    ny = None\n",
    "    \n",
    "    p =np.random.RandomState(seed=49).permutation(len(np_x0))\n",
    "    np_x0 = np_x0[p]\n",
    "    np_y0 = np_y0[p]\n",
    "    \n",
    "    \n",
    "    return np_x0, np_y0.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_val_balance(np_x, np_y): #::7, 1, *2, 1, ::4, ::3, ::2\n",
    "    \n",
    "    ny = np_y.ravel()\n",
    "    \n",
    "    np_x0 = np_x[ny==0,:,:]\n",
    "    np_x0 = np_x0[::3,:,:]\n",
    "    \n",
    "    np_y0 = ny[ny==0]\n",
    "    np_y0 = np_y0[::3]\n",
    "    \n",
    "    np_x1 = np_x[ny==1,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x1, axis=0)\n",
    "    np_x1 = None\n",
    "    \n",
    "    \n",
    "    np_y1 = ny[ny==1]\n",
    "    np_y0 =  np.append(np_y0, np_y1)\n",
    "    np_y1 = None\n",
    "    \n",
    "    np_x2 = np_x[ny==2,:,:]\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x2, axis=0)\n",
    "    np_x2 = None\n",
    "    \n",
    "    np_y2 = ny[ny==2]\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y0 =  np.append(np_y0, np_y2)\n",
    "    np_y2 = None\n",
    "    \n",
    "    np_x3 = np_x[ny==3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x3, axis=0)\n",
    "    np_x3 = None\n",
    "    \n",
    "    np_y3 = ny[ny==3]\n",
    "    np_y0 =  np.append(np_y0, np_y3)\n",
    "    np_y3 = None\n",
    "    \n",
    "    np_x4 = np_x[ny==4,:,:]\n",
    "    np_x4 = np_x4[::4,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x4, axis=0)\n",
    "    np_x4 = None\n",
    "    \n",
    "    np_y4 = ny[ny==4]\n",
    "    np_y4 = np_y4[::4]\n",
    "    np_y0 =  np.append(np_y0, np_y4)\n",
    "    np_y4 = None\n",
    "    \n",
    "    np_x5 = np_x[ny==5,:,:]\n",
    "    np_x5 = np_x5[::3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x5, axis=0)\n",
    "    np_x5 = None\n",
    "    \n",
    "    np_y5 = ny[ny==5]\n",
    "    np_y5 = np_y5[::3]\n",
    "    np_y0 =  np.append(np_y0, np_y5)\n",
    "    np_y5 = None\n",
    "    \n",
    "    np_x6 = np_x[ny==6,:,:]\n",
    "    np_x6 = np_x6[::2,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x6, axis=0)\n",
    "    np_x6 = None\n",
    "    \n",
    "    np_y6 = ny[ny==6]\n",
    "    np_y6 = np_y6[::2]\n",
    "    np_y0 =  np.append(np_y0, np_y6)\n",
    "    np_y6 = None\n",
    "    \n",
    "    np_x = None\n",
    "    np_y = None\n",
    "    ny = None\n",
    "    \n",
    "    #p = np.random.permutation(len(np_x0))\n",
    "    p =np.random.RandomState(seed=49).permutation(len(np_x0))\n",
    "    np_x0 = np_x0[p]\n",
    "    np_y0 = np_y0[p]\n",
    "    \n",
    "    \n",
    "    return np_x0, np_y0.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_read_separate(file_list, dir_data, pre_model, transformer, balance=0, sep_num=5, ignore_feat=False):\n",
    "    \n",
    "    step = -(-len(file_list) // sep_num)\n",
    "    \n",
    "    np_x_out_list = []\n",
    "    np_y_out_list = []\n",
    "    \n",
    "    for s in range(sep_num):\n",
    "        \n",
    "        start = step*s\n",
    "        stop = step*(s+1)\n",
    "        if stop>len(file_list):\n",
    "            stop = len(file_list)\n",
    "            \n",
    "        file_list_sep = file_list[start:stop]\n",
    "        \n",
    "        np_x_list = []\n",
    "        np_y_list = []\n",
    "\n",
    "        for i in tqdm(range(len(file_list_sep))):\n",
    "            name = os.path.splitext(os.path.basename(file_list_sep[i]))[0]\n",
    "\n",
    "            df_label = pd.read_csv(file_list_sep[i])\n",
    "            #display(df_label)\n",
    "            df_label = df_label.drop([\"Anger\",\"Disgust\",\"Fear\",\"Happiness\",\"Sadness\",\"Surprise\"],axis=1)\n",
    "            df_label.columns = [\"expr\"]\n",
    "            df_label[\"frame\"] = df_label.index\n",
    "\n",
    "            df_data = pd.read_hdf(dir_data + \"\\\\\" + name + \".h5\")\n",
    "            #display(df_data)\n",
    "\n",
    "            df_merge = pd.merge(df_label, df_data, on=\"frame\", how=\"outer\")\n",
    "            # interpolate 30 frame back\n",
    "            df_merge.interpolate(method=\"index\", limit=30, limit_direction='backward', inplace=True)\n",
    "            #df_merge.fillna(0, inplace=True)\n",
    "            #df_merge = df_merge.loc[df_merge.loc[:,\"expr\"]>=0,:]\n",
    "\n",
    "            np_x = df_merge.loc[:, df_merge.columns.str.contains(\"AU|pose_R|gaze|vgg-\")].values\n",
    "            np_y = df_merge.loc[:, df_merge.columns.str.contains(\"expr\")].values\n",
    "            pre_x = pre_model.predict(np_x)\n",
    "            \"\"\"\n",
    "            # normalize by single subject\n",
    "            np_mean_sub = np.nanmean(pre_x, axis=0)\n",
    "            np_std_sub = np.nanstd(pre_x, axis=0, ddof=1)\n",
    "            np_x_sub = (pre_x - np_mean_sub)/np_std_sub\n",
    "            df_sub = pd.DataFrame(np_x_sub)\n",
    "            df_sub.replace(np.inf, 9999, inplace=True)\n",
    "            df_sub.fillna(0, inplace=True)\n",
    "            df_sub.mask(df_sub > 5, 5, inplace=True)\n",
    "            df_sub.columns = [\"sub-\" + str(n) for n in df_sub.columns.values]\n",
    "            # ***************\n",
    "            \"\"\"\n",
    "            df = pd.DataFrame(pre_x)\n",
    "            df = pd.concat([df, df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "            #df = pd.concat([df, df_sub, df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "\n",
    "            batch_length = 90\n",
    "            feat_size = 300\n",
    "            np_x_tmp_list = []\n",
    "            np_y_tmp_list = []\n",
    "            for i in range(len(df)):\n",
    "                label = df.at[i, \"expr\"]\n",
    "                if label >= 0:         \n",
    "                    if ignore_feat==True:\n",
    "                        np_tmp = np.zeros((batch_length, feat_size))\n",
    "                        #np_tmp2 = df_feat.iloc[i-batch_length+1:i+1, :].values\n",
    "                        if i-batch_length+1 < 0:\n",
    "                            np_tmp = np.zeros((batch_length-i-1, feat_size))\n",
    "                            np_tmp2 = df.iloc[0:i+1, 0:feat_size].values\n",
    "                            np_tmp = np.append(np_tmp, np_tmp2, axis=0)\n",
    "                        else:\n",
    "                            np_tmp = df.iloc[i-batch_length+1:i+1, 0:feat_size].values\n",
    "\n",
    "                        np_tmp = np_tmp.astype(np.float32)\n",
    "                        #np_tmp = np_tmp[::5,:]\n",
    "                        np_tmp = np_tmp[np.newaxis, ::6, :]\n",
    "                        np_tmp = np.nan_to_num(np_tmp)\n",
    "\n",
    "                        np_x_tmp_list.append(np_tmp)\n",
    "                        np_y_tmp_list.append(label)\n",
    "                    else:\n",
    "                        if df.at[i,0]!=np.nan:\n",
    "                            np_tmp = np.zeros((batch_length, feat_size))\n",
    "                            #np_tmp2 = df_feat.iloc[i-batch_length+1:i+1, :].values\n",
    "                            if i-batch_length+1 < 0:\n",
    "                                np_tmp = np.zeros((batch_length-i-1, feat_size))\n",
    "                                np_tmp2 = df.iloc[0:i+1, 0:feat_size].values\n",
    "                                np_tmp = np.append(np_tmp, np_tmp2, axis=0)\n",
    "                            else:\n",
    "                                np_tmp = df.iloc[i-batch_length+1:i+1, 0:feat_size].values\n",
    "\n",
    "                            np_tmp = np_tmp.astype(np.float32)\n",
    "                            #np_tmp = np_tmp[::5,:]\n",
    "                            np_tmp = np_tmp[np.newaxis, ::6, :]\n",
    "                            np_tmp = np.nan_to_num(np_tmp)\n",
    "\n",
    "                            np_x_tmp_list.append(np_tmp)\n",
    "                            np_y_tmp_list.append(label)\n",
    "\n",
    "            if len(np_x_tmp_list) > 0:\n",
    "                np_x_tmp = np.concatenate([x for x in np_x_tmp_list], 0)\n",
    "                np_y_tmp = np.array(np_y_tmp_list)\n",
    "                np_x_list.append(np_x_tmp)\n",
    "                np_y_list.append(np_y_tmp)\n",
    "\n",
    "        # finish\n",
    "        np_data_x = np.concatenate([x for x in np_x_list], 0)\n",
    "        np_data_y = np.concatenate([x for x in np_y_list], 0).reshape(-1,1)\n",
    "        #np_data_y = np.concatenate([x for x in np_y_list], 0)\n",
    "\n",
    "        if balance == 1:\n",
    "            # balance and shuffle\n",
    "            np_data_x, np_data_y = np_train_balance(np_data_x, np_data_y)\n",
    "        elif balance == 2:\n",
    "            # balance and shuffle\n",
    "            np_data_x, np_data_y = np_val_balance(np_data_x, np_data_y)\n",
    "        \n",
    "        np_x_out_list.append(np_data_x)\n",
    "        np_y_out_list.append(np_data_y)\n",
    "        \n",
    "    np_data_x = np.concatenate([x for x in np_x_out_list], 0)\n",
    "    np_data_y = np.concatenate([x for x in np_y_out_list], 0).reshape(-1,1) \n",
    "        \n",
    "    np_data_y = transformer.transform(np_data_y).toarray()\n",
    "    \n",
    "    return np_data_x, np_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # root folder\n",
    "    dir_root = str(Path(Path().resolve()).parent)\n",
    "\n",
    "    # input: folder path including original images\n",
    "    dir_data = dir_root + \"\\\\dataset\\\\aff2_images\\\\dataset\"    \n",
    "\n",
    "    # input: expr labels\n",
    "    dir_label_train = dir_root + \"\\\\src\\\\annotations\\\\EXPR_Set\\\\Train_Set\"\n",
    "    dir_label_val = dir_root + \"\\\\src\\\\annotations\\\\EXPR_Set\\\\Validation_Set\"\n",
    "    \n",
    "    # output: folder path\n",
    "    dir_out = dir_root + \"\\\\model_expr\\\\model_image\"\n",
    "    if os.path.isdir(dir_out) == False:\n",
    "        os.makedirs(dir_out)\n",
    "    \n",
    "    model_path_base = \"model_image_multi\"\n",
    "    model_path_base_pre = \"model_image_single_pseudo\"\n",
    "    \n",
    "    # pre_model\n",
    "    file_pre_model = dir_out + \"\\\\\" + model_path_base_pre + \"_best.h5\"\n",
    "    base_model = keras.models.load_model(file_pre_model, custom_objects={'f1':f1})\n",
    "    layer_name = 'vgg_au'\n",
    "    pre_model = Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)  \n",
    "    # *****\n",
    "    \n",
    "    train_list = mFILE.search_files(dir_label_train, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)    \n",
    "    val_list = mFILE.search_files(dir_label_val, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)\n",
    "    \n",
    "    dummy = [[0],[1],[2],[3],[4],[5],[6]]\n",
    "    transformer = OneHotEncoder().fit(dummy)\n",
    "    #np_train_y_hot = transformer.transform(np_train_y).toarray()\n",
    "    #np_val_y_hot = transformer.transform(np_val_y).toarray()\n",
    "    \n",
    "    len_train = len(train_list)\n",
    "    len_val = len(val_list)\n",
    "    #len_train = 2\n",
    "    #len_val = 1\n",
    "    \n",
    "    np_train_x, np_train_y = data_read_separate(train_list, dir_data, pre_model, transformer, \n",
    "                                                balance=1, sep_num=5, ignore_feat=False)\n",
    "    \n",
    "    print(np_train_x.shape)\n",
    "    print(np_train_y.shape)\n",
    "    print(np_train_x.nbytes, np_train_y.nbytes)\n",
    "    \n",
    "    np_val_x, np_val_y = data_read_separate(val_list, dir_data, pre_model, transformer, \n",
    "                                            balance=2, sep_num=5, ignore_feat=False)\n",
    "    \n",
    "    print(np_val_x.shape)\n",
    "    print(np_val_y.shape)\n",
    "    print(np_val_x.nbytes, np_val_y.nbytes)\n",
    "    \n",
    "\n",
    "    len_feat = np_val_x.shape[2]\n",
    "    len_class = np_val_y.shape[1]\n",
    "    display(len_class)\n",
    "    \n",
    "    # search parameter\n",
    "    score_list = []\n",
    "    #***\n",
    "    \n",
    "    l_units = [64, 128]\n",
    "    l_drop = [0.3, 0.5]\n",
    "    l_lr = [1e-4, 1e-3]\n",
    "    l_batch = [128, 256]\n",
    "    MAX_COUNT = len(l_units)*len(l_drop)*len(l_lr)*len(l_batch)\n",
    "    COUNT = 0\n",
    "    \n",
    "    for _units in l_units:\n",
    "        for _drop in l_drop:\n",
    "            for _lr in l_lr:\n",
    "                for _batch in l_batch:\n",
    "                    model_path = dir_out + \"\\\\\" + model_path_base + \"_{0:02d}.h5\".format(COUNT)\n",
    "                    scores = create_gru_model(np_train_x, np_train_y, np_val_x, np_val_y, len_class,\n",
    "                                              n_units=_units, drop=_drop, lr=_lr, batch=_batch,\n",
    "                                              model_path=model_path)\n",
    "                    param = [COUNT, _units, _drop, _lr, _batch]\n",
    "                    param.extend(scores)\n",
    "                    score_list.append(param)\n",
    "                    COUNT = COUNT + 1\n",
    "        \n",
    "        \n",
    "    # ******************* validation balances frames  ********************\n",
    "    print(score_list)\n",
    "    \n",
    "    df_res = pd.DataFrame(score_list, columns = [\"id\", \"units\", \"drop\", \"lr\", \"batch\", \"score\", \"f1\", \"acc\"])\n",
    "    display(df_res)\n",
    "    file_out = dir_out + \"\\\\res0_\" + model_path_base + \".csv\"\n",
    "    df_res.to_csv(file_out, index=False)\n",
    "    \n",
    "    best_id = df_res.loc[:,\"score\"].idxmax()\n",
    "    \n",
    "    best_path = dir_out + \"\\\\\" + model_path_base + \"_{0:02d}.h5\".format(best_id)\n",
    "    out_path = dir_out + \"\\\\\" + model_path_base + \"_best.h5\"\n",
    "    #best_path = dir_out + \"\\\\model_image_multi_b2\" + \"_{0:02d}.h5\".format(best_id)\n",
    "    #out_path = dir_out + \"\\\\model_image_multi_b2_best.h5\"\n",
    "    shutil.copy(best_path, out_path)\n",
    "    \n",
    "    \n",
    "    np_x_list = None\n",
    "    np_y_list = None\n",
    "    np_train_x = None\n",
    "    np_train_y = None\n",
    "    np_val_x = None\n",
    "    np_val_y = None\n",
    "    \n",
    "    # ******************* validation all frames  ********************\n",
    "    \n",
    "    #file_model = dir_out + \"\\\\model_image_multi_best.h5\"\n",
    "    model = keras.models.load_model(out_path, custom_objects={'f1':f1})\n",
    "    model.summary()\n",
    "    # ******\n",
    "    \n",
    "    np_val_x, np_val_y = data_read_separate(val_list, dir_data, pre_model, transformer, \n",
    "                                            balance=0, sep_num=5, ignore_feat=True)\n",
    "    \n",
    "    print(np_val_x.shape)\n",
    "    print(np_val_y.shape)\n",
    "    print(np_val_x.nbytes, np_val_y.nbytes)\n",
    "\n",
    "    len_feat = np_val_x.shape[2]\n",
    "    len_class = np_val_y.shape[1]\n",
    "    display(len_class)\n",
    "    \n",
    "    pred_nn = model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    df_out = eval_pred_each_class(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), 7)\n",
    "    display(df_out)\n",
    "    \n",
    "    file_out = dir_out + \"\\\\res1_\" + model_path_base + \".csv\"\n",
    "    df_out.to_csv(file_out, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [02:11<00:00,  2.59s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [01:32<00:00,  1.81s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [01:20<00:00,  1.59s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [02:00<00:00,  2.37s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [01:56<00:00,  2.37s/it]\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(394390, 10, 300)\n",
      "(394390, 7)\n",
      "4732680000 22085840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:43<00:00,  3.09s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:48<00:00,  3.47s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:34<00:00,  2.50s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:44<00:00,  3.18s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:37<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102388, 10, 300)\n",
      "(102388, 7)\n",
      "1228656000 5733728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 77s 195us/step - loss: 0.8813 - accuracy: 0.7006 - f1: 0.6538 - val_loss: 1.6043 - val_accuracy: 0.5013 - val_f1: 0.4842\n",
      "Score = 0.39816382061062827, F1 = 0.3776528042389676, ACC = 0.439807399304606\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 77s 194us/step - loss: 0.5308 - accuracy: 0.8219 - f1: 0.8189 - val_loss: 1.7617 - val_accuracy: 0.5064 - val_f1: 0.4947\n",
      "Score = 0.41541561624909706, F1 = 0.39152944282347324, ACC = 0.4639117865374849\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 77s 195us/step - loss: 0.4612 - accuracy: 0.8446 - f1: 0.8438 - val_loss: 1.8747 - val_accuracy: 0.5065 - val_f1: 0.4984\n",
      "Score = 0.42035688830354734, F1 = 0.3945269221676457, ACC = 0.4727995468218932\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 77s 195us/step - loss: 0.4183 - accuracy: 0.8590 - f1: 0.8585 - val_loss: 1.9560 - val_accuracy: 0.5083 - val_f1: 0.5024\n",
      "Score = 0.4218769339779407, F1 = 0.3934138666572603, ACC = 0.4796655858108372\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 77s 196us/step - loss: 0.3928 - accuracy: 0.8670 - f1: 0.8671 - val_loss: 2.0375 - val_accuracy: 0.5089 - val_f1: 0.5040\n",
      "Score = 0.42211307376737184, F1 = 0.39180363074400726, ACC = 0.483650427784506\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 76s 193us/step - loss: 0.3698 - accuracy: 0.8743 - f1: 0.8747 - val_loss: 2.0716 - val_accuracy: 0.5104 - val_f1: 0.5071\n",
      "Score = 0.4285756537169876, F1 = 0.39974635601500247, ACC = 0.48710786420283625\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 75s 191us/step - loss: 0.3525 - accuracy: 0.8808 - f1: 0.8814 - val_loss: 2.0872 - val_accuracy: 0.5137 - val_f1: 0.5094\n",
      "Score = 0.43127727235464675, F1 = 0.402378767594727, ACC = 0.4899499941399383\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 76s 194us/step - loss: 0.3387 - accuracy: 0.8849 - f1: 0.8854 - val_loss: 2.1164 - val_accuracy: 0.5171 - val_f1: 0.5150\n",
      "Score = 0.43628978026024257, F1 = 0.4065553102550747, ACC = 0.4966597648161894\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 76s 193us/step - loss: 0.3248 - accuracy: 0.8898 - f1: 0.8899 - val_loss: 2.1282 - val_accuracy: 0.5117 - val_f1: 0.5105\n",
      "Score = 0.4333340346991259, F1 = 0.40409681207939624, ACC = 0.4926944563816072\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 77s 195us/step - loss: 0.3123 - accuracy: 0.8944 - f1: 0.8946 - val_loss: 2.1591 - val_accuracy: 0.5159 - val_f1: 0.5141\n",
      "Score = 0.43703356138070903, F1 = 0.4074152854119453, ACC = 0.4971676368324413\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 77s 195us/step - loss: 0.3027 - accuracy: 0.8977 - f1: 0.8985 - val_loss: 2.2125 - val_accuracy: 0.5159 - val_f1: 0.5147\n",
      "Score = 0.43922642377654564, F1 = 0.4100532285679606, ACC = 0.49845685041215765\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 77s 194us/step - loss: 0.2941 - accuracy: 0.9011 - f1: 0.9014 - val_loss: 2.2622 - val_accuracy: 0.5140 - val_f1: 0.5121\n",
      "Score = 0.43482502971462345, F1 = 0.4045711563450017, ACC = 0.49624956049537056\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 76s 193us/step - loss: 0.2857 - accuracy: 0.9037 - f1: 0.9042 - val_loss: 2.2666 - val_accuracy: 0.5170 - val_f1: 0.5157\n",
      "Score = 0.4362983227178092, F1 = 0.4043071259288059, ACC = 0.5012501465015432\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 76s 194us/step - loss: 0.2771 - accuracy: 0.9062 - f1: 0.9068 - val_loss: 2.3083 - val_accuracy: 0.5128 - val_f1: 0.5116\n",
      "Score = 0.43231866922300843, F1 = 0.4005032058969915, ACC = 0.49691370082431535\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 77s 195us/step - loss: 0.2716 - accuracy: 0.9086 - f1: 0.9091 - val_loss: 2.3449 - val_accuracy: 0.5132 - val_f1: 0.5129\n",
      "Score = 0.43391931531454075, F1 = 0.4017136577984184, ACC = 0.4993065593624253\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 76s 193us/step - loss: 0.2647 - accuracy: 0.9108 - f1: 0.9114 - val_loss: 2.3655 - val_accuracy: 0.5121 - val_f1: 0.5112\n",
      "Score = 0.43141311254303316, F1 = 0.39878603088188497, ACC = 0.4976559753096066\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 76s 194us/step - loss: 0.2583 - accuracy: 0.9130 - f1: 0.9134 - val_loss: 2.4184 - val_accuracy: 0.5103 - val_f1: 0.5101\n",
      "Score = 0.4299748441627725, F1 = 0.39686064458547715, ACC = 0.4972067039106145\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 76s 194us/step - loss: 0.2535 - accuracy: 0.9146 - f1: 0.9150 - val_loss: 2.4304 - val_accuracy: 0.5088 - val_f1: 0.5083\n",
      "Score = 0.4306379969853448, F1 = 0.39894721856011983, ACC = 0.4949798804547408\n",
      "Epoch 19/30\n",
      "394390/394390 [==============================] - 77s 195us/step - loss: 0.2496 - accuracy: 0.9158 - f1: 0.9162 - val_loss: 2.4895 - val_accuracy: 0.5102 - val_f1: 0.5097\n",
      "Score = 0.42921600284452366, F1 = 0.39571842460615264, ACC = 0.4972262374497011\n",
      "Epoch 20/30\n",
      "394390/394390 [==============================] - 77s 195us/step - loss: 0.2441 - accuracy: 0.9179 - f1: 0.9183 - val_loss: 2.5083 - val_accuracy: 0.5109 - val_f1: 0.5104\n",
      "Score = 0.4315749088246873, F1 = 0.3987004039760677, ACC = 0.4983201156385514\n",
      "Epoch 21/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.2419 - accuracy: 0.9187 - f1: 0.9190 - val_loss: 2.5329 - val_accuracy: 0.5125 - val_f1: 0.5124\n",
      "Score = 0.4305448479272219, F1 = 0.395917080557662, ACC = 0.5008497089502676\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 64)                70080     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 70,535\n",
      "Trainable params: 70,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4475165283238025, 0.4138253477409825, 0.5159198343555885]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 40s 101us/step - loss: 1.0150 - accuracy: 0.6523 - f1: 0.5853 - val_loss: 1.4927 - val_accuracy: 0.5031 - val_f1: 0.4798\n",
      "Score = 0.38584453612851777, F1 = 0.370002844974351, ACC = 0.4180079696839473\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 39s 99us/step - loss: 0.5940 - accuracy: 0.8027 - f1: 0.7960 - val_loss: 1.6399 - val_accuracy: 0.5115 - val_f1: 0.4955\n",
      "Score = 0.41294735072488264, F1 = 0.3913282652937302, ACC = 0.4568406453881314\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.5058 - accuracy: 0.8301 - f1: 0.8283 - val_loss: 1.7477 - val_accuracy: 0.5144 - val_f1: 0.5031\n",
      "Score = 0.4240433797074429, F1 = 0.4000916846232223, ACC = 0.4726725788178302\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.4612 - accuracy: 0.8446 - f1: 0.8441 - val_loss: 1.8357 - val_accuracy: 0.5146 - val_f1: 0.5055\n",
      "Score = 0.4272239113248508, F1 = 0.4016782492690786, ACC = 0.47908934640778217\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 39s 98us/step - loss: 0.4304 - accuracy: 0.8543 - f1: 0.8543 - val_loss: 1.9033 - val_accuracy: 0.5139 - val_f1: 0.5065\n",
      "Score = 0.428034268609372, F1 = 0.4016754921486307, ACC = 0.4815505723326952\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.4046 - accuracy: 0.8628 - f1: 0.8630 - val_loss: 1.9714 - val_accuracy: 0.5089 - val_f1: 0.5042\n",
      "Score = 0.4266545735558438, F1 = 0.39946230985026415, ACC = 0.48186310895808104\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 38s 98us/step - loss: 0.3870 - accuracy: 0.8689 - f1: 0.8691 - val_loss: 2.0054 - val_accuracy: 0.5125 - val_f1: 0.5081\n",
      "Score = 0.4305052160738431, F1 = 0.40279466727631685, ACC = 0.48676602726882057\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.3725 - accuracy: 0.8733 - f1: 0.8736 - val_loss: 2.0428 - val_accuracy: 0.5174 - val_f1: 0.5140\n",
      "Score = 0.43528548008633483, F1 = 0.4061290959219167, ACC = 0.4944817752080322\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 39s 98us/step - loss: 0.3581 - accuracy: 0.8787 - f1: 0.8789 - val_loss: 2.0734 - val_accuracy: 0.5127 - val_f1: 0.5099\n",
      "Score = 0.43402208576358337, F1 = 0.4062734630918411, ACC = 0.4903601984607571\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.3463 - accuracy: 0.8823 - f1: 0.8825 - val_loss: 2.1252 - val_accuracy: 0.5127 - val_f1: 0.5098\n",
      "Score = 0.4346680505380398, F1 = 0.4070932746679272, ACC = 0.4906532015470563\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 39s 99us/step - loss: 0.3369 - accuracy: 0.8863 - f1: 0.8865 - val_loss: 2.1365 - val_accuracy: 0.5164 - val_f1: 0.5151\n",
      "Score = 0.4399824322717163, F1 = 0.41178772225867893, ACC = 0.4972262374497011\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 39s 98us/step - loss: 0.3258 - accuracy: 0.8899 - f1: 0.8904 - val_loss: 2.2036 - val_accuracy: 0.5140 - val_f1: 0.5141\n",
      "Score = 0.4378994666238836, F1 = 0.40869324980198524, ACC = 0.4971969371410712\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 39s 98us/step - loss: 0.3179 - accuracy: 0.8928 - f1: 0.8932 - val_loss: 2.2248 - val_accuracy: 0.5138 - val_f1: 0.5136\n",
      "Score = 0.43918515259642654, F1 = 0.4106939625627029, ACC = 0.49703090205883504\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 38s 98us/step - loss: 0.3095 - accuracy: 0.8952 - f1: 0.8956 - val_loss: 2.2573 - val_accuracy: 0.5132 - val_f1: 0.5122\n",
      "Score = 0.43733991283651, F1 = 0.4084690281962932, ACC = 0.49595655740907135\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 38s 98us/step - loss: 0.3014 - accuracy: 0.8976 - f1: 0.8983 - val_loss: 2.3457 - val_accuracy: 0.5141 - val_f1: 0.5133\n",
      "Score = 0.43629233856935806, F1 = 0.40602035280252974, ACC = 0.49775364300503966\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.2950 - accuracy: 0.9000 - f1: 0.9005 - val_loss: 2.3371 - val_accuracy: 0.5174 - val_f1: 0.5179\n",
      "Score = 0.44205386316894824, F1 = 0.41211818406515494, ACC = 0.5028323631675587\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 39s 98us/step - loss: 0.2875 - accuracy: 0.9026 - f1: 0.9033 - val_loss: 2.3739 - val_accuracy: 0.5170 - val_f1: 0.5173\n",
      "Score = 0.43949556526029077, F1 = 0.4082517239932888, ACC = 0.5029300308629917\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.2819 - accuracy: 0.9050 - f1: 0.9054 - val_loss: 2.3899 - val_accuracy: 0.5168 - val_f1: 0.5162\n",
      "Score = 0.439256374814476, F1 = 0.4086018665973648, ACC = 0.5014943157401258\n",
      "Epoch 19/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.2773 - accuracy: 0.9061 - f1: 0.9068 - val_loss: 2.4262 - val_accuracy: 0.5191 - val_f1: 0.5189\n",
      "Score = 0.4405099827342599, F1 = 0.40874114375861736, ACC = 0.5050103527757159\n",
      "Epoch 20/30\n",
      "394390/394390 [==============================] - 39s 100us/step - loss: 0.2720 - accuracy: 0.9083 - f1: 0.9088 - val_loss: 2.4961 - val_accuracy: 0.5102 - val_f1: 0.5096\n",
      "Score = 0.431483153980805, F1 = 0.39987672251976036, ACC = 0.4956537875532289\n",
      "Epoch 21/30\n",
      "394390/394390 [==============================] - 39s 99us/step - loss: 0.2669 - accuracy: 0.9095 - f1: 0.9103 - val_loss: 2.4816 - val_accuracy: 0.5167 - val_f1: 0.5166\n",
      "Score = 0.438977326294101, F1 = 0.40716555060091014, ACC = 0.5035648708833066\n",
      "Epoch 22/30\n",
      "394390/394390 [==============================] - 40s 103us/step - loss: 0.2631 - accuracy: 0.9115 - f1: 0.9116 - val_loss: 2.5063 - val_accuracy: 0.5178 - val_f1: 0.5171\n",
      "Score = 0.43777704005555995, F1 = 0.40521052165640725, ACC = 0.503896941047779\n",
      "Epoch 23/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.2604 - accuracy: 0.9126 - f1: 0.9132 - val_loss: 2.5014 - val_accuracy: 0.5159 - val_f1: 0.5143\n",
      "Score = 0.43610598795499483, F1 = 0.4040825955982483, ACC = 0.5011231784974802\n",
      "Epoch 24/30\n",
      "394390/394390 [==============================] - 40s 100us/step - loss: 0.2559 - accuracy: 0.9140 - f1: 0.9143 - val_loss: 2.4915 - val_accuracy: 0.5217 - val_f1: 0.5211\n",
      "Score = 0.44156453971800547, F1 = 0.4089200648607833, ACC = 0.5078427159432746\n",
      "Epoch 25/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.2522 - accuracy: 0.9151 - f1: 0.9157 - val_loss: 2.5515 - val_accuracy: 0.5127 - val_f1: 0.5120\n",
      "Score = 0.43371747299944596, F1 = 0.4014749370913229, ACC = 0.4991795913583623\n",
      "Epoch 26/30\n",
      "394390/394390 [==============================] - 38s 97us/step - loss: 0.2483 - accuracy: 0.9165 - f1: 0.9169 - val_loss: 2.6073 - val_accuracy: 0.5121 - val_f1: 0.5120\n",
      "Score = 0.4321787954954044, F1 = 0.39873102714904596, ACC = 0.5000879009258897\n",
      "Epoch 27/30\n",
      "394390/394390 [==============================] - 39s 99us/step - loss: 0.2448 - accuracy: 0.9172 - f1: 0.9178 - val_loss: 2.6568 - val_accuracy: 0.5138 - val_f1: 0.5133\n",
      "Score = 0.43517844944776213, F1 = 0.40256351581046795, ACC = 0.5013966480446927\n",
      "Epoch 28/30\n",
      "394390/394390 [==============================] - 39s 98us/step - loss: 0.2410 - accuracy: 0.9187 - f1: 0.9191 - val_loss: 2.6543 - val_accuracy: 0.5134 - val_f1: 0.5129\n",
      "Score = 0.43381067628223874, F1 = 0.4006278942901112, ACC = 0.50118177911474\n",
      "Epoch 29/30\n",
      "394390/394390 [==============================] - 39s 98us/step - loss: 0.2383 - accuracy: 0.9204 - f1: 0.9208 - val_loss: 2.7278 - val_accuracy: 0.5103 - val_f1: 0.5097\n",
      "Score = 0.430694176480801, F1 = 0.39693850173551487, ACC = 0.49922842520607885\n",
      "Epoch 30/30\n",
      "394390/394390 [==============================] - 39s 98us/step - loss: 0.2348 - accuracy: 0.9211 - f1: 0.9217 - val_loss: 2.7449 - val_accuracy: 0.5118 - val_f1: 0.5118\n",
      "Score = 0.43233470173763044, F1 = 0.3982902532525165, ACC = 0.5014552486619526\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 64)                70080     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 70,535\n",
      "Trainable params: 70,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4483078366067398, 0.4142607776227693, 0.5174336836348009]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 77s 196us/step - loss: 0.4954 - accuracy: 0.8325 - f1: 0.8269 - val_loss: 2.0163 - val_accuracy: 0.5173 - val_f1: 0.5124\n",
      "Score = 0.4407626715459993, F1 = 0.41623782891785616, ACC = 0.49055553385162326\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 76s 194us/step - loss: 0.3633 - accuracy: 0.8770 - f1: 0.8773 - val_loss: 2.2300 - val_accuracy: 0.5076 - val_f1: 0.5029\n",
      "Score = 0.4296322612157798, F1 = 0.403348601972381, ACC = 0.4829960542251045\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 76s 194us/step - loss: 0.3355 - accuracy: 0.8861 - f1: 0.8865 - val_loss: 2.1590 - val_accuracy: 0.5139 - val_f1: 0.5112\n",
      "Score = 0.4400611397127746, F1 = 0.4134974710322216, ACC = 0.4939934367308669\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 76s 193us/step - loss: 0.3180 - accuracy: 0.8921 - f1: 0.8927 - val_loss: 2.4484 - val_accuracy: 0.4867 - val_f1: 0.4847\n",
      "Score = 0.41474719728006093, F1 = 0.38794375441488416, ACC = 0.46916630855178343\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 76s 193us/step - loss: 0.3093 - accuracy: 0.8954 - f1: 0.8962 - val_loss: 2.5580 - val_accuracy: 0.4976 - val_f1: 0.4940\n",
      "Score = 0.4138796381030591, F1 = 0.38078008188482926, ACC = 0.48108176739461656\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 78s 198us/step - loss: 0.3017 - accuracy: 0.8985 - f1: 0.8991 - val_loss: 2.4247 - val_accuracy: 0.4996 - val_f1: 0.4975\n",
      "Score = 0.4245959430330327, F1 = 0.3957691726826976, ACC = 0.4831230222291675\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 77s 196us/step - loss: 0.2983 - accuracy: 0.8993 - f1: 0.8998 - val_loss: 2.4805 - val_accuracy: 0.4920 - val_f1: 0.4882\n",
      "Score = 0.41694886096238337, F1 = 0.3893200517349646, ACC = 0.47304371606047585\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 76s 191us/step - loss: 0.2941 - accuracy: 0.9010 - f1: 0.9015 - val_loss: 2.5541 - val_accuracy: 0.5021 - val_f1: 0.5016\n",
      "Score = 0.42414312180184555, F1 = 0.3924715984535175, ACC = 0.4884459116302692\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 76s 193us/step - loss: 0.2927 - accuracy: 0.9017 - f1: 0.9023 - val_loss: 2.5512 - val_accuracy: 0.4951 - val_f1: 0.4943\n",
      "Score = 0.42033537352056455, F1 = 0.39049247585601454, ACC = 0.48092549908192367\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 64)                70080     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 70,535\n",
      "Trainable params: 70,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4543564594874191, 0.4233462989482481, 0.5173164824002813]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.5281 - accuracy: 0.8217 - f1: 0.8131 - val_loss: 1.9817 - val_accuracy: 0.5165 - val_f1: 0.5105\n",
      "Score = 0.4392541675404831, F1 = 0.41538137494737565, ACC = 0.48772317068406457\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.3626 - accuracy: 0.8774 - f1: 0.8777 - val_loss: 2.0801 - val_accuracy: 0.5169 - val_f1: 0.5131\n",
      "Score = 0.4392991590442224, F1 = 0.413764851994372, ACC = 0.4911415400242216\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 43s 108us/step - loss: 0.3255 - accuracy: 0.8895 - f1: 0.8902 - val_loss: 2.3113 - val_accuracy: 0.5190 - val_f1: 0.5159\n",
      "Score = 0.43214388117477076, F1 = 0.3988376626709757, ACC = 0.49976559753096067\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.3063 - accuracy: 0.8965 - f1: 0.8968 - val_loss: 2.3298 - val_accuracy: 0.4986 - val_f1: 0.4952\n",
      "Score = 0.41583938535977893, F1 = 0.38492213389362095, ACC = 0.47861077470016017\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 43s 108us/step - loss: 0.2947 - accuracy: 0.9001 - f1: 0.9006 - val_loss: 2.4687 - val_accuracy: 0.5189 - val_f1: 0.5148\n",
      "Score = 0.43192717921138846, F1 = 0.3978070836352621, ACC = 0.5012013126538266\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.2844 - accuracy: 0.9037 - f1: 0.9042 - val_loss: 2.6299 - val_accuracy: 0.4920 - val_f1: 0.4892\n",
      "Score = 0.4090721108324006, F1 = 0.3761590427152994, ACC = 0.47589561276712117\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 43s 108us/step - loss: 0.2805 - accuracy: 0.9051 - f1: 0.9058 - val_loss: 2.5497 - val_accuracy: 0.5053 - val_f1: 0.5041\n",
      "Score = 0.4230096837187616, F1 = 0.38972159016705776, ACC = 0.49059460092979645\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.2746 - accuracy: 0.9073 - f1: 0.9080 - val_loss: 2.6465 - val_accuracy: 0.4869 - val_f1: 0.4847\n",
      "Score = 0.4038349154991007, F1 = 0.371002538895386, ACC = 0.470494589209673\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 41s 105us/step - loss: 0.2693 - accuracy: 0.9096 - f1: 0.9101 - val_loss: 2.6364 - val_accuracy: 0.4901 - val_f1: 0.4877\n",
      "Score = 0.4095632506787806, F1 = 0.3778205134594682, ACC = 0.47401062624526313\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.2690 - accuracy: 0.9096 - f1: 0.9100 - val_loss: 2.6730 - val_accuracy: 0.4902 - val_f1: 0.4888\n",
      "Score = 0.4065795372829865, F1 = 0.3727129820969345, ACC = 0.4753389069031527\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 42s 108us/step - loss: 0.2654 - accuracy: 0.9112 - f1: 0.9117 - val_loss: 2.7623 - val_accuracy: 0.5017 - val_f1: 0.5003\n",
      "Score = 0.4150818587911219, F1 = 0.37898580929063785, ACC = 0.48836777747392274\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 64)                70080     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 70,535\n",
      "Trainable params: 70,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.452456819711919, 0.4207322986290947, 0.5168672110012892]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 78s 199us/step - loss: 1.2411 - accuracy: 0.5613 - f1: 0.4876 - val_loss: 1.5099 - val_accuracy: 0.5004 - val_f1: 0.4782\n",
      "Score = 0.38703192152952737, F1 = 0.37104867672758474, ACC = 0.4194827518849865\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 79s 201us/step - loss: 0.7966 - accuracy: 0.7311 - f1: 0.7171 - val_loss: 1.6351 - val_accuracy: 0.5119 - val_f1: 0.4964\n",
      "Score = 0.4146991894168658, F1 = 0.3938371189431314, ACC = 0.45705551431808417\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 78s 199us/step - loss: 0.6971 - accuracy: 0.7671 - f1: 0.7605 - val_loss: 1.7070 - val_accuracy: 0.5230 - val_f1: 0.5110\n",
      "Score = 0.433658501253447, F1 = 0.4121095205644133, ACC = 0.47740946204633355\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 78s 198us/step - loss: 0.6403 - accuracy: 0.7864 - f1: 0.7818 - val_loss: 1.7601 - val_accuracy: 0.5216 - val_f1: 0.5110\n",
      "Score = 0.43607221606890556, F1 = 0.41405245803150753, ACC = 0.48077899753877407\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 77s 196us/step - loss: 0.6057 - accuracy: 0.7979 - f1: 0.7951 - val_loss: 1.8470 - val_accuracy: 0.5178 - val_f1: 0.5090\n",
      "Score = 0.4333204934396637, F1 = 0.4096615899236718, ACC = 0.48135523694182913\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.5781 - accuracy: 0.8077 - f1: 0.8050 - val_loss: 1.8354 - val_accuracy: 0.5205 - val_f1: 0.5126\n",
      "Score = 0.43480640606493026, F1 = 0.40979161364199157, ACC = 0.48559401492362386\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 77s 196us/step - loss: 0.5578 - accuracy: 0.8147 - f1: 0.8126 - val_loss: 1.9014 - val_accuracy: 0.5205 - val_f1: 0.5132\n",
      "Score = 0.4365508371812531, F1 = 0.41060573675719547, ACC = 0.4892272531937336\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.5403 - accuracy: 0.8199 - f1: 0.8188 - val_loss: 1.9535 - val_accuracy: 0.5155 - val_f1: 0.5086\n",
      "Score = 0.42820369658434204, F1 = 0.39985504489911666, ACC = 0.4857600500058601\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 77s 196us/step - loss: 0.5210 - accuracy: 0.8267 - f1: 0.8255 - val_loss: 1.9891 - val_accuracy: 0.5145 - val_f1: 0.5078\n",
      "Score = 0.43188835034051043, F1 = 0.40560948453416273, ACC = 0.48524241122006484\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 78s 199us/step - loss: 0.5092 - accuracy: 0.8311 - f1: 0.8299 - val_loss: 2.0178 - val_accuracy: 0.5154 - val_f1: 0.5086\n",
      "Score = 0.429067682293065, F1 = 0.40032198057582447, ACC = 0.48743016759776536\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.4959 - accuracy: 0.8360 - f1: 0.8347 - val_loss: 2.0267 - val_accuracy: 0.5165 - val_f1: 0.5100\n",
      "Score = 0.43330007780042123, F1 = 0.40569613110313074, ACC = 0.4893444544282533\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.4859 - accuracy: 0.8390 - f1: 0.8382 - val_loss: 2.0663 - val_accuracy: 0.5197 - val_f1: 0.5134\n",
      "Score = 0.4344583002696508, F1 = 0.4055535374657508, ACC = 0.4931437277805993\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 78s 198us/step - loss: 0.4746 - accuracy: 0.8429 - f1: 0.8422 - val_loss: 2.0888 - val_accuracy: 0.5218 - val_f1: 0.5172\n",
      "Score = 0.4388264935606721, F1 = 0.40980267368508805, ACC = 0.49775364300503966\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 78s 199us/step - loss: 0.4656 - accuracy: 0.8457 - f1: 0.8451 - val_loss: 2.0741 - val_accuracy: 0.5200 - val_f1: 0.5143\n",
      "Score = 0.4384504473162999, F1 = 0.41077114913509155, ACC = 0.4946478102902684\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.4553 - accuracy: 0.8497 - f1: 0.8492 - val_loss: 2.1376 - val_accuracy: 0.5185 - val_f1: 0.5138\n",
      "Score = 0.4351896408706859, F1 = 0.4049421741567748, ACC = 0.4966011641989296\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 77s 196us/step - loss: 0.4485 - accuracy: 0.8518 - f1: 0.8514 - val_loss: 2.1706 - val_accuracy: 0.5120 - val_f1: 0.5088\n",
      "Score = 0.43124966930444436, F1 = 0.4012022913824359, ACC = 0.49225495175215844\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.4404 - accuracy: 0.8550 - f1: 0.8546 - val_loss: 2.2075 - val_accuracy: 0.5148 - val_f1: 0.5111\n",
      "Score = 0.4369709198254351, F1 = 0.4086542986189299, ACC = 0.4944622416689456\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 79s 199us/step - loss: 0.4337 - accuracy: 0.8573 - f1: 0.8571 - val_loss: 2.1990 - val_accuracy: 0.5155 - val_f1: 0.5117\n",
      "Score = 0.4402134311188374, F1 = 0.4129262288986104, ACC = 0.49561472047505567\n",
      "Epoch 19/30\n",
      "394390/394390 [==============================] - 78s 198us/step - loss: 0.4272 - accuracy: 0.8593 - f1: 0.8592 - val_loss: 2.2088 - val_accuracy: 0.5204 - val_f1: 0.5174\n",
      "Score = 0.4459643767654374, F1 = 0.4182482119269399, ACC = 0.502236590225417\n",
      "Epoch 20/30\n",
      "394390/394390 [==============================] - 77s 196us/step - loss: 0.4219 - accuracy: 0.8613 - f1: 0.8614 - val_loss: 2.3001 - val_accuracy: 0.5131 - val_f1: 0.5101\n",
      "Score = 0.4380218864677591, F1 = 0.40960716174850414, ACC = 0.49571238817048874\n",
      "Epoch 21/30\n",
      "394390/394390 [==============================] - 77s 196us/step - loss: 0.4166 - accuracy: 0.8630 - f1: 0.8629 - val_loss: 2.2654 - val_accuracy: 0.5169 - val_f1: 0.5144\n",
      "Score = 0.44364141418364433, F1 = 0.41591638122580504, ACC = 0.49993163261319684\n",
      "Epoch 22/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.4097 - accuracy: 0.8658 - f1: 0.8657 - val_loss: 2.2699 - val_accuracy: 0.5161 - val_f1: 0.5125\n",
      "Score = 0.4430181006270155, F1 = 0.4155633222963813, ACC = 0.49875962026800014\n",
      "Epoch 23/30\n",
      "394390/394390 [==============================] - 79s 200us/step - loss: 0.4057 - accuracy: 0.8672 - f1: 0.8672 - val_loss: 2.2688 - val_accuracy: 0.5181 - val_f1: 0.5150\n",
      "Score = 0.4467876119908002, F1 = 0.4202081169801563, ACC = 0.5007520412548345\n",
      "Epoch 24/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.4018 - accuracy: 0.8685 - f1: 0.8683 - val_loss: 2.2935 - val_accuracy: 0.5207 - val_f1: 0.5185\n",
      "Score = 0.44399235667060255, F1 = 0.41368857087948224, ACC = 0.5055182247919678\n",
      "Epoch 25/30\n",
      "394390/394390 [==============================] - 78s 198us/step - loss: 0.3975 - accuracy: 0.8699 - f1: 0.8699 - val_loss: 2.3065 - val_accuracy: 0.5173 - val_f1: 0.5144\n",
      "Score = 0.44144360135059546, F1 = 0.4117124478656367, ACC = 0.5018068523655116\n",
      "Epoch 26/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.3911 - accuracy: 0.8720 - f1: 0.8721 - val_loss: 2.3171 - val_accuracy: 0.5157 - val_f1: 0.5134\n",
      "Score = 0.44073364228512046, F1 = 0.4108885218925624, ACC = 0.5013282806578896\n",
      "Epoch 27/30\n",
      "394390/394390 [==============================] - 78s 198us/step - loss: 0.3884 - accuracy: 0.8730 - f1: 0.8732 - val_loss: 2.3272 - val_accuracy: 0.5113 - val_f1: 0.5082\n",
      "Score = 0.4390725155085373, F1 = 0.41133401124269053, ACC = 0.4953900847755596\n",
      "Epoch 28/30\n",
      "394390/394390 [==============================] - 77s 196us/step - loss: 0.3860 - accuracy: 0.8738 - f1: 0.8741 - val_loss: 2.2738 - val_accuracy: 0.5186 - val_f1: 0.5158\n",
      "Score = 0.44378842441671873, F1 = 0.4143559150643673, ACC = 0.50354533734422\n",
      "Epoch 29/30\n",
      "394390/394390 [==============================] - 78s 197us/step - loss: 0.3800 - accuracy: 0.8759 - f1: 0.8759 - val_loss: 2.3575 - val_accuracy: 0.5189 - val_f1: 0.5176\n",
      "Score = 0.44174473592627145, F1 = 0.40990096819326244, ACC = 0.5063972340508653\n",
      "Epoch 30/30\n",
      "394390/394390 [==============================] - 77s 195us/step - loss: 0.3800 - accuracy: 0.8760 - f1: 0.8762 - val_loss: 2.3828 - val_accuracy: 0.5149 - val_f1: 0.5125\n",
      "Score = 0.43890100556962575, F1 = 0.40835528414685435, ACC = 0.5009180763370708\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 64)                70080     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 70,535\n",
      "Trainable params: 70,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.45718984362122483, 0.42719039061669956, 0.5180978239637457]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 1.3874 - accuracy: 0.5048 - f1: 0.4114 - val_loss: 1.4687 - val_accuracy: 0.5009 - val_f1: 0.4632\n",
      "Score = 0.3609490969333065, F1 = 0.347868659643641, ACC = 0.38750634840020315\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.8880 - accuracy: 0.6984 - f1: 0.6737 - val_loss: 1.5592 - val_accuracy: 0.5111 - val_f1: 0.4928\n",
      "Score = 0.4057083114207236, F1 = 0.38579603530009415, ACC = 0.4461362659686682\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 41s 105us/step - loss: 0.7596 - accuracy: 0.7453 - f1: 0.7344 - val_loss: 1.6309 - val_accuracy: 0.5232 - val_f1: 0.5081\n",
      "Score = 0.42877191195829056, F1 = 0.40827485207841885, ACC = 0.47038715474469667\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.6977 - accuracy: 0.7668 - f1: 0.7603 - val_loss: 1.6660 - val_accuracy: 0.5248 - val_f1: 0.5105\n",
      "Score = 0.433955279845501, F1 = 0.4133895004140112, ACC = 0.4757100441457983\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 41s 105us/step - loss: 0.6563 - accuracy: 0.7804 - f1: 0.7757 - val_loss: 1.7079 - val_accuracy: 0.5315 - val_f1: 0.5207\n",
      "Score = 0.44619809759177986, F1 = 0.42501906438760545, ACC = 0.4891979528851037\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.6262 - accuracy: 0.7916 - f1: 0.7878 - val_loss: 1.7317 - val_accuracy: 0.5299 - val_f1: 0.5206\n",
      "Score = 0.4464466533579531, F1 = 0.4245722584096856, ACC = 0.4908583037074657\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.6023 - accuracy: 0.7997 - f1: 0.7969 - val_loss: 1.7729 - val_accuracy: 0.5301 - val_f1: 0.5199\n",
      "Score = 0.44696943364228825, F1 = 0.4253813904813735, ACC = 0.4907997030902059\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.5829 - accuracy: 0.8055 - f1: 0.8032 - val_loss: 1.8143 - val_accuracy: 0.5288 - val_f1: 0.5185\n",
      "Score = 0.44407743077862466, F1 = 0.42125738823407216, ACC = 0.49040903230847366\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.5644 - accuracy: 0.8127 - f1: 0.8103 - val_loss: 1.8351 - val_accuracy: 0.5250 - val_f1: 0.5172\n",
      "Score = 0.44242277744532776, F1 = 0.4182249280768125, ACC = 0.49155174434504045\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.5510 - accuracy: 0.8171 - f1: 0.8149 - val_loss: 1.8605 - val_accuracy: 0.5281 - val_f1: 0.5219\n",
      "Score = 0.44657291048862224, F1 = 0.42162425691077743, ACC = 0.4972262374497011\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 41s 104us/step - loss: 0.5376 - accuracy: 0.8215 - f1: 0.8202 - val_loss: 1.8727 - val_accuracy: 0.5283 - val_f1: 0.5199\n",
      "Score = 0.4433829257839648, F1 = 0.417753027919675, ACC = 0.49541938508418953\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.5267 - accuracy: 0.8254 - f1: 0.8238 - val_loss: 1.8807 - val_accuracy: 0.5285 - val_f1: 0.5208\n",
      "Score = 0.44788875089153646, F1 = 0.4238720172181242, ACC = 0.4966499980466461\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.5161 - accuracy: 0.8294 - f1: 0.8284 - val_loss: 1.9105 - val_accuracy: 0.5282 - val_f1: 0.5222\n",
      "Score = 0.44600754401248033, F1 = 0.41994821012067407, ACC = 0.498915888580693\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 42s 105us/step - loss: 0.5052 - accuracy: 0.8321 - f1: 0.8311 - val_loss: 1.9516 - val_accuracy: 0.5262 - val_f1: 0.5209\n",
      "Score = 0.44466473462520495, F1 = 0.4178574280335656, ACC = 0.49909169043247253\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 42s 105us/step - loss: 0.4953 - accuracy: 0.8357 - f1: 0.8349 - val_loss: 1.9784 - val_accuracy: 0.5252 - val_f1: 0.5198\n",
      "Score = 0.44522790585096494, F1 = 0.4191646004497466, ACC = 0.4981443137867719\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 42s 105us/step - loss: 0.4875 - accuracy: 0.8382 - f1: 0.8377 - val_loss: 1.9827 - val_accuracy: 0.5270 - val_f1: 0.5201\n",
      "Score = 0.44655505644345217, F1 = 0.42127049518880444, ACC = 0.4978903777786459\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.4774 - accuracy: 0.8422 - f1: 0.8413 - val_loss: 1.9987 - val_accuracy: 0.5224 - val_f1: 0.5171\n",
      "Score = 0.4434699225835641, F1 = 0.4177385589362729, ACC = 0.49571238817048874\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 41s 105us/step - loss: 0.4713 - accuracy: 0.8443 - f1: 0.8437 - val_loss: 2.0703 - val_accuracy: 0.5153 - val_f1: 0.5110\n",
      "Score = 0.43688709697397055, F1 = 0.41044857875967994, ACC = 0.49056530062116654\n",
      "Epoch 19/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.4655 - accuracy: 0.8463 - f1: 0.8458 - val_loss: 2.0791 - val_accuracy: 0.5205 - val_f1: 0.5148\n",
      "Score = 0.44137430829494795, F1 = 0.41474547037204, ACC = 0.49543891862327616\n",
      "Epoch 20/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.4564 - accuracy: 0.8490 - f1: 0.8488 - val_loss: 2.1193 - val_accuracy: 0.5117 - val_f1: 0.5080\n",
      "Score = 0.4341542027654713, F1 = 0.40703348096341563, ACC = 0.48921748642419033\n",
      "Epoch 21/30\n",
      "394390/394390 [==============================] - 41s 103us/step - loss: 0.4509 - accuracy: 0.8513 - f1: 0.8508 - val_loss: 2.0969 - val_accuracy: 0.5184 - val_f1: 0.5140\n",
      "Score = 0.43975289256215344, F1 = 0.41244089885261975, ACC = 0.49520451615423683\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 64)                70080     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 70,535\n",
      "Trainable params: 70,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.46755872461649395, 0.43752872007554494, 0.5285287338359964]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 70s 178us/step - loss: 0.7213 - accuracy: 0.7564 - f1: 0.7437 - val_loss: 1.8079 - val_accuracy: 0.5234 - val_f1: 0.5126\n",
      "Score = 0.4386652737886999, F1 = 0.41652283839053844, ACC = 0.4836211274758761\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 70s 177us/step - loss: 0.5511 - accuracy: 0.8160 - f1: 0.8143 - val_loss: 1.9068 - val_accuracy: 0.5223 - val_f1: 0.5149acy:  - ETA: 2s - l\n",
      "Score = 0.4427227018755233, F1 = 0.418638902991067, ACC = 0.49162011173184356\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 71s 180us/step - loss: 0.5193 - accuracy: 0.8280 - f1: 0.8272 - val_loss: 2.0025 - val_accuracy: 0.5358 - val_f1: 0.5305\n",
      "Score = 0.4597509830195853, F1 = 0.4344428721155128, ACC = 0.5111341172793686\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 69s 176us/step - loss: 0.4973 - accuracy: 0.8367 - f1: 0.8358 - val_loss: 2.1425 - val_accuracy: 0.5007 - val_f1: 0.4912\n",
      "Score = 0.4078573955955386, F1 = 0.37692446205852026, ACC = 0.4706606242919092\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 69s 175us/step - loss: 0.4890 - accuracy: 0.8389 - f1: 0.8385 - val_loss: 2.1445 - val_accuracy: 0.4978 - val_f1: 0.4895\n",
      "Score = 0.4160142639956914, F1 = 0.38991186674147993, ACC = 0.46901004023909054\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 70s 176us/step - loss: 0.4821 - accuracy: 0.8415 - f1: 0.8409 - val_loss: 2.0324 - val_accuracy: 0.5245 - val_f1: 0.5181\n",
      "Score = 0.44848543247503003, F1 = 0.42517147911242764, ACC = 0.4958198226354651\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 70s 177us/step - loss: 0.4798 - accuracy: 0.8428 - f1: 0.8423 - val_loss: 2.2451 - val_accuracy: 0.5092 - val_f1: 0.5055\n",
      "Score = 0.433458732825786, F1 = 0.4064476529806515, ACC = 0.4882994100871196\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 70s 178us/step - loss: 0.4760 - accuracy: 0.8442 - f1: 0.8435 - val_loss: 2.3586 - val_accuracy: 0.5044 - val_f1: 0.4982\n",
      "Score = 0.4194746880502249, F1 = 0.3888326517987245, ACC = 0.48168730710630153\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 70s 177us/step - loss: 0.4725 - accuracy: 0.8453 - f1: 0.8453 - val_loss: 2.1157 - val_accuracy: 0.5356 - val_f1: 0.5303\n",
      "Score = 0.46670866626803065, F1 = 0.4441058992140975, ACC = 0.5125991327108645\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 69s 176us/step - loss: 0.4734 - accuracy: 0.8455 - f1: 0.8450 - val_loss: 2.2241 - val_accuracy: 0.5353 - val_f1: 0.5313\n",
      "Score = 0.46067778529986464, F1 = 0.43360851932395494, ACC = 0.5156365980388327\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 70s 177us/step - loss: 0.4723 - accuracy: 0.8456 - f1: 0.8448 - val_loss: 2.1355 - val_accuracy: 0.5347 - val_f1: 0.5310\n",
      "Score = 0.46601824579447715, F1 = 0.4423682776258896, ACC = 0.5140348478337305\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 70s 176us/step - loss: 0.4687 - accuracy: 0.8469 - f1: 0.8461 - val_loss: 2.2744 - val_accuracy: 0.5112 - val_f1: 0.5060\n",
      "Score = 0.4331962209459486, F1 = 0.40543528990707556, ACC = 0.48955932335820607\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 70s 178us/step - loss: 0.4709 - accuracy: 0.8459 - f1: 0.8456 - val_loss: 2.0996 - val_accuracy: 0.5236 - val_f1: 0.5193\n",
      "Score = 0.456256919034969, F1 = 0.43281167257462555, ACC = 0.5038578739696058\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 71s 180us/step - loss: 0.4687 - accuracy: 0.8476 - f1: 0.8474 - val_loss: 2.3310 - val_accuracy: 0.4897 - val_f1: 0.4845\n",
      "Score = 0.4069874286820605, F1 = 0.3767083661258521, ACC = 0.4684631011446654\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 71s 179us/step - loss: 0.4645 - accuracy: 0.8483 - f1: 0.8480 - val_loss: 2.2619 - val_accuracy: 0.5139 - val_f1: 0.5075\n",
      "Score = 0.4451254113075504, F1 = 0.4227493808007682, ACC = 0.49055553385162326\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 71s 179us/step - loss: 0.4671 - accuracy: 0.8479 - f1: 0.8476 - val_loss: 2.2577 - val_accuracy: 0.5096 - val_f1: 0.5035\n",
      "Score = 0.4307751744075313, F1 = 0.4024182894164707, ACC = 0.4883482439348361\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 71s 180us/step - loss: 0.4665 - accuracy: 0.8483 - f1: 0.8476 - val_loss: 2.2212 - val_accuracy: 0.5102 - val_f1: 0.5040\n",
      "Score = 0.4325332411424423, F1 = 0.40474882921349203, ACC = 0.48894401687697775\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 71s 181us/step - loss: 0.4668 - accuracy: 0.8474 - f1: 0.8473 - val_loss: 2.1839 - val_accuracy: 0.5058 - val_f1: 0.4995\n",
      "Score = 0.43698036824742625, F1 = 0.414003243502146, ACC = 0.4836308942454194\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 64)                70080     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 70,535\n",
      "Trainable params: 70,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4776312783887438, 0.44906033956385255, 0.535638942063523]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.7685 - accuracy: 0.7403 - f1: 0.7238 - val_loss: 1.7640 - val_accuracy: 0.5243 - val_f1: 0.5119\n",
      "Score = 0.43927395892838994, F1 = 0.4195864269710943, ACC = 0.47924561472047505\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 41s 104us/step - loss: 0.5581 - accuracy: 0.8141 - f1: 0.8120 - val_loss: 1.9921 - val_accuracy: 0.5156 - val_f1: 0.5091\n",
      "Score = 0.4301657174186152, F1 = 0.40120559071837897, ACC = 0.4889635504160644\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 41s 103us/step - loss: 0.5142 - accuracy: 0.8294 - f1: 0.8285 - val_loss: 2.0320 - val_accuracy: 0.5086 - val_f1: 0.5022\n",
      "Score = 0.4307927620836057, F1 = 0.40648054786352955, ACC = 0.4801539242880025\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 41s 105us/step - loss: 0.4924 - accuracy: 0.8375 - f1: 0.8368 - val_loss: 2.1912 - val_accuracy: 0.4902 - val_f1: 0.4835\n",
      "Score = 0.4059853146088616, F1 = 0.37668468599941046, ACC = 0.4654744696644138\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 41s 105us/step - loss: 0.4762 - accuracy: 0.8429 - f1: 0.8428 - val_loss: 2.2856 - val_accuracy: 0.4879 - val_f1: 0.4853\n",
      "Score = 0.40441831051543287, F1 = 0.3725130740171589, ACC = 0.46919560886041334\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 41s 105us/step - loss: 0.4681 - accuracy: 0.8460 - f1: 0.8456 - val_loss: 2.2845 - val_accuracy: 0.4999 - val_f1: 0.4966\n",
      "Score = 0.42225351113068244, F1 = 0.39317737936943864, ACC = 0.481286869555026\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 41s 104us/step - loss: 0.4580 - accuracy: 0.8494 - f1: 0.8494 - val_loss: 2.3480 - val_accuracy: 0.5003 - val_f1: 0.4968\n",
      "Score = 0.42029401923346366, F1 = 0.3893532013907279, ACC = 0.4831132554596242\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.4539 - accuracy: 0.8511 - f1: 0.8511 - val_loss: 2.3490 - val_accuracy: 0.5044 - val_f1: 0.5013\n",
      "Score = 0.414897007995812, F1 = 0.3794988343240316, ACC = 0.48676602726882057\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 41s 104us/step - loss: 0.4508 - accuracy: 0.8520 - f1: 0.8520 - val_loss: 2.3465 - val_accuracy: 0.4982 - val_f1: 0.4946\n",
      "Score = 0.4245827368253193, F1 = 0.39751010435094697, ACC = 0.47954838457631754\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_8 (GRU)                  (None, 64)                70080     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 70,535\n",
      "Trainable params: 70,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4662582572871852, 0.43765623838731554, 0.5243290229323749]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 82s 207us/step - loss: 0.7082 - accuracy: 0.7579 - f1: 0.7362 - val_loss: 1.6605 - val_accuracy: 0.5106 - val_f1: 0.5024\n",
      "Score = 0.43608061931629094, F1 = 0.42025611167348187, ACC = 0.46820916513653943\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 81s 207us/step - loss: 0.4236 - accuracy: 0.8539 - f1: 0.8538 - val_loss: 1.9056 - val_accuracy: 0.5099 - val_f1: 0.5077\n",
      "Score = 0.43849321003104724, F1 = 0.4161746273417486, ACC = 0.4838066960971989\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 81s 207us/step - loss: 0.3608 - accuracy: 0.8758 - f1: 0.8759 - val_loss: 2.0737 - val_accuracy: 0.5055 - val_f1: 0.5038\n",
      "Score = 0.43428553119896074, F1 = 0.4100580666285984, ACC = 0.4834746259327265\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.3215 - accuracy: 0.8893 - f1: 0.8897 - val_loss: 2.2402 - val_accuracy: 0.5107 - val_f1: 0.5104\n",
      "Score = 0.43709547571754204, F1 = 0.4093501157692758, ACC = 0.49342696409735515\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 79s 202us/step - loss: 0.2937 - accuracy: 0.8988 - f1: 0.8993 - val_loss: 2.3366 - val_accuracy: 0.5054 - val_f1: 0.5046\n",
      "Score = 0.43412741767993407, F1 = 0.40703198721126205, ACC = 0.4891393522678439\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 80s 204us/step - loss: 0.2731 - accuracy: 0.9057 - f1: 0.9062 - val_loss: 2.4696 - val_accuracy: 0.5083 - val_f1: 0.5071\n",
      "Score = 0.4335266251860985, F1 = 0.404321724087802, ACC = 0.49282142438567017\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 81s 204us/step - loss: 0.2535 - accuracy: 0.9128 - f1: 0.9133 - val_loss: 2.5125 - val_accuracy: 0.5123 - val_f1: 0.5108\n",
      "Score = 0.4384262745348061, F1 = 0.4096238452190019, ACC = 0.49690393405477207\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.2400 - accuracy: 0.9178 - f1: 0.9182 - val_loss: 2.6010 - val_accuracy: 0.5098 - val_f1: 0.5084\n",
      "Score = 0.4327875353039682, F1 = 0.4018331813123899, ACC = 0.4956342540141423\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.2275 - accuracy: 0.9222 - f1: 0.9225 - val_loss: 2.6779 - val_accuracy: 0.5075 - val_f1: 0.5067\n",
      "Score = 0.43135737319419815, F1 = 0.3999247044255938, ACC = 0.4951752158456069\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.2173 - accuracy: 0.9251 - f1: 0.9256 - val_loss: 2.7408 - val_accuracy: 0.5147 - val_f1: 0.5151\n",
      "Score = 0.43949732673573394, F1 = 0.4077636822210731, ACC = 0.503926241356409\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.2093 - accuracy: 0.9282 - f1: 0.9287 - val_loss: 2.8130 - val_accuracy: 0.5116 - val_f1: 0.5109\n",
      "Score = 0.4341734998560321, F1 = 0.4017755448145948, ACC = 0.49995116615228347\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.2005 - accuracy: 0.9313 - f1: 0.9319 - val_loss: 2.7893 - val_accuracy: 0.5077 - val_f1: 0.5064\n",
      "Score = 0.4320697901817453, F1 = 0.40111789681988935, ACC = 0.4949115130679376\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 80s 203us/step - loss: 0.1931 - accuracy: 0.9341 - f1: 0.9345 - val_loss: 2.9233 - val_accuracy: 0.5062 - val_f1: 0.5041\n",
      "Score = 0.4296358831243691, F1 = 0.39851945688216, ACC = 0.4928116576161269\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.1877 - accuracy: 0.9358 - f1: 0.9360 - val_loss: 2.9488 - val_accuracy: 0.5078 - val_f1: 0.5055\n",
      "Score = 0.4288420486157445, F1 = 0.396083899665085, ACC = 0.49535101769738643\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 81s 204us/step - loss: 0.1810 - accuracy: 0.9379 - f1: 0.9382 - val_loss: 2.9789 - val_accuracy: 0.4942 - val_f1: 0.4914\n",
      "Score = 0.4197168954507684, F1 = 0.38987724615893765, ACC = 0.48030042583115207\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.1761 - accuracy: 0.9396 - f1: 0.9399 - val_loss: 3.0281 - val_accuracy: 0.4954 - val_f1: 0.4946\n",
      "Score = 0.4247165823285549, F1 = 0.39526614055541837, ACC = 0.4845099035043169\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.1704 - accuracy: 0.9417 - f1: 0.9419 - val_loss: 3.0813 - val_accuracy: 0.5003 - val_f1: 0.4987\n",
      "Score = 0.4252283347547941, F1 = 0.3938315523634978, ACC = 0.4889733171856077\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.1672 - accuracy: 0.9430 - f1: 0.9433 - val_loss: 3.1617 - val_accuracy: 0.4928 - val_f1: 0.4916\n",
      "Score = 0.41486809656344414, F1 = 0.3817791536749864, ACC = 0.48204867757940384\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_9 (GRU)                  (None, 128)               164736    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 165,639\n",
      "Trainable params: 165,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.44242064158188155, 0.40684491142976886, 0.5146501543149588]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 44s 111us/step - loss: 0.8131 - accuracy: 0.7223 - f1: 0.6899 - val_loss: 1.5994 - val_accuracy: 0.5040 - val_f1: 0.4946\n",
      "Score = 0.4214152328112525, F1 = 0.4051695198813311, ACC = 0.454398953002305\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.4731 - accuracy: 0.8381 - f1: 0.8370 - val_loss: 1.7844 - val_accuracy: 0.5066 - val_f1: 0.5016\n",
      "Score = 0.4333775685971692, F1 = 0.41385013188822495, ACC = 0.4730241825213892\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.4023 - accuracy: 0.8618 - f1: 0.8615 - val_loss: 1.9358 - val_accuracy: 0.5053 - val_f1: 0.5018\n",
      "Score = 0.4319790485848164, F1 = 0.4090544779691151, ACC = 0.47852287377427044\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3611 - accuracy: 0.8758 - f1: 0.8762 - val_loss: 2.0642 - val_accuracy: 0.5038 - val_f1: 0.5022\n",
      "Score = 0.430842281890429, F1 = 0.4058521252519279, ACC = 0.4815798726413252\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3302 - accuracy: 0.8860 - f1: 0.8867 - val_loss: 2.1934 - val_accuracy: 0.5068 - val_f1: 0.5055\n",
      "Score = 0.43365819033927916, F1 = 0.4071638641255492, ACC = 0.487449701136852\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.3087 - accuracy: 0.8935 - f1: 0.8940 - val_loss: 2.2368 - val_accuracy: 0.5063 - val_f1: 0.5049\n",
      "Score = 0.4315726072874053, F1 = 0.403906738647411, ACC = 0.48774270422315114\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.2885 - accuracy: 0.9005 - f1: 0.9007 - val_loss: 2.3377 - val_accuracy: 0.5085 - val_f1: 0.5065\n",
      "Score = 0.4301270234129903, F1 = 0.4004070217126839, ACC = 0.4904676329257335\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.2722 - accuracy: 0.9066 - f1: 0.9070 - val_loss: 2.4097 - val_accuracy: 0.5086 - val_f1: 0.5069\n",
      "Score = 0.4293684604884392, F1 = 0.3981058871242827, ACC = 0.4928409579247568\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 44s 111us/step - loss: 0.2590 - accuracy: 0.9111 - f1: 0.9115 - val_loss: 2.4728 - val_accuracy: 0.5063 - val_f1: 0.5051\n",
      "Score = 0.43068520359744555, F1 = 0.4009996015440134, ACC = 0.49095597140289876\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.2470 - accuracy: 0.9152 - f1: 0.9156 - val_loss: 2.5714 - val_accuracy: 0.5088 - val_f1: 0.5070\n",
      "Score = 0.4290365592702584, F1 = 0.39650890803089706, ACC = 0.49507754815017385\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.2380 - accuracy: 0.9183 - f1: 0.9186 - val_loss: 2.6086 - val_accuracy: 0.5101 - val_f1: 0.5082\n",
      "Score = 0.42963020985352063, F1 = 0.3966685684143587, ACC = 0.49655233035121304\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 42s 108us/step - loss: 0.2284 - accuracy: 0.9215 - f1: 0.9218 - val_loss: 2.6102 - val_accuracy: 0.5044 - val_f1: 0.5033\n",
      "Score = 0.42622796909716976, F1 = 0.3942411817721324, ACC = 0.4911708403328515\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.2199 - accuracy: 0.9246 - f1: 0.9251 - val_loss: 2.6537 - val_accuracy: 0.5039 - val_f1: 0.5014\n",
      "Score = 0.4268393091576582, F1 = 0.3954903645138322, ACC = 0.4904871664648201\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 42s 108us/step - loss: 0.2129 - accuracy: 0.9266 - f1: 0.9269 - val_loss: 2.7588 - val_accuracy: 0.5080 - val_f1: 0.5058\n",
      "Score = 0.42746759362939313, F1 = 0.3940420953091853, ACC = 0.4953314841582998\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 43s 108us/step - loss: 0.2052 - accuracy: 0.9293 - f1: 0.9298 - val_loss: 2.7150 - val_accuracy: 0.5032 - val_f1: 0.5012\n",
      "Score = 0.42365175798703103, F1 = 0.39054040551592345, ACC = 0.4908778372465523\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.2001 - accuracy: 0.9311 - f1: 0.9315 - val_loss: 2.8051 - val_accuracy: 0.5006 - val_f1: 0.4987\n",
      "Score = 0.42134665139276667, F1 = 0.3882833305267611, ACC = 0.4884752119388991\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.1945 - accuracy: 0.9334 - f1: 0.9336 - val_loss: 2.8508 - val_accuracy: 0.5031 - val_f1: 0.5016\n",
      "Score = 0.4249706201537239, F1 = 0.39210477464271815, ACC = 0.49169824588819\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.1891 - accuracy: 0.9351 - f1: 0.9355 - val_loss: 2.8460 - val_accuracy: 0.5038 - val_f1: 0.5021\n",
      "Score = 0.4267515335551539, F1 = 0.3943828249702346, ACC = 0.4924698206821112\n",
      "Epoch 19/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.1839 - accuracy: 0.9370 - f1: 0.9374 - val_loss: 2.8980 - val_accuracy: 0.5027 - val_f1: 0.5008\n",
      "Score = 0.42303165709017565, F1 = 0.3898121122249766, ACC = 0.4904773996952768\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 128)               164736    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 165,639\n",
      "Trainable params: 165,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.44076407446120136, 0.40822563243380144, 0.5068269719107708]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 82s 207us/step - loss: 0.4107 - accuracy: 0.8581 - f1: 0.8564 - val_loss: 2.1049 - val_accuracy: 0.5279 - val_f1: 0.5228\n",
      "Score = 0.4686870111405582, F1 = 0.45165748925596266, ACC = 0.5032621010274642\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.2904 - accuracy: 0.8993 - f1: 0.8996 - val_loss: 2.6033 - val_accuracy: 0.4900 - val_f1: 0.4869\n",
      "Score = 0.42288808136871353, F1 = 0.3978141514248673, ACC = 0.4737957573153104\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 80s 203us/step - loss: 0.2615 - accuracy: 0.9101 - f1: 0.9105 - val_loss: 2.5668 - val_accuracy: 0.5001 - val_f1: 0.4974\n",
      "Score = 0.43211098638514206, F1 = 0.4073272006864424, ACC = 0.48242958159159277\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.2463 - accuracy: 0.9152 - f1: 0.9157 - val_loss: 2.7077 - val_accuracy: 0.4875 - val_f1: 0.4853\n",
      "Score = 0.41477040103006896, F1 = 0.3867036047931617, ACC = 0.47175450248075945\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.2371 - accuracy: 0.9186 - f1: 0.9192 - val_loss: 2.8204 - val_accuracy: 0.4817 - val_f1: 0.4781\n",
      "Score = 0.4048045549922366, F1 = 0.3744653608623842, ACC = 0.46640231277102784\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 80s 202us/step - loss: 0.2308 - accuracy: 0.9205 - f1: 0.9212 - val_loss: 2.8961 - val_accuracy: 0.5080 - val_f1: 0.5059\n",
      "Score = 0.43361502674675656, F1 = 0.40310672715475204, ACC = 0.49555611985779585\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.2237 - accuracy: 0.9235 - f1: 0.9239 - val_loss: 3.0358 - val_accuracy: 0.4942 - val_f1: 0.4935\n",
      "Score = 0.4252316260712021, F1 = 0.3966554168570687, ACC = 0.48324999023323045\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 80s 204us/step - loss: 0.2215 - accuracy: 0.9243 - f1: 0.9248 - val_loss: 3.1269 - val_accuracy: 0.5029 - val_f1: 0.5027\n",
      "Score = 0.4296675070400833, F1 = 0.3981433328943639, ACC = 0.4936711333359378\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.2183 - accuracy: 0.9252 - f1: 0.9255 - val_loss: 3.0791 - val_accuracy: 0.5022 - val_f1: 0.5008\n",
      "Score = 0.4300996841664253, F1 = 0.39967831559132033, ACC = 0.4918642809704262\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_11 (GRU)                 (None, 128)               164736    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 165,639\n",
      "Trainable params: 165,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.47994083916231056, 0.4563414124461684, 0.5278548267375083]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 44s 111us/step - loss: 0.4298 - accuracy: 0.8518 - f1: 0.8489 - val_loss: 2.3442 - val_accuracy: 0.4968 - val_f1: 0.4924\n",
      "Score = 0.4186041410685465, F1 = 0.391059423295966, ACC = 0.4745282650310583\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 44s 111us/step - loss: 0.2849 - accuracy: 0.9012 - f1: 0.9018 - val_loss: 2.4416 - val_accuracy: 0.5080 - val_f1: 0.5047\n",
      "Score = 0.4326197871096496, F1 = 0.40486357080358065, ACC = 0.4889733171856077\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 44s 111us/step - loss: 0.2489 - accuracy: 0.9144 - f1: 0.9149 - val_loss: 2.7305 - val_accuracy: 0.5001 - val_f1: 0.4969\n",
      "Score = 0.42729416033719403, F1 = 0.3996279952437963, ACC = 0.48346485916318316\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.2313 - accuracy: 0.9204 - f1: 0.9208 - val_loss: 2.7115 - val_accuracy: 0.5083 - val_f1: 0.5057\n",
      "Score = 0.43418203268573113, F1 = 0.40520854476630364, ACC = 0.493006993006993\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.2181 - accuracy: 0.9246 - f1: 0.9252 - val_loss: 2.6736 - val_accuracy: 0.5188 - val_f1: 0.5154\n",
      "Score = 0.45052234436009586, F1 = 0.42506558013068074, ACC = 0.5022072899167871\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.2113 - accuracy: 0.9272 - f1: 0.9276 - val_loss: 2.7765 - val_accuracy: 0.5021 - val_f1: 0.4991\n",
      "Score = 0.4142286033827306, F1 = 0.37942002069900643, ACC = 0.48490057428604916\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.2060 - accuracy: 0.9289 - f1: 0.9295 - val_loss: 2.8583 - val_accuracy: 0.4898 - val_f1: 0.4876\n",
      "Score = 0.4079890906085155, F1 = 0.37445600564817644, ACC = 0.4760714146189007\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 44s 111us/step - loss: 0.2003 - accuracy: 0.9313 - f1: 0.9316 - val_loss: 3.1073 - val_accuracy: 0.4857 - val_f1: 0.4836\n",
      "Score = 0.39920115873947914, F1 = 0.36234989409640744, ACC = 0.4740203930148064\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.1979 - accuracy: 0.9323 - f1: 0.9327 - val_loss: 3.0236 - val_accuracy: 0.4867 - val_f1: 0.4842\n",
      "Score = 0.39344437675946153, F1 = 0.35367109321416146, ACC = 0.47419619486658593\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 44s 113us/step - loss: 0.1937 - accuracy: 0.9339 - f1: 0.9344 - val_loss: 2.9458 - val_accuracy: 0.5049 - val_f1: 0.5023\n",
      "Score = 0.42342479773349523, F1 = 0.38998518643942515, ACC = 0.49131734187600107\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.1937 - accuracy: 0.9339 - f1: 0.9343 - val_loss: 2.8171 - val_accuracy: 0.5119 - val_f1: 0.5099\n",
      "Score = 0.42987668768788223, F1 = 0.39607434609272196, ACC = 0.4985056842598742\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.1920 - accuracy: 0.9341 - f1: 0.9346 - val_loss: 2.9321 - val_accuracy: 0.5037 - val_f1: 0.4994\n",
      "Score = 0.42604125034507057, F1 = 0.39563655052176533, ACC = 0.48777200453178104\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.1903 - accuracy: 0.9346 - f1: 0.9351 - val_loss: 2.8871 - val_accuracy: 0.5152 - val_f1: 0.5127\n",
      "Score = 0.4424755641779077, F1 = 0.4130891339447954, ACC = 0.5021389225299839\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_12 (GRU)                 (None, 128)               164736    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 165,639\n",
      "Trainable params: 165,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.45903259248476663, 0.4295847851708701, 0.5188205649099504]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 82s 208us/step - loss: 1.0241 - accuracy: 0.6438 - f1: 0.6078 - val_loss: 1.6114 - val_accuracy: 0.5184 - val_f1: 0.5055\n",
      "Score = 0.43487243934141573, F1 = 0.4180872600988233, ACC = 0.46895143962183067\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.6508 - accuracy: 0.7783 - f1: 0.7742 - val_loss: 1.7806 - val_accuracy: 0.5185 - val_f1: 0.5108\n",
      "Score = 0.4407214586269014, F1 = 0.41927908858680346, ACC = 0.484255967496191\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.5659 - accuracy: 0.8072 - f1: 0.8052 - val_loss: 1.8701 - val_accuracy: 0.5232 - val_f1: 0.5164\n",
      "Score = 0.4466009021422648, F1 = 0.4237297393255361, ACC = 0.49303629331562293\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 81s 204us/step - loss: 0.5189 - accuracy: 0.8226 - f1: 0.8215 - val_loss: 1.9763 - val_accuracy: 0.5205 - val_f1: 0.5147\n",
      "Score = 0.4447524929704416, F1 = 0.4203936598542852, ACC = 0.49420830566081964\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.4822 - accuracy: 0.8352 - f1: 0.8344 - val_loss: 2.0498 - val_accuracy: 0.5195 - val_f1: 0.5145\n",
      "Score = 0.44215942025856014, F1 = 0.4155228184015479, ACC = 0.49623979372582727\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.4559 - accuracy: 0.8446 - f1: 0.8442 - val_loss: 2.1674 - val_accuracy: 0.5193 - val_f1: 0.5146\n",
      "Score = 0.442360136109489, F1 = 0.4149565045807368, ACC = 0.4979978122436223\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 82s 207us/step - loss: 0.4321 - accuracy: 0.8525 - f1: 0.8522 - val_loss: 2.2166 - val_accuracy: 0.5242 - val_f1: 0.5199\n",
      "Score = 0.4470503039624494, F1 = 0.41843547025548217, ACC = 0.5051470875493221\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 82s 209us/step - loss: 0.4144 - accuracy: 0.8582 - f1: 0.8582 - val_loss: 2.2936 - val_accuracy: 0.5164 - val_f1: 0.5121\n",
      "Score = 0.4347156353910567, F1 = 0.4032870351005964, ACC = 0.4985252177989608\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 82s 207us/step - loss: 0.3972 - accuracy: 0.8640 - f1: 0.8642 - val_loss: 2.2908 - val_accuracy: 0.5179 - val_f1: 0.5146\n",
      "Score = 0.44285048748423517, F1 = 0.41447612669943057, ACC = 0.5004590381685354\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.3838 - accuracy: 0.8688 - f1: 0.8688 - val_loss: 2.4285 - val_accuracy: 0.5173 - val_f1: 0.5146\n",
      "Score = 0.4354270735221162, F1 = 0.4023669577035093, ACC = 0.5025491268508028\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 82s 208us/step - loss: 0.3699 - accuracy: 0.8742 - f1: 0.8746 - val_loss: 2.4714 - val_accuracy: 0.5181 - val_f1: 0.5150\n",
      "Score = 0.4375762583178331, F1 = 0.40488679492883506, ACC = 0.5039457748954955\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 82s 207us/step - loss: 0.3590 - accuracy: 0.8775 - f1: 0.8778 - val_loss: 2.4673 - val_accuracy: 0.5121 - val_f1: 0.5095\n",
      "Score = 0.43510338551759864, F1 = 0.4042554170057226, ACC = 0.49773410946595303\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.3475 - accuracy: 0.8825 - f1: 0.8827 - val_loss: 2.5554 - val_accuracy: 0.5154 - val_f1: 0.5134\n",
      "Score = 0.4399194055196834, F1 = 0.408826595414186, ACC = 0.5030472320975115\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.3390 - accuracy: 0.8854 - f1: 0.8858 - val_loss: 2.6496 - val_accuracy: 0.5107 - val_f1: 0.5088\n",
      "Score = 0.4313130458737192, F1 = 0.39781408241226907, ACC = 0.4993260929015119\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.3301 - accuracy: 0.8886 - f1: 0.8889 - val_loss: 2.6344 - val_accuracy: 0.5076 - val_f1: 0.5058\n",
      "Score = 0.4320662209848885, F1 = 0.40016009097090965, ACC = 0.4968453334375122\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_13 (GRU)                 (None, 128)               164736    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 165,639\n",
      "Trainable params: 165,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4572033604713728, 0.4242184349953398, 0.524172754619682]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 42s 108us/step - loss: 1.1498 - accuracy: 0.5977 - f1: 0.5501 - val_loss: 1.5262 - val_accuracy: 0.5157 - val_f1: 0.4963\n",
      "Score = 0.41541928607311984, F1 = 0.3984764694098158, ACC = 0.4498183380864945\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.7205 - accuracy: 0.7544 - f1: 0.7475 - val_loss: 1.6566 - val_accuracy: 0.5247 - val_f1: 0.5113\n",
      "Score = 0.4433124618363131, F1 = 0.4252773083613522, ACC = 0.4799292885885065\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.6219 - accuracy: 0.7883 - f1: 0.7853 - val_loss: 1.7824 - val_accuracy: 0.5181 - val_f1: 0.5096\n",
      "Score = 0.43967975324218556, F1 = 0.4183159957376198, ACC = 0.4830546548423643\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.5683 - accuracy: 0.8063 - f1: 0.8047 - val_loss: 1.8363 - val_accuracy: 0.5196 - val_f1: 0.5119\n",
      "Score = 0.44431786851180943, F1 = 0.4235019659076645, ACC = 0.48658045864749777\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.5308 - accuracy: 0.8188 - f1: 0.8177 - val_loss: 1.9148 - val_accuracy: 0.5212 - val_f1: 0.5144\n",
      "Score = 0.44453836381537926, F1 = 0.4210457847836799, ACC = 0.4922354182130718\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 44s 110us/step - loss: 0.5032 - accuracy: 0.8278 - f1: 0.8274 - val_loss: 2.0132 - val_accuracy: 0.5191 - val_f1: 0.5143\n",
      "Score = 0.4425114090937764, F1 = 0.4171738315050558, ACC = 0.4939543696526937\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 44s 113us/step - loss: 0.4790 - accuracy: 0.8362 - f1: 0.8354 - val_loss: 2.0230 - val_accuracy: 0.5223 - val_f1: 0.5176\n",
      "Score = 0.445971036647394, F1 = 0.4207163167479016, ACC = 0.49724577098878775\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.4594 - accuracy: 0.8427 - f1: 0.8423 - val_loss: 2.1237 - val_accuracy: 0.5200 - val_f1: 0.5148\n",
      "Score = 0.44010124370481496, F1 = 0.4124124291099965, ACC = 0.4963179278821737\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.4426 - accuracy: 0.8481 - f1: 0.8481 - val_loss: 2.1512 - val_accuracy: 0.5198 - val_f1: 0.5142\n",
      "Score = 0.4410418991303209, F1 = 0.4138837394096919, ACC = 0.4961811931085674\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.4271 - accuracy: 0.8536 - f1: 0.8536 - val_loss: 2.2378 - val_accuracy: 0.5227 - val_f1: 0.5184\n",
      "Score = 0.4428420316861892, F1 = 0.4134244384440681, ACC = 0.5025686603898895\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.4128 - accuracy: 0.8584 - f1: 0.8590 - val_loss: 2.2437 - val_accuracy: 0.5243 - val_f1: 0.5198\n",
      "Score = 0.4464940792450973, F1 = 0.4180478499659041, ACC = 0.5042485447513381\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 42s 108us/step - loss: 0.4003 - accuracy: 0.8630 - f1: 0.8634 - val_loss: 2.2846 - val_accuracy: 0.5214 - val_f1: 0.5182\n",
      "Score = 0.44328894719819656, F1 = 0.41347573272242355, ACC = 0.5038188068914325\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.3880 - accuracy: 0.8679 - f1: 0.8681 - val_loss: 2.3473 - val_accuracy: 0.5228 - val_f1: 0.5195\n",
      "Score = 0.44191512980742675, F1 = 0.41020339240318526, ACC = 0.5062995663554323\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.3789 - accuracy: 0.8712 - f1: 0.8715 - val_loss: 2.3963 - val_accuracy: 0.5249 - val_f1: 0.5219\n",
      "Score = 0.444547699011278, F1 = 0.41242968372527805, ACC = 0.5097570027737626\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 43s 108us/step - loss: 0.3682 - accuracy: 0.8745 - f1: 0.8746 - val_loss: 2.4180 - val_accuracy: 0.5224 - val_f1: 0.5205\n",
      "Score = 0.4442685143048576, F1 = 0.41256138695482847, ACC = 0.5086435910458257\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 43s 108us/step - loss: 0.3592 - accuracy: 0.8780 - f1: 0.8784 - val_loss: 2.3831 - val_accuracy: 0.5270 - val_f1: 0.5244\n",
      "Score = 0.4511840249441159, F1 = 0.421117591700901, ACC = 0.512227995468219\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 42s 108us/step - loss: 0.3520 - accuracy: 0.8808 - f1: 0.8811 - val_loss: 2.4376 - val_accuracy: 0.5332 - val_f1: 0.5315\n",
      "Score = 0.4624212327970358, F1 = 0.433896830021809, ACC = 0.5203344141891628\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 42s 108us/step - loss: 0.3447 - accuracy: 0.8828 - f1: 0.8833 - val_loss: 2.4481 - val_accuracy: 0.5332 - val_f1: 0.5316\n",
      "Score = 0.4603001513324322, F1 = 0.430524185358491, ACC = 0.5207543852795249\n",
      "Epoch 19/30\n",
      "394390/394390 [==============================] - 44s 110us/step - loss: 0.3363 - accuracy: 0.8865 - f1: 0.8868 - val_loss: 2.5283 - val_accuracy: 0.5232 - val_f1: 0.5217\n",
      "Score = 0.4469042343685121, F1 = 0.41566308126889895, ACC = 0.5103332421768176\n",
      "Epoch 20/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.3306 - accuracy: 0.8882 - f1: 0.8886 - val_loss: 2.5318 - val_accuracy: 0.5238 - val_f1: 0.5224\n",
      "Score = 0.4503716894168225, F1 = 0.42012162304481837, ACC = 0.5117884908387702\n",
      "Epoch 21/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.3252 - accuracy: 0.8899 - f1: 0.8902 - val_loss: 2.6192 - val_accuracy: 0.5177 - val_f1: 0.5157\n",
      "Score = 0.4390697086582539, F1 = 0.4062691775636793, ACC = 0.5056647263351174\n",
      "Epoch 22/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.3189 - accuracy: 0.8919 - f1: 0.8924 - val_loss: 2.6086 - val_accuracy: 0.5278 - val_f1: 0.5270\n",
      "Score = 0.4536328517173905, F1 = 0.4217563745174221, ACC = 0.5183517599718717\n",
      "Epoch 23/30\n",
      "394390/394390 [==============================] - 44s 111us/step - loss: 0.3145 - accuracy: 0.8937 - f1: 0.8942 - val_loss: 2.6717 - val_accuracy: 0.5235 - val_f1: 0.5229\n",
      "Score = 0.44697808941227263, F1 = 0.4140174807498979, ACC = 0.5138981130601242\n",
      "Epoch 24/30\n",
      "394390/394390 [==============================] - 44s 111us/step - loss: 0.3087 - accuracy: 0.8961 - f1: 0.8965 - val_loss: 2.6376 - val_accuracy: 0.5229 - val_f1: 0.5217\n",
      "Score = 0.44839759662690254, F1 = 0.416723029043097, ACC = 0.512706567175841\n",
      "Epoch 25/30\n",
      "394390/394390 [==============================] - 44s 110us/step - loss: 0.3037 - accuracy: 0.8973 - f1: 0.8980 - val_loss: 2.7102 - val_accuracy: 0.5200 - val_f1: 0.5191\n",
      "Score = 0.4424036246878713, F1 = 0.4087052284657566, ACC = 0.5108215806539829\n",
      "Epoch 26/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.3000 - accuracy: 0.8990 - f1: 0.8995 - val_loss: 2.6121 - val_accuracy: 0.5312 - val_f1: 0.5298\n",
      "Score = 0.4574773291589488, F1 = 0.42604644052163365, ACC = 0.5212915576044068\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_14 (GRU)                 (None, 128)               164736    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 165,639\n",
      "Trainable params: 165,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4679327710782706, 0.43580201162160986, 0.5331679493690666]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.6027 - accuracy: 0.7932 - f1: 0.7882 - val_loss: 1.9571 - val_accuracy: 0.5111 - val_f1: 0.5041\n",
      "Score = 0.4337945112230499, F1 = 0.4110377384346235, ACC = 0.47999765597530963\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.4480 - accuracy: 0.8472 - f1: 0.8474 - val_loss: 2.4776 - val_accuracy: 0.4997 - val_f1: 0.4939\n",
      "Score = 0.41545864526484055, F1 = 0.38525342830194786, ACC = 0.47678438879556195\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 81s 204us/step - loss: 0.4139 - accuracy: 0.8596 - f1: 0.8594 - val_loss: 2.4759 - val_accuracy: 0.4936 - val_f1: 0.4888\n",
      "Score = 0.41379252048547327, F1 = 0.3849073467020482, ACC = 0.4724381763487909\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 80s 203us/step - loss: 0.3967 - accuracy: 0.8658 - f1: 0.8660 - val_loss: 2.5560 - val_accuracy: 0.5105 - val_f1: 0.5069\n",
      "Score = 0.43004589980341285, F1 = 0.39874177170178865, ACC = 0.49360276594913466\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 80s 202us/step - loss: 0.3866 - accuracy: 0.8697 - f1: 0.8697 - val_loss: 2.5125 - val_accuracy: 0.5037 - val_f1: 0.5023\n",
      "Score = 0.4336364452517876, F1 = 0.406938988833813, ACC = 0.4878403719185842\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 81s 206us/step - loss: 0.3801 - accuracy: 0.8715 - f1: 0.8717 - val_loss: 2.5705 - val_accuracy: 0.5020 - val_f1: 0.5001\n",
      "Score = 0.4302046291985121, F1 = 0.4020333477508916, ACC = 0.48740086728913545\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 80s 203us/step - loss: 0.3732 - accuracy: 0.8743 - f1: 0.8747 - val_loss: 2.4840 - val_accuracy: 0.5149 - val_f1: 0.5114\n",
      "Score = 0.43941270981761815, F1 = 0.4103986144132778, ACC = 0.4983201156385514\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 80s 204us/step - loss: 0.3697 - accuracy: 0.8757 - f1: 0.8761 - val_loss: 2.6401 - val_accuracy: 0.5033 - val_f1: 0.5014\n",
      "Score = 0.42629850198329267, F1 = 0.3952075339557832, ACC = 0.48942258858459975\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 79s 201us/step - loss: 0.3659 - accuracy: 0.8771 - f1: 0.8776 - val_loss: 2.6049 - val_accuracy: 0.5029 - val_f1: 0.5002\n",
      "Score = 0.4270105202574034, F1 = 0.3971072745248687, ACC = 0.48772317068406457\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 81s 205us/step - loss: 0.3638 - accuracy: 0.8778 - f1: 0.8781 - val_loss: 2.6635 - val_accuracy: 0.4900 - val_f1: 0.4886\n",
      "Score = 0.4187974687278634, F1 = 0.39008281095365754, ACC = 0.4770969254209478\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 79s 200us/step - loss: 0.3635 - accuracy: 0.8779 - f1: 0.8783 - val_loss: 2.4375 - val_accuracy: 0.5165 - val_f1: 0.5148\n",
      "Score = 0.4424780533893773, F1 = 0.41255407336143574, ACC = 0.5032328007188343\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 78s 198us/step - loss: 0.3613 - accuracy: 0.8781 - f1: 0.8788 - val_loss: 2.4811 - val_accuracy: 0.5075 - val_f1: 0.5065\n",
      "Score = 0.44218737167045025, F1 = 0.41586759832795905, ACC = 0.49562448724459895\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 80s 203us/step - loss: 0.3582 - accuracy: 0.8798 - f1: 0.8804 - val_loss: 2.7715 - val_accuracy: 0.4628 - val_f1: 0.4609\n",
      "Score = 0.392191681059193, F1 = 0.3642317260868469, ACC = 0.4489588623666836\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 79s 201us/step - loss: 0.3599 - accuracy: 0.8795 - f1: 0.8799 - val_loss: 2.4479 - val_accuracy: 0.5141 - val_f1: 0.5107\n",
      "Score = 0.4437185134443549, F1 = 0.417017606927768, ACC = 0.49792944485681917\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 80s 204us/step - loss: 0.3571 - accuracy: 0.8809 - f1: 0.8813 - val_loss: 2.6587 - val_accuracy: 0.4876 - val_f1: 0.4853\n",
      "Score = 0.4042120685600242, F1 = 0.3699106424511582, ACC = 0.47385435793257025\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 79s 201us/step - loss: 0.3575 - accuracy: 0.8801 - f1: 0.8806 - val_loss: 2.7175 - val_accuracy: 0.4846 - val_f1: 0.4837\n",
      "Score = 0.40379654449506996, F1 = 0.3698099911102168, ACC = 0.4727995468218932\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 80s 202us/step - loss: 0.3576 - accuracy: 0.8799 - f1: 0.8801 - val_loss: 2.6048 - val_accuracy: 0.5025 - val_f1: 0.5024\n",
      "Score = 0.42898378885200195, F1 = 0.3985371445257223, ACC = 0.4907997030902059\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 80s 202us/step - loss: 0.3570 - accuracy: 0.8807 - f1: 0.8810 - val_loss: 2.5909 - val_accuracy: 0.5029 - val_f1: 0.5022\n",
      "Score = 0.4320370152456912, F1 = 0.40341650223959064, ACC = 0.49014532953080436\n",
      "Epoch 19/30\n",
      "394390/394390 [==============================] - 79s 201us/step - loss: 0.3568 - accuracy: 0.8806 - f1: 0.8809 - val_loss: 2.7491 - val_accuracy: 0.4807 - val_f1: 0.4792\n",
      "Score = 0.39929159472558695, F1 = 0.36535193024548984, ACC = 0.46819939836699614\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_15 (GRU)                 (None, 128)               164736    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 165,639\n",
      "Trainable params: 165,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.45378053102242094, 0.42407897920528864, 0.514083681681447]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.6365 - accuracy: 0.7818 - f1: 0.7750 - val_loss: 2.0503 - val_accuracy: 0.5147 - val_f1: 0.5089\n",
      "Score = 0.4340108849231899, F1 = 0.4079404198707341, ACC = 0.4869418291206001\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.4524 - accuracy: 0.8458 - f1: 0.8455 - val_loss: 2.3361 - val_accuracy: 0.5092 - val_f1: 0.5062\n",
      "Score = 0.4236191891690275, F1 = 0.39061686829902503, ACC = 0.49062390123842636\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.4064 - accuracy: 0.8612 - f1: 0.8616 - val_loss: 2.3206 - val_accuracy: 0.5089 - val_f1: 0.5061\n",
      "Score = 0.42694776209248547, F1 = 0.3949162283057512, ACC = 0.4919814822049459\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.3848 - accuracy: 0.8689 - f1: 0.8695 - val_loss: 2.4973 - val_accuracy: 0.5064 - val_f1: 0.5032\n",
      "Score = 0.4344403495382536, F1 = 0.406868874391803, ACC = 0.49041879907801694\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.3690 - accuracy: 0.8757 - f1: 0.8760 - val_loss: 2.4451 - val_accuracy: 0.5155 - val_f1: 0.5114\n",
      "Score = 0.4338784568385427, F1 = 0.40161900150939894, ACC = 0.4993749267492284\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 43s 108us/step - loss: 0.3594 - accuracy: 0.8790 - f1: 0.8793 - val_loss: 2.5509 - val_accuracy: 0.4941 - val_f1: 0.4913\n",
      "Score = 0.4098762162066216, F1 = 0.3753676536395002, ACC = 0.47993905535804976\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.3507 - accuracy: 0.8819 - f1: 0.8824 - val_loss: 2.5665 - val_accuracy: 0.4999 - val_f1: 0.4976\n",
      "Score = 0.42044439358062147, F1 = 0.3880238497213798, ACC = 0.48626792202211194\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 43s 108us/step - loss: 0.3461 - accuracy: 0.8835 - f1: 0.8842 - val_loss: 2.6213 - val_accuracy: 0.5103 - val_f1: 0.5090\n",
      "Score = 0.4287082692751187, F1 = 0.39329137035270645, ACC = 0.5006153064812283\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 43s 108us/step - loss: 0.3436 - accuracy: 0.8848 - f1: 0.8854 - val_loss: 2.4704 - val_accuracy: 0.5210 - val_f1: 0.5168\n",
      "Score = 0.4534226473462579, F1 = 0.42865357379929453, ACC = 0.5037113724264562\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3401 - accuracy: 0.8859 - f1: 0.8863 - val_loss: 2.6424 - val_accuracy: 0.5054 - val_f1: 0.5022\n",
      "Score = 0.42616366712300957, F1 = 0.3939575992375316, ACC = 0.49155174434504045\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3363 - accuracy: 0.8877 - f1: 0.8878 - val_loss: 2.4371 - val_accuracy: 0.5229 - val_f1: 0.5198\n",
      "Score = 0.45369323531503425, F1 = 0.42657521924846203, ACC = 0.5087510255108021\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 42s 106us/step - loss: 0.3357 - accuracy: 0.8874 - f1: 0.8879 - val_loss: 2.5937 - val_accuracy: 0.5037 - val_f1: 0.5024\n",
      "Score = 0.42903466907065135, F1 = 0.39805506733248597, ACC = 0.4919326483572294\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3343 - accuracy: 0.8884 - f1: 0.8886 - val_loss: 2.7057 - val_accuracy: 0.4945 - val_f1: 0.4933\n",
      "Score = 0.4151459592985465, F1 = 0.3817032033350977, ACC = 0.48304488807282103\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3294 - accuracy: 0.8899 - f1: 0.8908 - val_loss: 2.6548 - val_accuracy: 0.5043 - val_f1: 0.5023\n",
      "Score = 0.4261037276489972, F1 = 0.3930936470885044, ACC = 0.49312419424151266\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3305 - accuracy: 0.8895 - f1: 0.8900 - val_loss: 2.5682 - val_accuracy: 0.5254 - val_f1: 0.5235\n",
      "Score = 0.45335472215694617, F1 = 0.42406399788287635, ACC = 0.5128237684103606\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3289 - accuracy: 0.8901 - f1: 0.8904 - val_loss: 2.7064 - val_accuracy: 0.4995 - val_f1: 0.4966\n",
      "Score = 0.41267070943254086, F1 = 0.37620967413653, ACC = 0.4866976598820174\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3302 - accuracy: 0.8898 - f1: 0.8904 - val_loss: 2.7446 - val_accuracy: 0.4973 - val_f1: 0.4943\n",
      "Score = 0.41702900527737097, F1 = 0.3839845648939075, ACC = 0.48411923272258467\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3282 - accuracy: 0.8904 - f1: 0.8907 - val_loss: 2.6255 - val_accuracy: 0.5141 - val_f1: 0.5109\n",
      "Score = 0.43706470153609533, F1 = 0.4058213832905694, ACC = 0.5004981052467086\n",
      "Epoch 19/30\n",
      "394390/394390 [==============================] - 42s 107us/step - loss: 0.3271 - accuracy: 0.8908 - f1: 0.8913 - val_loss: 2.7339 - val_accuracy: 0.5137 - val_f1: 0.5112\n",
      "Score = 0.44776765885586384, F1 = 0.4217285994763581, ACC = 0.5006348400203149\n",
      "Epoch 20/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.3267 - accuracy: 0.8905 - f1: 0.8912 - val_loss: 2.8551 - val_accuracy: 0.4956 - val_f1: 0.4943\n",
      "Score = 0.41074068296288574, F1 = 0.3737283089844942, ACC = 0.485887018009923\n",
      "Epoch 21/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.3264 - accuracy: 0.8909 - f1: 0.8913 - val_loss: 2.7767 - val_accuracy: 0.5104 - val_f1: 0.5095\n",
      "Score = 0.43876858181521383, F1 = 0.40809028977416467, ACC = 0.5010548111106771\n",
      "Epoch 22/30\n",
      "394390/394390 [==============================] - 43s 109us/step - loss: 0.3256 - accuracy: 0.8914 - f1: 0.8918 - val_loss: 2.7066 - val_accuracy: 0.5093 - val_f1: 0.5079\n",
      "Score = 0.44156460469335, F1 = 0.41381243874402723, ACC = 0.49790991131773255\n",
      "Epoch 23/30\n",
      "394390/394390 [==============================] - 43s 110us/step - loss: 0.3255 - accuracy: 0.8919 - f1: 0.8925 - val_loss: 2.6842 - val_accuracy: 0.5182 - val_f1: 0.5163\n",
      "Score = 0.44833894107365374, F1 = 0.4196131819705034, ACC = 0.5066609368285346\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_16 (GRU)                 (None, 128)               164736    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 165,639\n",
      "Trainable params: 165,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.46238625006440204, 0.4325890768973334, 0.5228835410399656]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 64, 0.3, 0.0001, 128, 0.4475165283238025, 0.4138253477409825, 0.5159198343555885], [1, 64, 0.3, 0.0001, 256, 0.4483078366067398, 0.4142607776227693, 0.5174336836348009], [2, 64, 0.3, 0.001, 128, 0.4543564594874191, 0.4233462989482481, 0.5173164824002813], [3, 64, 0.3, 0.001, 256, 0.452456819711919, 0.4207322986290947, 0.5168672110012892], [4, 64, 0.5, 0.0001, 128, 0.45718984362122483, 0.42719039061669956, 0.5180978239637457], [5, 64, 0.5, 0.0001, 256, 0.46755872461649395, 0.43752872007554494, 0.5285287338359964], [6, 64, 0.5, 0.001, 128, 0.4776312783887438, 0.44906033956385255, 0.535638942063523], [7, 64, 0.5, 0.001, 256, 0.4662582572871852, 0.43765623838731554, 0.5243290229323749], [8, 128, 0.3, 0.0001, 128, 0.44242064158188155, 0.40684491142976886, 0.5146501543149588], [9, 128, 0.3, 0.0001, 256, 0.44076407446120136, 0.40822563243380144, 0.5068269719107708], [10, 128, 0.3, 0.001, 128, 0.47994083916231056, 0.4563414124461684, 0.5278548267375083], [11, 128, 0.3, 0.001, 256, 0.45903259248476663, 0.4295847851708701, 0.5188205649099504], [12, 128, 0.5, 0.0001, 128, 0.4572033604713728, 0.4242184349953398, 0.524172754619682], [13, 128, 0.5, 0.0001, 256, 0.4679327710782706, 0.43580201162160986, 0.5331679493690666], [14, 128, 0.5, 0.001, 128, 0.45378053102242094, 0.42407897920528864, 0.514083681681447], [15, 128, 0.5, 0.001, 256, 0.46238625006440204, 0.4325890768973334, 0.5228835410399656]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>units</th>\n",
       "      <th>drop</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch</th>\n",
       "      <th>score</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.447517</td>\n",
       "      <td>0.413825</td>\n",
       "      <td>0.515920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>0.414261</td>\n",
       "      <td>0.517434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.454356</td>\n",
       "      <td>0.423346</td>\n",
       "      <td>0.517316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.452457</td>\n",
       "      <td>0.420732</td>\n",
       "      <td>0.516867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.457190</td>\n",
       "      <td>0.427190</td>\n",
       "      <td>0.518098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.467559</td>\n",
       "      <td>0.437529</td>\n",
       "      <td>0.528529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.477631</td>\n",
       "      <td>0.449060</td>\n",
       "      <td>0.535639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.437656</td>\n",
       "      <td>0.524329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.442421</td>\n",
       "      <td>0.406845</td>\n",
       "      <td>0.514650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.440764</td>\n",
       "      <td>0.408226</td>\n",
       "      <td>0.506827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.479941</td>\n",
       "      <td>0.456341</td>\n",
       "      <td>0.527855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.459033</td>\n",
       "      <td>0.429585</td>\n",
       "      <td>0.518821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.457203</td>\n",
       "      <td>0.424218</td>\n",
       "      <td>0.524173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.467933</td>\n",
       "      <td>0.435802</td>\n",
       "      <td>0.533168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.453781</td>\n",
       "      <td>0.424079</td>\n",
       "      <td>0.514084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.462386</td>\n",
       "      <td>0.432589</td>\n",
       "      <td>0.522884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  units  drop      lr  batch     score        f1       acc\n",
       "0    0     64   0.3  0.0001    128  0.447517  0.413825  0.515920\n",
       "1    1     64   0.3  0.0001    256  0.448308  0.414261  0.517434\n",
       "2    2     64   0.3  0.0010    128  0.454356  0.423346  0.517316\n",
       "3    3     64   0.3  0.0010    256  0.452457  0.420732  0.516867\n",
       "4    4     64   0.5  0.0001    128  0.457190  0.427190  0.518098\n",
       "5    5     64   0.5  0.0001    256  0.467559  0.437529  0.528529\n",
       "6    6     64   0.5  0.0010    128  0.477631  0.449060  0.535639\n",
       "7    7     64   0.5  0.0010    256  0.466258  0.437656  0.524329\n",
       "8    8    128   0.3  0.0001    128  0.442421  0.406845  0.514650\n",
       "9    9    128   0.3  0.0001    256  0.440764  0.408226  0.506827\n",
       "10  10    128   0.3  0.0010    128  0.479941  0.456341  0.527855\n",
       "11  11    128   0.3  0.0010    256  0.459033  0.429585  0.518821\n",
       "12  12    128   0.5  0.0001    128  0.457203  0.424218  0.524173\n",
       "13  13    128   0.5  0.0001    256  0.467933  0.435802  0.533168\n",
       "14  14    128   0.5  0.0010    128  0.453781  0.424079  0.514084\n",
       "15  15    128   0.5  0.0010    256  0.462386  0.432589  0.522884"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_11 (GRU)                 (None, 128)               164736    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 165,639\n",
      "Trainable params: 165,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:46<00:00,  3.33s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:52<00:00,  3.78s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:36<00:00,  2.63s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:47<00:00,  3.38s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:40<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243006, 10, 300)\n",
      "(243006, 7)\n",
      "2916072000 13608336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.5042357899062622, 0.4547609742819514, 0.6046846579919838]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.712836</td>\n",
       "      <td>0.672625</td>\n",
       "      <td>0.692147</td>\n",
       "      <td>0.744348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.504634</td>\n",
       "      <td>0.381861</td>\n",
       "      <td>0.434746</td>\n",
       "      <td>0.956297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>0.318173</td>\n",
       "      <td>0.298423</td>\n",
       "      <td>0.968326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.069476</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.113480</td>\n",
       "      <td>0.956536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.770224</td>\n",
       "      <td>0.614532</td>\n",
       "      <td>0.683626</td>\n",
       "      <td>0.838222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.304517</td>\n",
       "      <td>0.569616</td>\n",
       "      <td>0.396868</td>\n",
       "      <td>0.847868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.611073</td>\n",
       "      <td>0.523726</td>\n",
       "      <td>0.564038</td>\n",
       "      <td>0.897772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all</td>\n",
       "      <td>0.464820</td>\n",
       "      <td>0.484294</td>\n",
       "      <td>0.454761</td>\n",
       "      <td>0.887053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class    recall  precision        f1  accuracy\n",
       "0     0  0.712836   0.672625  0.692147  0.744348\n",
       "1     1  0.504634   0.381861  0.434746  0.956297\n",
       "2     2  0.280982   0.318173  0.298423  0.968326\n",
       "3     3  0.069476   0.309524  0.113480  0.956536\n",
       "4     4  0.770224   0.614532  0.683626  0.838222\n",
       "5     5  0.304517   0.569616  0.396868  0.847868\n",
       "6     6  0.611073   0.523726  0.564038  0.897772\n",
       "7   all  0.464820   0.484294  0.454761  0.887053"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
