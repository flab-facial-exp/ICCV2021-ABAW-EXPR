{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.HIGHEST_PROTOCOL = 4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import func_proc_filepath as mFILE\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, GRU, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.utils import Sequence\n",
    "from keras import backend as K\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # root folder\n",
    "    dir_root = str(Path(Path().resolve()).parent)\n",
    "\n",
    "    # input: folder path including original images\n",
    "    dir_data = dir_root + \"\\\\dataset\\\\aff2_images\\\\dataset\"\n",
    "    dir_audio = dir_root + \"\\\\dataset\\\\aff2_audio\\\\dataset\"\n",
    "\n",
    "    # input: expr labels\n",
    "    file_label_test = dir_root + \"\\\\src\\\\test_set\\\\test_set_Expr_Challenge.txt\"\n",
    "    file_frame_list = dir_root + \"\\\\parameters\\\\frame_list.csv\"\n",
    "    \n",
    "    dir_model_single = dir_root + \"\\\\model_expr4\\\\model_image\"\n",
    "    dir_model_multi = dir_root + \"\\\\model_expr4\\\\model_mix\"\n",
    "    \n",
    "    # output: folder path\n",
    "    dir_out = dir_root + \"\\\\model_expr4\\\\submission4\"\n",
    "    if os.path.isdir(dir_out) == False:\n",
    "        os.makedirs(dir_out)\n",
    "        \n",
    "    file_model = dir_model_multi + \"\\\\model_modal_multi_norm_best.h5\"\n",
    "    file_pre_model = dir_model_single + \"\\\\model_image_single_pseudo_best.h5\"\n",
    "    \n",
    "    # read pre_model\n",
    "    base_model = keras.models.load_model(file_pre_model, custom_objects={'f1':f1})\n",
    "    layer_name = 'vgg_au'\n",
    "    pre_model = Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)  \n",
    "    # *****\n",
    "    \n",
    "    # read model\n",
    "    model = keras.models.load_model(file_model, custom_objects={'f1':f1})\n",
    "    # *****\n",
    "    \n",
    "    # read test list\n",
    "    df_label = pd.read_csv(file_label_test, header=None)\n",
    "    df_label.columns = [\"name\"]\n",
    "    #df_label.loc[df_label.loc[:,\"name\"]==\"video49_right\", \"name\"] = \"video49\" ### ***************** ###\n",
    "    # read frame list \n",
    "    df_frames = pd.read_csv(file_frame_list)\n",
    "    # test set and frames\n",
    "    df_label = pd.merge(df_label, df_frames, on=\"name\")\n",
    "    display(df_label)\n",
    "    \n",
    "    name_list = df_label.loc[:,\"name\"].values\n",
    "    \n",
    "    length = len(name_list)\n",
    "    #length =10\n",
    "    \n",
    "    # predict and save per file\n",
    "    for i in tqdm(range(length)):\n",
    "        name = name_list[i]\n",
    "        # create dummy data frame\n",
    "        frame_num = int(df_label.loc[df_label.loc[:, \"name\"] == name, \"video frames\"].values.ravel()[0]) + 1\n",
    "        df_dummy = pd.DataFrame(np.arange(frame_num).reshape(-1,1), columns = [\"frame\"])\n",
    "        df_dummy[\"expr\"] = -1\n",
    "        df_dummy.set_index(\"frame\", drop=True, inplace=True)\n",
    "        # read data\n",
    "        file_data = dir_data + \"\\\\\" + name + \".h5\"\n",
    "        df_data = pd.read_hdf(file_data)\n",
    "        df_data.set_index(\"frame\", drop=True, inplace=True)\n",
    "        file_audio = dir_audio + \"\\\\\" + name + \".h5\"\n",
    "        df_audio = pd.read_hdf(file_audio)\n",
    "        df_audio.set_index(\"frame\", drop=True, inplace=True)\n",
    "        # merged\n",
    "        #df_merge = pd.merge(df_dummy, df_data, on=\"frame\", how=\"outer\")\n",
    "        df_merge = df_dummy.join([df_data, df_audio], how=\"outer\")\n",
    "        # interpolate 30 frame back\n",
    "        df_merge.interpolate(method=\"index\", limit=30, limit_direction='backward', inplace=True)\n",
    "        # normalize per single subject\n",
    "        # create feture data (predict from all subjects )\n",
    "        np_x = df_merge.loc[:, df_merge.columns.str.contains(\"AU|pose_R|gaze|vgg-\")].values\n",
    "        pre_x = pre_model.predict(np_x)\n",
    "        df = pd.DataFrame(pre_x)\n",
    "        # create normalized feature data from single subject\n",
    "        np_mean_sub = np.nanmean(pre_x, axis=0)\n",
    "        np_std_sub = np.nanstd(pre_x, axis=0, ddof=1)\n",
    "        np_x_sub = (pre_x - np_mean_sub)/np_std_sub\n",
    "        df_sub = pd.DataFrame(np_x_sub)\n",
    "        df_sub.replace(np.inf, 9999, inplace=True)\n",
    "        df_sub.fillna(0, inplace=True)\n",
    "        df_sub.mask(df_sub > 5, 5, inplace=True)\n",
    "        #df_sub.mask(df_sub < -5, -5, inplace=True)\n",
    "        df_sub.columns = [\"sub-\" + str(n) for n in df_sub.columns.values]\n",
    "        \n",
    "        np_audio = df_merge.loc[:, df_merge.columns.str.contains(\"audio\")].values\n",
    "        np_audio_mean = np.nanmean(np_audio, axis=0)\n",
    "        np_audio_std = np.nanstd(np_audio, axis=0, ddof=1)\n",
    "        np_audio_sub = (np_audio - np_audio_mean)/np_audio_std\n",
    "        df_audio_sub = pd.DataFrame(np_audio_sub)\n",
    "        df_audio_sub.replace(np.inf, 9999, inplace=True)\n",
    "        df_audio_sub.fillna(0, inplace=True)\n",
    "        df_audio_sub.mask(df_audio_sub > 5, 5, inplace=True)\n",
    "        df_audio_sub.mask(df_audio_sub < -5, -5, inplace=True)\n",
    "        df_audio_sub.columns = [\"subau-\" + str(n) for n in df_audio_sub.columns.values]\n",
    "        \n",
    "        # create all merged data\n",
    "        #df = pd.concat([df, df_sub, df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "        #df = pd.DataFrame(pre_x)\n",
    "        df = pd.concat([df, df_sub, \n",
    "                        df_merge.loc[:, df_merge.columns.str.contains(\"audio\")], df_audio_sub, \n",
    "                        df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "        \n",
    "        \n",
    "        # create GRU features\n",
    "        batch_length = 90\n",
    "        feat_size = 1200\n",
    "        np_x_list = []\n",
    "        # create line * batch_length * feat_size data\n",
    "        for i in range(len(df)):\n",
    "            np_tmp = np.zeros((batch_length, feat_size))\n",
    "            if i-batch_length+1 < 0:\n",
    "                np_tmp = np.zeros((batch_length-i-1, feat_size))\n",
    "                np_tmp2 = df.iloc[0:i+1, 0:feat_size].values\n",
    "                np_tmp = np.append(np_tmp, np_tmp2, axis=0)\n",
    "            else:\n",
    "                np_tmp = df.iloc[i-batch_length+1:i+1, 0:feat_size].values\n",
    "\n",
    "            np_tmp = np_tmp.astype(np.float32)\n",
    "            np_tmp = np_tmp[np.newaxis, ::6, :]\n",
    "            np_tmp = np.nan_to_num(np_tmp)\n",
    "            np_x_list.append(np_tmp)\n",
    "            \n",
    "        np_test_x = np.concatenate([x for x in np_x_list], 0)\n",
    "        np_x_list = None\n",
    "        \n",
    "        # predict\n",
    "        pred_nn = model.predict(np_test_x)\n",
    "        pred_one = np.argmax(pred_nn, axis=1).ravel()\n",
    "        df[\"expr\"] = pred_one\n",
    "        list_out = df[\"expr\"].values.tolist()\n",
    "        \n",
    "        # save result\n",
    "        file_out = dir_out + \"\\\\\" + name + \".txt\"\n",
    "        f = open(file_out, 'w')\n",
    "        f.write(\"Neutral,Anger,Disgust,Fear,Happiness,Sadness,Surprise\\n\")\n",
    "        for x in list_out:\n",
    "            f.write(str(x) + \"\\n\")\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "    #df.to_csv(\"C:\\\\Users\\\\sense\\\\Desktop\\\\for_move\\\\sample.csv\")\n",
    "    display([np_test_x.shape, np_test_x.nbytes])\n",
    "    display(df)\n",
    "    #display(list_out)\n",
    "    \n",
    "    \n",
    "    # Neutral,Anger,Disgust,Fear,Happiness,Sadness,Surprise\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
