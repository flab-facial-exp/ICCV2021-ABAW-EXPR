{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.HIGHEST_PROTOCOL = 4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import func_proc_filepath as mFILE\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, GRU, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.utils import Sequence\n",
    "from keras import backend as K\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Callback(Callback):\n",
    "    def __init__(self, model, X_val, y_val, path):\n",
    "        self.model = model\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        self.path = path\n",
    "        self.best_score = -1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pred = self.model.predict(self.X_val)\n",
    "        f1_val = f1_score(self.y_val, np.round(pred), average='macro')\n",
    "        acc_val = accuracy_score(self.y_val, np.round(pred))\n",
    "        score = f1_val*0.67 + acc_val*0.33\n",
    "        log = \"Score = {0}, F1 = {1}, ACC = {2}\".format(score, f1_val, acc_val)\n",
    "        print(log)\n",
    "        # 以下チェックポイントなど必要なら書く\n",
    "        if score > self.best_score:\n",
    "            self.best_score = score\n",
    "            self.model.save(self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_aff2_with_balance(df_data):\n",
    "    df_data.dropna(how='any', inplace=True)\n",
    "    #display(df_data)\n",
    "    \n",
    "    df_0 = df_data.loc[df_data.loc[:,\"expr\"]==0,:]\n",
    "    df_1 = df_data.loc[df_data.loc[:,\"expr\"]==1,:]\n",
    "    df_2 = df_data.loc[df_data.loc[:,\"expr\"]==2,:]\n",
    "    df_3 = df_data.loc[df_data.loc[:,\"expr\"]==3,:]\n",
    "    df_4 = df_data.loc[df_data.loc[:,\"expr\"]==4,:]\n",
    "    df_5 = df_data.loc[df_data.loc[:,\"expr\"]==5,:]\n",
    "    df_6 = df_data.loc[df_data.loc[:,\"expr\"]==6,:]\n",
    "\n",
    "    df_0 = df_0[::4]\n",
    "    df_1 = pd.concat([df_1,df_1],axis=0)\n",
    "    df_2 = pd.concat([df_2,df_2,df_2,df_2],axis=0)\n",
    "    df_3 = pd.concat([df_3,df_3,df_3,df_3],axis=0)\n",
    "    df_4 = df_4[::3]\n",
    "    df_5 = df_5[::2]\n",
    "    df_m = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6],axis=0)\n",
    "    \n",
    "    return df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y: after one hot encoding\n",
    "def create_gru_model(np_train_x, np_train_y, np_val_x, np_val_y, n_class, n_units=64, drop=0.5, lr=1e-4, \n",
    "                     batch=128, model_path=\"\"):\n",
    "    # ** fix random seed **\n",
    "    FIX_SEED = 49\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(FIX_SEED)\n",
    "    random.seed(FIX_SEED)\n",
    "    session_conf = tf.compat.v1.ConfigProto()\n",
    "    tf.compat.v1.set_random_seed(FIX_SEED)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    # *********************\n",
    "    \n",
    "    #*********************************************    \n",
    "    # モデルの定義\n",
    "    model = Sequential()\n",
    "    \n",
    "    n_rnn = np_train_x.shape[1]\n",
    "    n_feat = np_train_x.shape[2]\n",
    "    adam = Adam(lr=lr)\n",
    "    \n",
    "    #model.add(Bidirectional(GRU(units=n_units, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=False)))\n",
    "    #model.add(GRU(units=128, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=True))\n",
    "    #model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(GRU(units=n_units, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=False))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=[\"accuracy\", f1])\n",
    "\n",
    "    #model_path = dir_out + \"\\\\model_multi_image_norm\" + footer + \".h5\"\n",
    "    #cb_early = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "    cb_early = EarlyStopping(monitor='val_f1', patience=8, verbose=0, mode='max')\n",
    "    \n",
    "    model.fit(np_train_x, np_train_y,\n",
    "              epochs=30,\n",
    "              batch_size=batch,\n",
    "              validation_data=(np_val_x, np_val_y),\n",
    "              callbacks=[F1Callback(model, np_val_x, np_val_y, model_path), cb_early])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # bestモデルを読み込んで、重みやオプティマイザーを含むモデル全体を再作成\n",
    "    new_model = keras.models.load_model(model_path, custom_objects={'f1':f1})\n",
    "    \n",
    "    pred_nn = new_model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    \n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    del model\n",
    "    del new_model\n",
    "    \n",
    "    return scores_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predict data\n",
    "def eval_pred_each_class(np_true, np_pred, num_class):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    # calc\n",
    "    for i in range(num_class):\n",
    "        # i以外を0、iを1に置き換える\n",
    "        y_true_i = np.where(np_true == i, 1, 0)\n",
    "        y_pred_i = np.where(np_pred == i, 1, 0)\n",
    "\n",
    "        recall_i = recall_score(y_true_i, y_pred_i, average='binary')\n",
    "        precision_i = precision_score(y_true_i, y_pred_i, average='binary')\n",
    "        f1_i = f1_score(y_true_i, y_pred_i, average='binary')\n",
    "        acc_i = accuracy_score(y_true_i, y_pred_i)\n",
    "\n",
    "        df_reslut = pd.DataFrame({\"class\":[i], \"recall\":[recall_i], \"precision\":[precision_i], \n",
    "                                 \"f1\":[f1_i], \"accuracy\":[acc_i]})\n",
    "        #result_i = [recall_i, precision_i, f1_i, acc_i]\n",
    "\n",
    "        result.append(df_reslut)\n",
    "\n",
    "    df_out = pd.concat([x for x in result], axis=0, ignore_index=True)\n",
    "    f1_all = df_out.loc[:, \"f1\"].mean()\n",
    "    recall_all = df_out.loc[:, \"recall\"].mean()\n",
    "    precision_all = df_out.loc[:, \"precision\"].mean()\n",
    "    accuracy_all = df_out.loc[:, \"accuracy\"].mean()\n",
    "    df_all = pd.DataFrame({\"class\":[\"all\"], \"recall\":[recall_all], \"precision\":[precision_all], \n",
    "                                 \"f1\":[f1_all], \"accuracy\":[accuracy_all]})\n",
    "    df_out = pd.concat([df_out, df_all], axis=0, ignore_index=True)\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_train_balance(np_x, np_y):\n",
    "    \n",
    "    ny = np_y.ravel()\n",
    "    \n",
    "    np_x0 = np_x[ny==0,:,:]\n",
    "    np_x0 = np_x0[::2,:,:]\n",
    "    \n",
    "    np_y0 = ny[ny==0]\n",
    "    np_y0 = np_y0[::2]\n",
    "    \n",
    "    np_x1 = np_x[ny==1,:,:]\n",
    "    np_x1 = np.append(np_x1, np_x1, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x1, axis=0)\n",
    "    np_x1 = None\n",
    "    \n",
    "    \n",
    "    np_y1 = ny[ny==1]\n",
    "    np_y1 = np.append(np_y1, np_y1)\n",
    "    np_y0 =  np.append(np_y0, np_y1)\n",
    "    np_y1 = None\n",
    "    \n",
    "    np_x2 = np_x[ny==2,:,:]\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x2, axis=0)\n",
    "    np_x2 = None\n",
    "    \n",
    "    np_y2 = ny[ny==2]\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y0 =  np.append(np_y0, np_y2)\n",
    "    np_y2 = None\n",
    "    \n",
    "    np_x3 = np_x[ny==3,:,:]\n",
    "    np_x3 = np.append(np_x3, np_x3, axis=0)\n",
    "    np_x3 = np.append(np_x3, np_x3, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x3, axis=0)\n",
    "    np_x3 = None\n",
    "    \n",
    "    np_y3 = ny[ny==3]\n",
    "    np_y3 = np.append(np_y3, np_y3)\n",
    "    np_y3 = np.append(np_y3, np_y3)\n",
    "    np_y0 =  np.append(np_y0, np_y3)\n",
    "    np_y3 = None\n",
    "    \n",
    "    np_x4 = np_x[ny==4,:,:]\n",
    "    np_x4 = np_x4[::3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x4, axis=0)\n",
    "    np_x4 = None\n",
    "    \n",
    "    np_y4 = ny[ny==4]\n",
    "    np_y4 = np_y4[::3]\n",
    "    np_y0 =  np.append(np_y0, np_y4)\n",
    "    np_y4 = None\n",
    "    \n",
    "    np_x5 = np_x[ny==5,:,:]\n",
    "    np_x5 = np_x5[::2,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x5, axis=0)\n",
    "    np_x5 = None\n",
    "    \n",
    "    np_y5 = ny[ny==5]\n",
    "    np_y5 = np_y5[::2]\n",
    "    np_y0 =  np.append(np_y0, np_y5)\n",
    "    np_y5 = None\n",
    "    \n",
    "    np_x6 = np_x[ny==6,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x6, axis=0)\n",
    "    np_x6 = None\n",
    "    \n",
    "    np_y6 = ny[ny==6]\n",
    "    np_y0 =  np.append(np_y0, np_y6)\n",
    "    np_y6 = None\n",
    "    \n",
    "    np_x = None\n",
    "    np_y = None\n",
    "    ny = None\n",
    "    \n",
    "    p =np.random.RandomState(seed=49).permutation(len(np_x0))\n",
    "    np_x0 = np_x0[p]\n",
    "    np_y0 = np_y0[p]\n",
    "    \n",
    "    \n",
    "    return np_x0, np_y0.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_val_balance(np_x, np_y): #::7, 1, *2, 1, ::4, ::3, ::2\n",
    "    \n",
    "    ny = np_y.ravel()\n",
    "    \n",
    "    np_x0 = np_x[ny==0,:,:]\n",
    "    np_x0 = np_x0[::3,:,:]\n",
    "    \n",
    "    np_y0 = ny[ny==0]\n",
    "    np_y0 = np_y0[::3]\n",
    "    \n",
    "    np_x1 = np_x[ny==1,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x1, axis=0)\n",
    "    np_x1 = None\n",
    "    \n",
    "    \n",
    "    np_y1 = ny[ny==1]\n",
    "    np_y0 =  np.append(np_y0, np_y1)\n",
    "    np_y1 = None\n",
    "    \n",
    "    np_x2 = np_x[ny==2,:,:]\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x2, axis=0)\n",
    "    np_x2 = None\n",
    "    \n",
    "    np_y2 = ny[ny==2]\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y0 =  np.append(np_y0, np_y2)\n",
    "    np_y2 = None\n",
    "    \n",
    "    np_x3 = np_x[ny==3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x3, axis=0)\n",
    "    np_x3 = None\n",
    "    \n",
    "    np_y3 = ny[ny==3]\n",
    "    np_y0 =  np.append(np_y0, np_y3)\n",
    "    np_y3 = None\n",
    "    \n",
    "    np_x4 = np_x[ny==4,:,:]\n",
    "    np_x4 = np_x4[::4,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x4, axis=0)\n",
    "    np_x4 = None\n",
    "    \n",
    "    np_y4 = ny[ny==4]\n",
    "    np_y4 = np_y4[::4]\n",
    "    np_y0 =  np.append(np_y0, np_y4)\n",
    "    np_y4 = None\n",
    "    \n",
    "    np_x5 = np_x[ny==5,:,:]\n",
    "    np_x5 = np_x5[::3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x5, axis=0)\n",
    "    np_x5 = None\n",
    "    \n",
    "    np_y5 = ny[ny==5]\n",
    "    np_y5 = np_y5[::3]\n",
    "    np_y0 =  np.append(np_y0, np_y5)\n",
    "    np_y5 = None\n",
    "    \n",
    "    np_x6 = np_x[ny==6,:,:]\n",
    "    np_x6 = np_x6[::2,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x6, axis=0)\n",
    "    np_x6 = None\n",
    "    \n",
    "    np_y6 = ny[ny==6]\n",
    "    np_y6 = np_y6[::2]\n",
    "    np_y0 =  np.append(np_y0, np_y6)\n",
    "    np_y6 = None\n",
    "    \n",
    "    np_x = None\n",
    "    np_y = None\n",
    "    ny = None\n",
    "    \n",
    "    #p = np.random.permutation(len(np_x0))\n",
    "    p =np.random.RandomState(seed=49).permutation(len(np_x0))\n",
    "    np_x0 = np_x0[p]\n",
    "    np_y0 = np_y0[p]\n",
    "    \n",
    "    \n",
    "    return np_x0, np_y0.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_read_separate(file_list, dir_data, pre_model, transformer, balance=0, sep_num=5, ignore_feat=False):\n",
    "    \n",
    "    step = -(-len(file_list) // sep_num)\n",
    "    \n",
    "    np_x_out_list = []\n",
    "    np_y_out_list = []\n",
    "    \n",
    "    for s in range(sep_num):\n",
    "        \n",
    "        start = step*s\n",
    "        stop = step*(s+1)\n",
    "        if stop>len(file_list):\n",
    "            stop = len(file_list)\n",
    "            \n",
    "        file_list_sep = file_list[start:stop]\n",
    "        \n",
    "        np_x_list = []\n",
    "        np_y_list = []\n",
    "\n",
    "        for i in tqdm(range(len(file_list_sep))):\n",
    "            name = os.path.splitext(os.path.basename(file_list_sep[i]))[0]\n",
    "\n",
    "            df_label = pd.read_csv(file_list_sep[i])\n",
    "            #display(df_label)\n",
    "            df_label = df_label.drop([\"Anger\",\"Disgust\",\"Fear\",\"Happiness\",\"Sadness\",\"Surprise\"],axis=1)\n",
    "            df_label.columns = [\"expr\"]\n",
    "            df_label[\"frame\"] = df_label.index\n",
    "\n",
    "            df_data = pd.read_hdf(dir_data + \"\\\\\" + name + \".h5\")\n",
    "            #display(df_data)\n",
    "\n",
    "            df_merge = pd.merge(df_label, df_data, on=\"frame\", how=\"outer\")\n",
    "            # interpolate 30 frame back\n",
    "            df_merge.interpolate(method=\"index\", limit=30, limit_direction='backward', inplace=True)\n",
    "            #df_merge.fillna(0, inplace=True)\n",
    "            #df_merge = df_merge.loc[df_merge.loc[:,\"expr\"]>=0,:]\n",
    "\n",
    "            np_x = df_merge.loc[:, df_merge.columns.str.contains(\"AU|pose_R|gaze|vgg-\")].values\n",
    "            np_y = df_merge.loc[:, df_merge.columns.str.contains(\"expr\")].values\n",
    "            pre_x = pre_model.predict(np_x)\n",
    "\n",
    "            # normalize by single subject\n",
    "            np_mean_sub = np.nanmean(pre_x, axis=0)\n",
    "            np_std_sub = np.nanstd(pre_x, axis=0, ddof=1)\n",
    "            np_x_sub = (pre_x - np_mean_sub)/np_std_sub\n",
    "            df_sub = pd.DataFrame(np_x_sub)\n",
    "            df_sub.replace(np.inf, 9999, inplace=True)\n",
    "            df_sub.fillna(0, inplace=True)\n",
    "            df_sub.mask(df_sub > 5, 5, inplace=True)\n",
    "            df_sub.columns = [\"sub-\" + str(n) for n in df_sub.columns.values]\n",
    "            # ***************\n",
    "\n",
    "            df = pd.DataFrame(pre_x)\n",
    "            #df = pd.concat([df, df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "            df = pd.concat([df, df_sub, df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "\n",
    "            batch_length = 90\n",
    "            feat_size = 600\n",
    "            np_x_tmp_list = []\n",
    "            np_y_tmp_list = []\n",
    "            for i in range(len(df)):\n",
    "                label = df.at[i, \"expr\"]\n",
    "                if label >= 0:            \n",
    "                    if ignore_feat==True:\n",
    "                        np_tmp = np.zeros((batch_length, feat_size))\n",
    "                        #np_tmp2 = df_feat.iloc[i-batch_length+1:i+1, :].values\n",
    "                        if i-batch_length+1 < 0:\n",
    "                            np_tmp = np.zeros((batch_length-i-1, feat_size))\n",
    "                            np_tmp2 = df.iloc[0:i+1, 0:feat_size].values\n",
    "                            np_tmp = np.append(np_tmp, np_tmp2, axis=0)\n",
    "                        else:\n",
    "                            np_tmp = df.iloc[i-batch_length+1:i+1, 0:feat_size].values\n",
    "\n",
    "                        np_tmp = np_tmp.astype(np.float32)\n",
    "                        #np_tmp = np_tmp[::5,:]\n",
    "                        np_tmp = np_tmp[np.newaxis, ::6, :]\n",
    "                        np_tmp = np.nan_to_num(np_tmp)\n",
    "\n",
    "                        np_x_tmp_list.append(np_tmp)\n",
    "                        np_y_tmp_list.append(label)\n",
    "                    else:\n",
    "                        if df.at[i,0]!=np.nan:\n",
    "                            np_tmp = np.zeros((batch_length, feat_size))\n",
    "                            #np_tmp2 = df_feat.iloc[i-batch_length+1:i+1, :].values\n",
    "                            if i-batch_length+1 < 0:\n",
    "                                np_tmp = np.zeros((batch_length-i-1, feat_size))\n",
    "                                np_tmp2 = df.iloc[0:i+1, 0:feat_size].values\n",
    "                                np_tmp = np.append(np_tmp, np_tmp2, axis=0)\n",
    "                            else:\n",
    "                                np_tmp = df.iloc[i-batch_length+1:i+1, 0:feat_size].values\n",
    "\n",
    "                            np_tmp = np_tmp.astype(np.float32)\n",
    "                            #np_tmp = np_tmp[::5,:]\n",
    "                            np_tmp = np_tmp[np.newaxis, ::6, :]\n",
    "                            np_tmp = np.nan_to_num(np_tmp)\n",
    "\n",
    "                            np_x_tmp_list.append(np_tmp)\n",
    "                            np_y_tmp_list.append(label)\n",
    "\n",
    "            if len(np_x_tmp_list) > 0:\n",
    "                np_x_tmp = np.concatenate([x for x in np_x_tmp_list], 0)\n",
    "                np_y_tmp = np.array(np_y_tmp_list)\n",
    "                np_x_list.append(np_x_tmp)\n",
    "                np_y_list.append(np_y_tmp)\n",
    "\n",
    "        # finish\n",
    "        np_data_x = np.concatenate([x for x in np_x_list], 0)\n",
    "        np_data_y = np.concatenate([x for x in np_y_list], 0).reshape(-1,1)\n",
    "        #np_data_y = np.concatenate([x for x in np_y_list], 0)\n",
    "\n",
    "        if balance == 1:\n",
    "            # balance and shuffle\n",
    "            np_data_x, np_data_y = np_train_balance(np_data_x, np_data_y)\n",
    "        elif balance == 2:\n",
    "            # balance and shuffle\n",
    "            np_data_x, np_data_y = np_val_balance(np_data_x, np_data_y)\n",
    "        \n",
    "        np_x_out_list.append(np_data_x)\n",
    "        np_y_out_list.append(np_data_y)\n",
    "        \n",
    "    np_data_x = np.concatenate([x for x in np_x_out_list], 0)\n",
    "    np_data_y = np.concatenate([x for x in np_y_out_list], 0).reshape(-1,1) \n",
    "        \n",
    "    np_data_y = transformer.transform(np_data_y).toarray()\n",
    "    \n",
    "    return np_data_x, np_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # root folder\n",
    "    dir_root = str(Path(Path().resolve()).parent)\n",
    "\n",
    "    # input: folder path including original images\n",
    "    dir_data = dir_root + \"\\\\dataset\\\\aff2_images\\\\dataset\"    \n",
    "\n",
    "    # input: expr labels\n",
    "    dir_label_train = dir_root + \"\\\\src\\\\annotations\\\\EXPR_Set\\\\Train_Set\"\n",
    "    dir_label_val = dir_root + \"\\\\src\\\\annotations\\\\EXPR_Set\\\\Validation_Set\"\n",
    "    \n",
    "    # output: folder path\n",
    "    dir_out = dir_root + \"\\\\model_expr\\\\model_image\"\n",
    "    if os.path.isdir(dir_out) == False:\n",
    "        os.makedirs(dir_out)\n",
    "        \n",
    "    model_path_base = \"model_image_multi_norm\"\n",
    "    model_path_base_pre = \"model_image_single_pseudo\"\n",
    "        \n",
    "    # pre_model\n",
    "    file_pre_model = dir_out + \"\\\\\"  + model_path_base_pre + \"_best.h5\"\n",
    "    base_model = keras.models.load_model(file_pre_model, custom_objects={'f1':f1})\n",
    "    layer_name = 'vgg_au'\n",
    "    pre_model = Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)  \n",
    "    # *****\n",
    "    \n",
    "    train_list = mFILE.search_files(dir_label_train, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)    \n",
    "    val_list = mFILE.search_files(dir_label_val, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)\n",
    "    \n",
    "    dummy = [[0],[1],[2],[3],[4],[5],[6]]\n",
    "    transformer = OneHotEncoder().fit(dummy)\n",
    "    #np_train_y_hot = transformer.transform(np_train_y).toarray()\n",
    "    #np_val_y_hot = transformer.transform(np_val_y).toarray()\n",
    "    \n",
    "    len_train = len(train_list)\n",
    "    len_val = len(val_list)\n",
    "    #len_train = 2\n",
    "    #len_val = 1\n",
    "    \n",
    "    np_train_x, np_train_y = data_read_separate(train_list, dir_data, pre_model, transformer, balance=1, sep_num=5)\n",
    "    \n",
    "    print(np_train_x.shape)\n",
    "    print(np_train_y.shape)\n",
    "    print(np_train_x.nbytes, np_train_y.nbytes)\n",
    "    \n",
    "    np_val_x, np_val_y = data_read_separate(val_list, dir_data, pre_model, transformer, balance=2, sep_num=5)\n",
    "    \n",
    "    print(np_val_x.shape)\n",
    "    print(np_val_y.shape)\n",
    "    print(np_val_x.nbytes, np_val_y.nbytes)\n",
    "\n",
    "    len_feat = np_val_x.shape[2]\n",
    "    len_class = np_val_y.shape[1]\n",
    "    display(len_class)\n",
    "    \n",
    "    # search parameter\n",
    "    score_list = []\n",
    "    #***\n",
    "    \n",
    "    l_units = [64, 128]\n",
    "    l_drop = [0.3, 0.5]\n",
    "    l_lr = [1e-4, 1e-3]\n",
    "    l_batch = [128, 256]\n",
    "    MAX_COUNT = len(l_units)*len(l_drop)*len(l_lr)*len(l_batch)\n",
    "    COUNT = 0\n",
    "    \n",
    "    for _units in l_units:\n",
    "        for _drop in l_drop:\n",
    "            for _lr in l_lr:\n",
    "                for _batch in l_batch:\n",
    "                    model_path = dir_out + \"\\\\\" + model_path_base + \"_{0:02d}.h5\".format(COUNT)\n",
    "                    scores = create_gru_model(np_train_x, np_train_y, np_val_x, np_val_y, len_class,\n",
    "                                              n_units=_units, drop=_drop, lr=_lr, batch=_batch,\n",
    "                                              model_path=model_path)\n",
    "                    param = [COUNT, _units, _drop, _lr, _batch]\n",
    "                    param.extend(scores)\n",
    "                    score_list.append(param)\n",
    "                    COUNT = COUNT + 1\n",
    "        \n",
    "        \n",
    "    # ******************* validation balances frames  ********************\n",
    "    print(score_list)\n",
    "    \n",
    "    df_res = pd.DataFrame(score_list, columns = [\"id\", \"units\", \"drop\", \"lr\", \"batch\", \"score\", \"f1\", \"acc\"])\n",
    "    display(df_res)\n",
    "    file_out = dir_out + \"\\\\res0_\" + model_path_base + \".csv\"\n",
    "    df_res.to_csv(file_out, index=False)\n",
    "    \n",
    "    best_id = df_res.loc[:,\"score\"].idxmax()\n",
    "    \n",
    "    best_path = dir_out + \"\\\\\" + model_path_base + \"_{0:02d}.h5\".format(best_id)\n",
    "    out_path = dir_out + \"\\\\\" + model_path_base + \"_best.h5\"\n",
    "    #best_path = dir_out + \"\\\\model_image_multi_b2_norm\" + \"_{0:02d}.h5\".format(best_id)\n",
    "    #out_path = dir_out + \"\\\\model_image_multi2_b2_norm_best.h5\"\n",
    "    shutil.copy(best_path, out_path)\n",
    "    \n",
    "    \n",
    "    np_x_list = None\n",
    "    np_y_list = None\n",
    "    np_train_x = None\n",
    "    np_train_y = None\n",
    "    np_val_x = None\n",
    "    np_val_y = None\n",
    "    \n",
    "    # ******************* validation all frames  ********************\n",
    "    \n",
    "    #file_model = dir_out + \"\\\\model_image_multi_best.h5\"\n",
    "    model = keras.models.load_model(out_path, custom_objects={'f1':f1})\n",
    "    model.summary()\n",
    "    # *****\n",
    "    \n",
    "    np_val_x, np_val_y = data_read_separate(val_list, dir_data, pre_model, transformer, \n",
    "                                            balance=0, sep_num=5, ignore_feat=True)\n",
    "    \n",
    "    print(np_val_x.shape)\n",
    "    print(np_val_y.shape)\n",
    "    print(np_val_x.nbytes, np_val_y.nbytes)\n",
    "    \n",
    "    len_feat = np_val_x.shape[2]\n",
    "    len_class = np_val_y.shape[1]\n",
    "    display(len_class)\n",
    "    \n",
    "    pred_nn = model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    df_out = eval_pred_each_class(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), 7)\n",
    "    display(df_out)\n",
    "    \n",
    "    file_out = dir_out + \"\\\\res1_\" + model_path_base + \".csv\"\n",
    "    df_out.to_csv(file_out, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [03:07<00:00,  3.68s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [01:57<00:00,  2.31s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [01:38<00:00,  1.92s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [02:50<00:00,  3.34s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [03:15<00:00,  3.99s/it]\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327818, 10, 600)\n",
      "(327818, 7)\n",
      "7867632000 18357808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:00<00:00,  4.34s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:12<00:00,  5.20s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:44<00:00,  3.19s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:54<00:00,  3.86s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:53<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88136, 10, 600)\n",
      "(88136, 7)\n",
      "2115264000 4935616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 69s 210us/step - loss: 0.8088 - accuracy: 0.7276 - f1: 0.6865 - val_loss: 1.6470 - val_accuracy: 0.4842 - val_f1: 0.4704\n",
      "Score = 0.39760267312506453, F1 = 0.3840849961618118, ACC = 0.42504765362621405\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.4558 - accuracy: 0.8495 - f1: 0.8472 - val_loss: 1.8788 - val_accuracy: 0.4894 - val_f1: 0.4807\n",
      "Score = 0.41210076420794767, F1 = 0.3925688954626377, ACC = 0.4517563765090315\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.3765 - accuracy: 0.8747 - f1: 0.8743 - val_loss: 2.0289 - val_accuracy: 0.4906 - val_f1: 0.4851\n",
      "Score = 0.4182783994629014, F1 = 0.396524994192528, ACC = 0.4624444041027503\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.3322 - accuracy: 0.8898 - f1: 0.8898 - val_loss: 2.1350 - val_accuracy: 0.4956 - val_f1: 0.4919\n",
      "Score = 0.4237597408599227, F1 = 0.3995200856551094, ACC = 0.47297358627575564\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 69s 209us/step - loss: 0.3001 - accuracy: 0.9001 - f1: 0.9003 - val_loss: 2.2141 - val_accuracy: 0.4935 - val_f1: 0.4894\n",
      "Score = 0.4213940276532706, F1 = 0.39690007609082867, ACC = 0.471124171734592\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 66s 203us/step - loss: 0.2756 - accuracy: 0.9085 - f1: 0.9089 - val_loss: 2.3168 - val_accuracy: 0.4866 - val_f1: 0.4837\n",
      "Score = 0.41238070981107694, F1 = 0.385643595581406, ACC = 0.46666515385313606\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 65s 199us/step - loss: 0.2557 - accuracy: 0.9147 - f1: 0.9152 - val_loss: 2.3836 - val_accuracy: 0.4970 - val_f1: 0.4950\n",
      "Score = 0.4250665075281529, F1 = 0.398391287201687, ACC = 0.4792252881909776\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 66s 201us/step - loss: 0.2402 - accuracy: 0.9201 - f1: 0.9204 - val_loss: 2.4817 - val_accuracy: 0.4871 - val_f1: 0.4867\n",
      "Score = 0.4146893471230434, F1 = 0.38648513860594946, ACC = 0.4719524371425978\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.2269 - accuracy: 0.9252 - f1: 0.9253 - val_loss: 2.5611 - val_accuracy: 0.4854 - val_f1: 0.4846\n",
      "Score = 0.4131138235517665, F1 = 0.38446332520972487, ACC = 0.47128301715530546\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 67s 203us/step - loss: 0.2153 - accuracy: 0.9292 - f1: 0.9295 - val_loss: 2.6060 - val_accuracy: 0.4890 - val_f1: 0.4884\n",
      "Score = 0.41621625503407034, F1 = 0.3866964056512869, ACC = 0.4761504946900245\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.2038 - accuracy: 0.9324 - f1: 0.9328 - val_loss: 2.6692 - val_accuracy: 0.4878 - val_f1: 0.4871\n",
      "Score = 0.4145215903412732, F1 = 0.38469236292755254, ACC = 0.47508396115094853\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 66s 203us/step - loss: 0.1943 - accuracy: 0.9357 - f1: 0.9361 - val_loss: 2.7403 - val_accuracy: 0.4901 - val_f1: 0.4893\n",
      "Score = 0.41567313124847766, F1 = 0.3847457439539813, ACC = 0.47846509939184895\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 66s 201us/step - loss: 0.1878 - accuracy: 0.9382 - f1: 0.9386 - val_loss: 2.8054 - val_accuracy: 0.4888 - val_f1: 0.4884\n",
      "Score = 0.4166587114917204, F1 = 0.3864458827543705, ACC = 0.4779999092311882\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 66s 202us/step - loss: 0.1803 - accuracy: 0.9406 - f1: 0.9411 - val_loss: 2.8361 - val_accuracy: 0.4879 - val_f1: 0.4875\n",
      "Score = 0.4165000450073074, F1 = 0.38623142061935567, ACC = 0.47795452482527\n",
      "Epoch 15/30\n",
      "327818/327818 [==============================] - 66s 203us/step - loss: 0.1727 - accuracy: 0.9426 - f1: 0.9429 - val_loss: 2.9248 - val_accuracy: 0.4915 - val_f1: 0.4911\n",
      "Score = 0.4202275329559281, F1 = 0.3898612565621731, ACC = 0.48188027593718796\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.434864176020188, 0.40424091901585085, 0.49703866751384224]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.9385 - accuracy: 0.6818 - f1: 0.6226 - val_loss: 1.5277 - val_accuracy: 0.4887 - val_f1: 0.4670\n",
      "Score = 0.3910383314357231, F1 = 0.3825191525481462, ACC = 0.40833484614686394\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.5220 - accuracy: 0.8290 - f1: 0.8235 - val_loss: 1.6922 - val_accuracy: 0.4934 - val_f1: 0.4814\n",
      "Score = 0.4130356931362633, F1 = 0.3974905785065161, ACC = 0.44459698647544704\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.4294 - accuracy: 0.8574 - f1: 0.8561 - val_loss: 1.8493 - val_accuracy: 0.4916 - val_f1: 0.4814\n",
      "Score = 0.41605405228020476, F1 = 0.3972287054296027, ACC = 0.4542752110374875\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.3771 - accuracy: 0.8748 - f1: 0.8743 - val_loss: 1.9743 - val_accuracy: 0.4928 - val_f1: 0.4875\n",
      "Score = 0.41865175472438754, F1 = 0.3962439841003628, ACC = 0.46414631932468003\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 36s 111us/step - loss: 0.3421 - accuracy: 0.8861 - f1: 0.8863 - val_loss: 2.0489 - val_accuracy: 0.4955 - val_f1: 0.4910\n",
      "Score = 0.4237444412325634, F1 = 0.4012631779460441, ACC = 0.46938821820822363\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.3159 - accuracy: 0.8952 - f1: 0.8953 - val_loss: 2.1448 - val_accuracy: 0.4899 - val_f1: 0.4870\n",
      "Score = 0.41904148807640373, F1 = 0.3950597481148862, ACC = 0.46773168739221205\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.2944 - accuracy: 0.9023 - f1: 0.9026 - val_loss: 2.2133 - val_accuracy: 0.4908 - val_f1: 0.4886\n",
      "Score = 0.4190941399833166, F1 = 0.39348417306174027, ACC = 0.4710901334301534\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.2773 - accuracy: 0.9080 - f1: 0.9083 - val_loss: 2.2693 - val_accuracy: 0.4891 - val_f1: 0.4862\n",
      "Score = 0.4188436154607076, F1 = 0.39356850288775086, ACC = 0.4701597531088318\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.2631 - accuracy: 0.9131 - f1: 0.9132 - val_loss: 2.3277 - val_accuracy: 0.4900 - val_f1: 0.4862\n",
      "Score = 0.41948872811145277, F1 = 0.394307822456729, ACC = 0.4706135971680131\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 36s 111us/step - loss: 0.2499 - accuracy: 0.9173 - f1: 0.9177 - val_loss: 2.3922 - val_accuracy: 0.4906 - val_f1: 0.4887\n",
      "Score = 0.420781036969178, F1 = 0.39451542111843885, ACC = 0.4741081964237088\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.2378 - accuracy: 0.9212 - f1: 0.9218 - val_loss: 2.4338 - val_accuracy: 0.4945 - val_f1: 0.4918\n",
      "Score = 0.4237451680628733, F1 = 0.3970618022552222, ACC = 0.47792048652083147\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 36s 111us/step - loss: 0.2266 - accuracy: 0.9248 - f1: 0.9253 - val_loss: 2.4665 - val_accuracy: 0.4949 - val_f1: 0.4921\n",
      "Score = 0.4248389565590676, F1 = 0.39825284050988335, ACC = 0.47881682853771446\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.2194 - accuracy: 0.9272 - f1: 0.9279 - val_loss: 2.4942 - val_accuracy: 0.5005 - val_f1: 0.4986\n",
      "Score = 0.43281939747301323, F1 = 0.4065370888085017, ACC = 0.48618044839793045\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 37s 111us/step - loss: 0.2101 - accuracy: 0.9310 - f1: 0.9313 - val_loss: 2.5790 - val_accuracy: 0.4957 - val_f1: 0.4938\n",
      "Score = 0.4264233129302939, F1 = 0.3989242728744922, ACC = 0.4822546972860125\n",
      "Epoch 15/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.2013 - accuracy: 0.9334 - f1: 0.9338 - val_loss: 2.6167 - val_accuracy: 0.4950 - val_f1: 0.4923\n",
      "Score = 0.42543722320851773, F1 = 0.39807839554450314, ACC = 0.480983933920305\n",
      "Epoch 16/30\n",
      "327818/327818 [==============================] - 36s 111us/step - loss: 0.1943 - accuracy: 0.9360 - f1: 0.9362 - val_loss: 2.6618 - val_accuracy: 0.4958 - val_f1: 0.4940\n",
      "Score = 0.4253673056480377, F1 = 0.39696254449696206, ACC = 0.48303757828810023\n",
      "Epoch 17/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.1883 - accuracy: 0.9377 - f1: 0.9382 - val_loss: 2.7262 - val_accuracy: 0.4936 - val_f1: 0.4917\n",
      "Score = 0.4230250475938787, F1 = 0.394187537759387, ACC = 0.4815739311972406\n",
      "Epoch 18/30\n",
      "327818/327818 [==============================] - 36s 111us/step - loss: 0.1817 - accuracy: 0.9398 - f1: 0.9400 - val_loss: 2.7532 - val_accuracy: 0.4929 - val_f1: 0.4911\n",
      "Score = 0.42379085213826967, F1 = 0.3956937742088302, ACC = 0.48083643460107106\n",
      "Epoch 19/30\n",
      "327818/327818 [==============================] - 36s 111us/step - loss: 0.1771 - accuracy: 0.9416 - f1: 0.9417 - val_loss: 2.7458 - val_accuracy: 0.4933 - val_f1: 0.4914\n",
      "Score = 0.42244494012941436, F1 = 0.393372001127939, ACC = 0.4814718162839248\n",
      "Epoch 20/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.1732 - accuracy: 0.9427 - f1: 0.9430 - val_loss: 2.7994 - val_accuracy: 0.4936 - val_f1: 0.4923\n",
      "Score = 0.42381370858610057, F1 = 0.3948002175055199, ACC = 0.4827198874466733\n",
      "Epoch 21/30\n",
      "327818/327818 [==============================] - 36s 111us/step - loss: 0.1667 - accuracy: 0.9447 - f1: 0.9450 - val_loss: 2.8986 - val_accuracy: 0.4902 - val_f1: 0.4885\n",
      "Score = 0.41914183477464173, F1 = 0.3897943806941819, ACC = 0.4787260597258782\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.44119176328633136, 0.4119973888556914, 0.5004651901606608]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 68s 206us/step - loss: 0.4268 - accuracy: 0.8566 - f1: 0.8520 - val_loss: 2.1315 - val_accuracy: 0.5050 - val_f1: 0.5006\n",
      "Score = 0.4413145078144697, F1 = 0.4219378982267584, ACC = 0.48065489697739855\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.2856 - accuracy: 0.9040 - f1: 0.9046 - val_loss: 2.4823 - val_accuracy: 0.4851 - val_f1: 0.4838\n",
      "Score = 0.4176000675667807, F1 = 0.3921762966572993, ACC = 0.4692180266860307\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 66s 200us/step - loss: 0.2555 - accuracy: 0.9145 - f1: 0.9151 - val_loss: 2.5824 - val_accuracy: 0.4803 - val_f1: 0.4786\n",
      "Score = 0.41599020940639453, F1 = 0.3918076929995907, ACC = 0.46508804574748114\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 67s 205us/step - loss: 0.2396 - accuracy: 0.9202 - f1: 0.9206 - val_loss: 2.6324 - val_accuracy: 0.5029 - val_f1: 0.5017\n",
      "Score = 0.4381360184364499, F1 = 0.4128852445290613, ACC = 0.48940274121811744\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 67s 205us/step - loss: 0.2291 - accuracy: 0.9233 - f1: 0.9238 - val_loss: 2.8788 - val_accuracy: 0.4787 - val_f1: 0.4795\n",
      "Score = 0.41259544316966623, F1 = 0.38540525529747277, ACC = 0.46779976400108925\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 67s 203us/step - loss: 0.2232 - accuracy: 0.9262 - f1: 0.9265 - val_loss: 2.8597 - val_accuracy: 0.4831 - val_f1: 0.4818\n",
      "Score = 0.41637592288662895, F1 = 0.38951654667237345, ACC = 0.47090859580648087\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 67s 203us/step - loss: 0.2198 - accuracy: 0.9267 - f1: 0.9274 - val_loss: 2.8525 - val_accuracy: 0.4851 - val_f1: 0.4838\n",
      "Score = 0.41497501958059513, F1 = 0.38688357351656205, ACC = 0.47200916764999545\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 67s 203us/step - loss: 0.2154 - accuracy: 0.9286 - f1: 0.9290 - val_loss: 2.7696 - val_accuracy: 0.4889 - val_f1: 0.4867\n",
      "Score = 0.4247237569437029, F1 = 0.39960093969411925, ACC = 0.47573068893528186\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.2128 - accuracy: 0.9292 - f1: 0.9297 - val_loss: 2.9312 - val_accuracy: 0.4790 - val_f1: 0.4772\n",
      "Score = 0.4119955979637532, F1 = 0.38519174610292495, ACC = 0.46641553962058635\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.2111 - accuracy: 0.9299 - f1: 0.9303 - val_loss: 2.9211 - val_accuracy: 0.4782 - val_f1: 0.4776\n",
      "Score = 0.41295166840055386, F1 = 0.3863560631221087, ACC = 0.46694880639012437\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 66s 202us/step - loss: 0.2108 - accuracy: 0.9305 - f1: 0.9311 - val_loss: 2.8512 - val_accuracy: 0.4850 - val_f1: 0.4851\n",
      "Score = 0.41797340080079215, F1 = 0.38969343262208433, ACC = 0.47539030589089587\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 67s 205us/step - loss: 0.2058 - accuracy: 0.9318 - f1: 0.9321 - val_loss: 2.9301 - val_accuracy: 0.4760 - val_f1: 0.4750\n",
      "Score = 0.4154678234880923, F1 = 0.3905641771222375, ACC = 0.4660297721702823\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4559386309735445, 0.43176669942050744, 0.505014976853953]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.4511 - accuracy: 0.8497 - f1: 0.8427 - val_loss: 2.0607 - val_accuracy: 0.5040 - val_f1: 0.4975\n",
      "Score = 0.4370450985433575, F1 = 0.417806585297914, ACC = 0.4761051102841064\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.2807 - accuracy: 0.9060 - f1: 0.9064 - val_loss: 2.2200 - val_accuracy: 0.5183 - val_f1: 0.5134\n",
      "Score = 0.45638634034141745, F1 = 0.43591089368552477, ACC = 0.4979577017336843\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.2429 - accuracy: 0.9189 - f1: 0.9192 - val_loss: 2.4151 - val_accuracy: 0.4996 - val_f1: 0.4960\n",
      "Score = 0.4369011509864752, F1 = 0.4139760574116795, ACC = 0.48344603794136337\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.2235 - accuracy: 0.9255 - f1: 0.9260 - val_loss: 2.5010 - val_accuracy: 0.4967 - val_f1: 0.4938\n",
      "Score = 0.43248874255584396, F1 = 0.4094413080378808, ACC = 0.4792820186983752\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.2108 - accuracy: 0.9295 - f1: 0.9298 - val_loss: 2.5977 - val_accuracy: 0.5004 - val_f1: 0.4973\n",
      "Score = 0.4358499814752581, F1 = 0.41150183040225735, ACC = 0.48528410638104746\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.2018 - accuracy: 0.9330 - f1: 0.9333 - val_loss: 2.8481 - val_accuracy: 0.4914 - val_f1: 0.4867\n",
      "Score = 0.42371880502040915, F1 = 0.3986151422577384, ACC = 0.4746868475991649\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.1970 - accuracy: 0.9348 - f1: 0.9352 - val_loss: 2.7698 - val_accuracy: 0.4941 - val_f1: 0.4924\n",
      "Score = 0.43603818156577256, F1 = 0.41426396604299687, ACC = 0.4802464373241354\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.1926 - accuracy: 0.9363 - f1: 0.9367 - val_loss: 2.7344 - val_accuracy: 0.4992 - val_f1: 0.4968\n",
      "Score = 0.4413038374720999, F1 = 0.4193960253326438, ACC = 0.4857833348461469\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.1887 - accuracy: 0.9376 - f1: 0.9378 - val_loss: 2.8295 - val_accuracy: 0.4949 - val_f1: 0.4929\n",
      "Score = 0.4311854110712344, F1 = 0.40627218230872364, ACC = 0.48176681492239265\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.1846 - accuracy: 0.9388 - f1: 0.9389 - val_loss: 2.8343 - val_accuracy: 0.5038 - val_f1: 0.5022\n",
      "Score = 0.44387751633004946, F1 = 0.42076727383435303, ACC = 0.49079831170009985\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4702918181733551, 0.4466621409810148, 0.5182672233820459]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 1.1534 - accuracy: 0.5958 - f1: 0.5329 - val_loss: 1.5228 - val_accuracy: 0.4940 - val_f1: 0.4707\n",
      "Score = 0.3986441887382681, F1 = 0.3919375994669702, ACC = 0.4122605972587819\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 69s 211us/step - loss: 0.7135 - accuracy: 0.7613 - f1: 0.7509 - val_loss: 1.7049 - val_accuracy: 0.4970 - val_f1: 0.4840\n",
      "Score = 0.4195544855232918, F1 = 0.40576714101410516, ACC = 0.44754697286012524\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 70s 212us/step - loss: 0.6107 - accuracy: 0.7969 - f1: 0.7924 - val_loss: 1.8097 - val_accuracy: 0.4996 - val_f1: 0.4888\n",
      "Score = 0.4270742823996807, F1 = 0.41172646604464497, ACC = 0.4582350004538441\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 68s 209us/step - loss: 0.5537 - accuracy: 0.8166 - f1: 0.8141 - val_loss: 1.9039 - val_accuracy: 0.4979 - val_f1: 0.4904\n",
      "Score = 0.42728189618078466, F1 = 0.4093427389995251, ACC = 0.4637038213669783\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 69s 210us/step - loss: 0.5142 - accuracy: 0.8299 - f1: 0.8285 - val_loss: 1.9688 - val_accuracy: 0.5001 - val_f1: 0.4916\n",
      "Score = 0.42927536885187356, F1 = 0.4109433302726303, ACC = 0.46649496233094306\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 69s 212us/step - loss: 0.4807 - accuracy: 0.8414 - f1: 0.8406 - val_loss: 2.0594 - val_accuracy: 0.4977 - val_f1: 0.4931\n",
      "Score = 0.4299934400704254, F1 = 0.4098188456721398, ACC = 0.47095398021239904\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.4543 - accuracy: 0.8505 - f1: 0.8497 - val_loss: 2.1403 - val_accuracy: 0.4964 - val_f1: 0.4921\n",
      "Score = 0.42864437824493684, F1 = 0.4075147248857558, ACC = 0.4715439774893347\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.4319 - accuracy: 0.8584 - f1: 0.8578 - val_loss: 2.2194 - val_accuracy: 0.4956 - val_f1: 0.4919\n",
      "Score = 0.4254058593224251, F1 = 0.401775797262461, ACC = 0.4733820459290188\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 70s 215us/step - loss: 0.4131 - accuracy: 0.8646 - f1: 0.8642 - val_loss: 2.2794 - val_accuracy: 0.4960 - val_f1: 0.4932\n",
      "Score = 0.42474981672133205, F1 = 0.3990698202938626, ACC = 0.4768879912861941\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.3980 - accuracy: 0.8699 - f1: 0.8700 - val_loss: 2.3404 - val_accuracy: 0.4965 - val_f1: 0.4947\n",
      "Score = 0.4246709734610291, F1 = 0.39792388217126556, ACC = 0.4789756739584279\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 70s 212us/step - loss: 0.3815 - accuracy: 0.8754 - f1: 0.8755 - val_loss: 2.4302 - val_accuracy: 0.4919 - val_f1: 0.4896\n",
      "Score = 0.418919341653732, F1 = 0.39112204977641957, ACC = 0.47535626758645727\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.3655 - accuracy: 0.8807 - f1: 0.8811 - val_loss: 2.4294 - val_accuracy: 0.4946 - val_f1: 0.4936\n",
      "Score = 0.424298772167914, F1 = 0.3969659946126554, ACC = 0.47979259326495416\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.3530 - accuracy: 0.8847 - f1: 0.8848 - val_loss: 2.4913 - val_accuracy: 0.4951 - val_f1: 0.4946\n",
      "Score = 0.4241330504887643, F1 = 0.39587480369343936, ACC = 0.4815058545883634\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.3412 - accuracy: 0.8897 - f1: 0.8896 - val_loss: 2.5719 - val_accuracy: 0.4942 - val_f1: 0.4928\n",
      "Score = 0.42103071684496046, F1 = 0.3912723968630473, ACC = 0.4814491240809658\n",
      "Epoch 15/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.3310 - accuracy: 0.8928 - f1: 0.8934 - val_loss: 2.6566 - val_accuracy: 0.4905 - val_f1: 0.4885\n",
      "Score = 0.41565865533040225, F1 = 0.38505385242820683, ACC = 0.4777956794045566\n",
      "Epoch 16/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.3209 - accuracy: 0.8960 - f1: 0.8961 - val_loss: 2.6722 - val_accuracy: 0.4900 - val_f1: 0.4889\n",
      "Score = 0.4159409213772778, F1 = 0.3851789609834285, ACC = 0.47839702278297175\n",
      "Epoch 17/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.3132 - accuracy: 0.8987 - f1: 0.8990 - val_loss: 2.6911 - val_accuracy: 0.4914 - val_f1: 0.4893\n",
      "Score = 0.4194909424375938, F1 = 0.39011984366561997, ACC = 0.4791231732776618\n",
      "Epoch 18/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.3056 - accuracy: 0.9015 - f1: 0.9017 - val_loss: 2.6803 - val_accuracy: 0.4928 - val_f1: 0.4917\n",
      "Score = 0.42139363552022235, F1 = 0.3918140665276173, ACC = 0.4814491240809658\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.44437442095900026, 0.41811677688149596, 0.49768539529817557]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 1.2955 - accuracy: 0.5404 - f1: 0.4601 - val_loss: 1.4796 - val_accuracy: 0.4903 - val_f1: 0.4544\n",
      "Score = 0.3767568575595649, F1 = 0.37353707089501115, ACC = 0.38329400018153764\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.8036 - accuracy: 0.7306 - f1: 0.7115 - val_loss: 1.5910 - val_accuracy: 0.5019 - val_f1: 0.4878\n",
      "Score = 0.42057369578162174, F1 = 0.40961870412295326, ACC = 0.4428156485431606\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.6792 - accuracy: 0.7734 - f1: 0.7651 - val_loss: 1.6894 - val_accuracy: 0.5045 - val_f1: 0.4934\n",
      "Score = 0.43231633736576086, F1 = 0.41995838029945404, ACC = 0.45740673504583823\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.6141 - accuracy: 0.7957 - f1: 0.7914 - val_loss: 1.7877 - val_accuracy: 0.5084 - val_f1: 0.4998\n",
      "Score = 0.43802868079053425, F1 = 0.422515877940241, ACC = 0.469524371425978\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.5685 - accuracy: 0.8116 - f1: 0.8089 - val_loss: 1.8526 - val_accuracy: 0.5038 - val_f1: 0.4966\n",
      "Score = 0.4364823887793991, F1 = 0.42082828941197253, ACC = 0.46826495416175\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.5345 - accuracy: 0.8232 - f1: 0.8215 - val_loss: 1.9108 - val_accuracy: 0.5033 - val_f1: 0.4968\n",
      "Score = 0.4365344735389634, F1 = 0.41959834732736784, ACC = 0.47091994190796044\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.5068 - accuracy: 0.8329 - f1: 0.8314 - val_loss: 1.9564 - val_accuracy: 0.5033 - val_f1: 0.4969\n",
      "Score = 0.43485491693378364, F1 = 0.41659418075179533, ACC = 0.47192974493963874\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.4851 - accuracy: 0.8397 - f1: 0.8389 - val_loss: 2.0313 - val_accuracy: 0.4978 - val_f1: 0.4932\n",
      "Score = 0.4304253350913468, F1 = 0.4103852278095816, ACC = 0.47111282563311246\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.4645 - accuracy: 0.8476 - f1: 0.8464 - val_loss: 2.0971 - val_accuracy: 0.5024 - val_f1: 0.4976\n",
      "Score = 0.43195926610947516, F1 = 0.4096681295430925, ACC = 0.4772170282291005\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.4477 - accuracy: 0.8531 - f1: 0.8526 - val_loss: 2.1318 - val_accuracy: 0.5018 - val_f1: 0.4977\n",
      "Score = 0.43063464174822397, F1 = 0.4071154752885545, ACC = 0.47838567668149223\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.4308 - accuracy: 0.8581 - f1: 0.8581 - val_loss: 2.1759 - val_accuracy: 0.5002 - val_f1: 0.4960\n",
      "Score = 0.42829146405644225, F1 = 0.4037243743400395, ACC = 0.4781701007533811\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.4154 - accuracy: 0.8637 - f1: 0.8634 - val_loss: 2.1989 - val_accuracy: 0.5001 - val_f1: 0.4972\n",
      "Score = 0.4309666247969103, F1 = 0.4069515437319476, ACC = 0.47972451665607696\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4603825757312938, 0.43671735090974245, 0.508430153399292]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 69s 210us/step - loss: 0.6478 - accuracy: 0.7823 - f1: 0.7716 - val_loss: 1.9824 - val_accuracy: 0.4925 - val_f1: 0.4875\n",
      "Score = 0.42636954463144916, F1 = 0.4082604391862068, ACC = 0.46313651629300173\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 69s 209us/step - loss: 0.4673 - accuracy: 0.8468 - f1: 0.8459 - val_loss: 2.1389 - val_accuracy: 0.5010 - val_f1: 0.4964\n",
      "Score = 0.43574808067456927, F1 = 0.4159154447592837, ACC = 0.4760143414722701\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.4289 - accuracy: 0.8590 - f1: 0.8585 - val_loss: 2.3368 - val_accuracy: 0.4890 - val_f1: 0.4845\n",
      "Score = 0.41693386691535217, F1 = 0.39205375434795275, ACC = 0.46744803485522374\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 68s 206us/step - loss: 0.4074 - accuracy: 0.8672 - f1: 0.8673 - val_loss: 2.4642 - val_accuracy: 0.4917 - val_f1: 0.4881\n",
      "Score = 0.42154113613910105, F1 = 0.3955940137080517, ACC = 0.47422165743850414\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.3976 - accuracy: 0.8714 - f1: 0.8712 - val_loss: 2.4278 - val_accuracy: 0.4842 - val_f1: 0.4808\n",
      "Score = 0.4183425062230211, F1 = 0.3944412083711907, ACC = 0.46686938367976766\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.3904 - accuracy: 0.8740 - f1: 0.8742 - val_loss: 2.4135 - val_accuracy: 0.5023 - val_f1: 0.4981\n",
      "Score = 0.44290686853912953, F1 = 0.42287834279120723, ACC = 0.4835708450576382\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.3852 - accuracy: 0.8750 - f1: 0.8754 - val_loss: 2.3910 - val_accuracy: 0.4988 - val_f1: 0.4958\n",
      "Score = 0.4403223130721924, F1 = 0.4199372913660358, ACC = 0.481710084414995\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 69s 210us/step - loss: 0.3791 - accuracy: 0.8776 - f1: 0.8775 - val_loss: 2.5460 - val_accuracy: 0.4924 - val_f1: 0.4900\n",
      "Score = 0.4299218636559786, F1 = 0.4062807509016481, ACC = 0.47792048652083147\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.3781 - accuracy: 0.8780 - f1: 0.8785 - val_loss: 2.6066 - val_accuracy: 0.4971 - val_f1: 0.4947\n",
      "Score = 0.43406347826583047, F1 = 0.4094110106707075, ACC = 0.48411545792865573\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 69s 209us/step - loss: 0.3767 - accuracy: 0.8788 - f1: 0.8794 - val_loss: 2.5131 - val_accuracy: 0.4906 - val_f1: 0.4881\n",
      "Score = 0.4344765829240793, F1 = 0.4147441761070181, ACC = 0.474539348279931\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 68s 209us/step - loss: 0.3745 - accuracy: 0.8802 - f1: 0.8803 - val_loss: 2.5424 - val_accuracy: 0.4927 - val_f1: 0.4883\n",
      "Score = 0.42981493278386657, F1 = 0.40707676528131664, ACC = 0.4759803031678315\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 68s 206us/step - loss: 0.3749 - accuracy: 0.8799 - f1: 0.8800 - val_loss: 2.3509 - val_accuracy: 0.5017 - val_f1: 0.4973\n",
      "Score = 0.44287375165134113, F1 = 0.422750677303709, ACC = 0.4837296904783516\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.3689 - accuracy: 0.8814 - f1: 0.8813 - val_loss: 2.4184 - val_accuracy: 0.4945 - val_f1: 0.4899\n",
      "Score = 0.4286474578020073, F1 = 0.40545162125354633, ACC = 0.4757420350367614\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.3683 - accuracy: 0.8819 - f1: 0.8819 - val_loss: 2.5908 - val_accuracy: 0.4946 - val_f1: 0.4914\n",
      "Score = 0.4271892104445635, F1 = 0.4013750840245205, ACC = 0.47959970953980213\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4528409615204802, 0.42846216946552473, 0.5023372969047836]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.6902 - accuracy: 0.7679 - f1: 0.7541 - val_loss: 1.9057 - val_accuracy: 0.5099 - val_f1: 0.4996\n",
      "Score = 0.44554095677293504, F1 = 0.43210201205564597, ACC = 0.47282608695652173\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.4733 - accuracy: 0.8439 - f1: 0.8435 - val_loss: 2.1183 - val_accuracy: 0.5023 - val_f1: 0.4982\n",
      "Score = 0.43450808870495494, F1 = 0.4128743858897157, ACC = 0.47843106108741035\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.4208 - accuracy: 0.8623 - f1: 0.8620 - val_loss: 2.2681 - val_accuracy: 0.5009 - val_f1: 0.4972\n",
      "Score = 0.43276334037770753, F1 = 0.4086887728383412, ACC = 0.4816420078061178\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.3920 - accuracy: 0.8731 - f1: 0.8730 - val_loss: 2.3880 - val_accuracy: 0.4956 - val_f1: 0.4934\n",
      "Score = 0.42742124766721906, F1 = 0.4025987836369237, ACC = 0.47781837160751567\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.3762 - accuracy: 0.8782 - f1: 0.8783 - val_loss: 2.3647 - val_accuracy: 0.5028 - val_f1: 0.5009\n",
      "Score = 0.438437034420583, F1 = 0.41446337454213406, ACC = 0.48711082871925204\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3641 - accuracy: 0.8821 - f1: 0.8825 - val_loss: 2.3740 - val_accuracy: 0.5056 - val_f1: 0.5039\n",
      "Score = 0.44760719480049527, F1 = 0.42594277163475386, ACC = 0.49159253880366705\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3586 - accuracy: 0.8849 - f1: 0.8852 - val_loss: 2.4522 - val_accuracy: 0.4913 - val_f1: 0.4901\n",
      "Score = 0.425878923404169, F1 = 0.40015709766639207, ACC = 0.4781020241445039\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3538 - accuracy: 0.8863 - f1: 0.8869 - val_loss: 2.7048 - val_accuracy: 0.4735 - val_f1: 0.4718\n",
      "Score = 0.39990213886365356, F1 = 0.36906420929674094, ACC = 0.4625124807116275\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3494 - accuracy: 0.8880 - f1: 0.8883 - val_loss: 2.5066 - val_accuracy: 0.4982 - val_f1: 0.4976\n",
      "Score = 0.4322037395717048, F1 = 0.4057690826336871, ACC = 0.4858741036579831\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3450 - accuracy: 0.8896 - f1: 0.8899 - val_loss: 2.4707 - val_accuracy: 0.5053 - val_f1: 0.5040\n",
      "Score = 0.44148164800578815, F1 = 0.41639780123794684, ACC = 0.4924094581101933\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3427 - accuracy: 0.8907 - f1: 0.8910 - val_loss: 2.6422 - val_accuracy: 0.4986 - val_f1: 0.4971\n",
      "Score = 0.4371265603079898, F1 = 0.412121844925295, ACC = 0.4878937097213398\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3392 - accuracy: 0.8916 - f1: 0.8918 - val_loss: 2.7506 - val_accuracy: 0.4841 - val_f1: 0.4835\n",
      "Score = 0.41965753498381453, F1 = 0.3931291481572826, ACC = 0.4735181991467732\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3365 - accuracy: 0.8928 - f1: 0.8932 - val_loss: 2.4043 - val_accuracy: 0.5200 - val_f1: 0.5185\n",
      "Score = 0.461661531493448, F1 = 0.43943096658804326, ACC = 0.5067963147862394\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3382 - accuracy: 0.8920 - f1: 0.8926 - val_loss: 2.6830 - val_accuracy: 0.4918 - val_f1: 0.4904\n",
      "Score = 0.4241745988103307, F1 = 0.3956909274666985, ACC = 0.48200508305346285\n",
      "Epoch 15/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.3399 - accuracy: 0.8913 - f1: 0.8917 - val_loss: 2.6802 - val_accuracy: 0.4996 - val_f1: 0.4989\n",
      "Score = 0.4336223305470353, F1 = 0.4057404453140516, ACC = 0.4902310066261233\n",
      "Epoch 16/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3372 - accuracy: 0.8922 - f1: 0.8925 - val_loss: 2.4046 - val_accuracy: 0.5196 - val_f1: 0.5183\n",
      "Score = 0.46599036122947946, F1 = 0.44629426973309566, ACC = 0.5059793954797132\n",
      "Epoch 17/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3308 - accuracy: 0.8940 - f1: 0.8943 - val_loss: 2.5206 - val_accuracy: 0.5124 - val_f1: 0.5110\n",
      "Score = 0.45364615911132555, F1 = 0.4303401506937682, ACC = 0.5009644186257602\n",
      "Epoch 18/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3330 - accuracy: 0.8939 - f1: 0.8942 - val_loss: 2.7241 - val_accuracy: 0.4878 - val_f1: 0.4861\n",
      "Score = 0.425360407895509, F1 = 0.39984702932439864, ACC = 0.4771602977217028\n",
      "Epoch 19/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3317 - accuracy: 0.8943 - f1: 0.8946 - val_loss: 2.7684 - val_accuracy: 0.4942 - val_f1: 0.4932\n",
      "Score = 0.4238243818105232, F1 = 0.3937990628332243, ACC = 0.4847848779159481\n",
      "Epoch 20/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.3351 - accuracy: 0.8931 - f1: 0.8936 - val_loss: 2.6370 - val_accuracy: 0.4986 - val_f1: 0.4975\n",
      "Score = 0.43956661888249593, F1 = 0.4154787160993333, ACC = 0.48847236089679585\n",
      "Epoch 21/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.3322 - accuracy: 0.8939 - f1: 0.8945 - val_loss: 2.6488 - val_accuracy: 0.5034 - val_f1: 0.5022\n",
      "Score = 0.440263034956491, F1 = 0.4145733874128939, ACC = 0.4924208042116729\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_8 (GRU)                  (None, 64)                127680    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 128,135\n",
      "Trainable params: 128,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4728269562272036, 0.44980326561191086, 0.519572025052192]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 68s 209us/step - loss: 0.6558 - accuracy: 0.7773 - f1: 0.7578 - val_loss: 1.8009 - val_accuracy: 0.4860 - val_f1: 0.4809\n",
      "Score = 0.4228992513099874, F1 = 0.4102507863264414, ACC = 0.4485794680947626\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 68s 209us/step - loss: 0.3593 - accuracy: 0.8787 - f1: 0.8784 - val_loss: 2.1030 - val_accuracy: 0.4831 - val_f1: 0.4801\n",
      "Score = 0.4202762915922648, F1 = 0.401686390296676, ACC = 0.45801942452573297\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.2896 - accuracy: 0.9021 - f1: 0.9024 - val_loss: 2.3540 - val_accuracy: 0.4833 - val_f1: 0.4796\n",
      "Score = 0.41529048456134654, F1 = 0.3922721897111999, ACC = 0.46202459834800763\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 67s 205us/step - loss: 0.2471 - accuracy: 0.9164 - f1: 0.9167 - val_loss: 2.5454 - val_accuracy: 0.4865 - val_f1: 0.4840\n",
      "Score = 0.41698465338621127, F1 = 0.39066539992547333, ACC = 0.470420713442861\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.2166 - accuracy: 0.9269 - f1: 0.9277 - val_loss: 2.7203 - val_accuracy: 0.4827 - val_f1: 0.4806\n",
      "Score = 0.41079022369300777, F1 = 0.3820235273337226, ACC = 0.4691953344830716\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 69s 211us/step - loss: 0.1954 - accuracy: 0.9345 - f1: 0.9348 - val_loss: 2.8102 - val_accuracy: 0.4836 - val_f1: 0.4823\n",
      "Score = 0.4119432135705008, F1 = 0.38282791370002217, ACC = 0.4710560951257148\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 68s 209us/step - loss: 0.1776 - accuracy: 0.9401 - f1: 0.9403 - val_loss: 3.0631 - val_accuracy: 0.4750 - val_f1: 0.4742\n",
      "Score = 0.40307969610994965, F1 = 0.372085611523482, ACC = 0.4660070799673232\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 68s 206us/step - loss: 0.1635 - accuracy: 0.9447 - f1: 0.9449 - val_loss: 3.0998 - val_accuracy: 0.4798 - val_f1: 0.4788\n",
      "Score = 0.40582261250089297, F1 = 0.3738323976815122, ACC = 0.4707724425887265\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.1508 - accuracy: 0.9492 - f1: 0.9496 - val_loss: 3.1335 - val_accuracy: 0.4780 - val_f1: 0.4773\n",
      "Score = 0.40518011892685174, F1 = 0.37333728745089007, ACC = 0.46983071616592537\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 67s 205us/step - loss: 0.1402 - accuracy: 0.9527 - f1: 0.9530 - val_loss: 3.2435 - val_accuracy: 0.4827 - val_f1: 0.4820\n",
      "Score = 0.4115646695635723, F1 = 0.38021198779388105, ACC = 0.47522011436870293\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.1320 - accuracy: 0.9554 - f1: 0.9557 - val_loss: 3.4020 - val_accuracy: 0.4750 - val_f1: 0.4742\n",
      "Score = 0.4019454020613975, F1 = 0.36916878047500756, ACC = 0.46849187619134064\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.1235 - accuracy: 0.9582 - f1: 0.9583 - val_loss: 3.4391 - val_accuracy: 0.4801 - val_f1: 0.4804\n",
      "Score = 0.4092053189258298, F1 = 0.37721028811726065, ACC = 0.47416492693110646\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_9 (GRU)                  (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4418098978428524, 0.42003398337368775, 0.486021602977217]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 36s 109us/step - loss: 0.7605 - accuracy: 0.7414 - f1: 0.7119 - val_loss: 1.6741 - val_accuracy: 0.4840 - val_f1: 0.4747\n",
      "Score = 0.4127075188954962, F1 = 0.4029691542746937, ACC = 0.43247935009530725\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.4136 - accuracy: 0.8612 - f1: 0.8594 - val_loss: 1.9461 - val_accuracy: 0.4825 - val_f1: 0.4798\n",
      "Score = 0.4191779453790979, F1 = 0.40221535838663475, ACC = 0.4536171371516747\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.3355 - accuracy: 0.8868 - f1: 0.8868 - val_loss: 2.1560 - val_accuracy: 0.4827 - val_f1: 0.4789\n",
      "Score = 0.4170777388706316, F1 = 0.3969962566857662, ACC = 0.45784923300353997\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.2883 - accuracy: 0.9026 - f1: 0.9029 - val_loss: 2.3117 - val_accuracy: 0.4835 - val_f1: 0.4804\n",
      "Score = 0.4161758511634428, F1 = 0.3931800924036867, ACC = 0.462864209857493\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.2569 - accuracy: 0.9140 - f1: 0.9144 - val_loss: 2.3975 - val_accuracy: 0.4857 - val_f1: 0.4837\n",
      "Score = 0.4197058317892958, F1 = 0.3959060080584648, ACC = 0.4680266860306799\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.2318 - accuracy: 0.9222 - f1: 0.9228 - val_loss: 2.5461 - val_accuracy: 0.4861 - val_f1: 0.4837\n",
      "Score = 0.41624617129273384, F1 = 0.38966936703412886, ACC = 0.4702051375147499\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.2127 - accuracy: 0.9284 - f1: 0.9287 - val_loss: 2.6275 - val_accuracy: 0.4857 - val_f1: 0.4840\n",
      "Score = 0.4186833678320766, F1 = 0.3922843005729256, ACC = 0.4722814740855042\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.1963 - accuracy: 0.9339 - f1: 0.9340 - val_loss: 2.7566 - val_accuracy: 0.4837 - val_f1: 0.4819\n",
      "Score = 0.4142965864543015, F1 = 0.3861224637862299, ACC = 0.4714985930834165\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.1815 - accuracy: 0.9392 - f1: 0.9394 - val_loss: 2.8029 - val_accuracy: 0.4787 - val_f1: 0.4777\n",
      "Score = 0.41177738491595295, F1 = 0.38412280066749666, ACC = 0.4679245711173641\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.1684 - accuracy: 0.9434 - f1: 0.9438 - val_loss: 2.8774 - val_accuracy: 0.4888 - val_f1: 0.4878\n",
      "Score = 0.42070965188274667, F1 = 0.39187175244665573, ACC = 0.4792593264954162\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.1603 - accuracy: 0.9460 - f1: 0.9464 - val_loss: 2.9650 - val_accuracy: 0.4831 - val_f1: 0.4822\n",
      "Score = 0.4146668459198779, F1 = 0.38516063932393424, ACC = 0.4745733865843696\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.1504 - accuracy: 0.9491 - f1: 0.9493 - val_loss: 3.0177 - val_accuracy: 0.4817 - val_f1: 0.4811\n",
      "Score = 0.4138561779265595, F1 = 0.3844815830374639, ACC = 0.4734955069438141\n",
      "Epoch 13/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.1431 - accuracy: 0.9516 - f1: 0.9519 - val_loss: 3.1173 - val_accuracy: 0.4785 - val_f1: 0.4770\n",
      "Score = 0.4092638883180057, F1 = 0.3794045237549389, ACC = 0.46988744667332305\n",
      "Epoch 14/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.1345 - accuracy: 0.9549 - f1: 0.9553 - val_loss: 3.2314 - val_accuracy: 0.4816 - val_f1: 0.4808\n",
      "Score = 0.41239805280883995, F1 = 0.3816234947340527, ACC = 0.474879731324317\n",
      "Epoch 15/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.1285 - accuracy: 0.9567 - f1: 0.9569 - val_loss: 3.2936 - val_accuracy: 0.4791 - val_f1: 0.4780\n",
      "Score = 0.4110737633534651, F1 = 0.3812508078918909, ACC = 0.4716234001996914\n",
      "Epoch 16/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.1233 - accuracy: 0.9583 - f1: 0.9584 - val_loss: 3.3874 - val_accuracy: 0.4777 - val_f1: 0.4762\n",
      "Score = 0.4083656315246347, F1 = 0.37790177900190886, ACC = 0.4702164836162295\n",
      "Epoch 17/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.1174 - accuracy: 0.9604 - f1: 0.9607 - val_loss: 3.4064 - val_accuracy: 0.4756 - val_f1: 0.4749\n",
      "Score = 0.4075016435938587, F1 = 0.376964312612332, ACC = 0.469501679223019\n",
      "Epoch 18/30\n",
      "327818/327818 [==============================] - 35s 106us/step - loss: 0.1137 - accuracy: 0.9618 - f1: 0.9620 - val_loss: 3.4238 - val_accuracy: 0.4812 - val_f1: 0.4804\n",
      "Score = 0.4145366519408787, F1 = 0.3844298356315898, ACC = 0.47566261232640467\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4263286768371177, 0.39555294229332494, 0.4888127439411818]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.3464 - accuracy: 0.8823 - f1: 0.8808 - val_loss: 2.2588 - val_accuracy: 0.5175 - val_f1: 0.5149\n",
      "Score = 0.4650509848135829, F1 = 0.44900526183974054, ACC = 0.4976286647907779\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.2194 - accuracy: 0.9258 - f1: 0.9263 - val_loss: 2.7224 - val_accuracy: 0.4922 - val_f1: 0.4901\n",
      "Score = 0.4253696464808625, F1 = 0.39929639204535483, ACC = 0.4783062539711355\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.1920 - accuracy: 0.9343 - f1: 0.9347 - val_loss: 3.0981 - val_accuracy: 0.4877 - val_f1: 0.4872\n",
      "Score = 0.4236030179893724, F1 = 0.396749047156283, ACC = 0.478124716347463\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.1773 - accuracy: 0.9399 - f1: 0.9404 - val_loss: 3.0383 - val_accuracy: 0.4996 - val_f1: 0.4987\n",
      "Score = 0.432996194149184, F1 = 0.4052809255359166, ACC = 0.4892665880003631\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.1721 - accuracy: 0.9417 - f1: 0.9421 - val_loss: 2.8861 - val_accuracy: 0.5077 - val_f1: 0.5072\n",
      "Score = 0.4486063562601491, F1 = 0.42501987795226415, ACC = 0.4964940546428247\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.1633 - accuracy: 0.9450 - f1: 0.9454 - val_loss: 3.2594 - val_accuracy: 0.4952 - val_f1: 0.4947\n",
      "Score = 0.4304510694624386, F1 = 0.4029743289905676, ACC = 0.48623717890532814\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 67s 204us/step - loss: 0.1595 - accuracy: 0.9463 - f1: 0.9467 - val_loss: 3.1375 - val_accuracy: 0.4887 - val_f1: 0.4870\n",
      "Score = 0.4241319606516961, F1 = 0.39722556462939035, ACC = 0.47876009803031677\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 68s 207us/step - loss: 0.1569 - accuracy: 0.9468 - f1: 0.9471 - val_loss: 3.1305 - val_accuracy: 0.4961 - val_f1: 0.4957\n",
      "Score = 0.43390355430094263, F1 = 0.406959320362897, ACC = 0.48860851411455025\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 67s 203us/step - loss: 0.1532 - accuracy: 0.9484 - f1: 0.9489 - val_loss: 3.1652 - val_accuracy: 0.5032 - val_f1: 0.5032\n",
      "Score = 0.43737576169150116, F1 = 0.4081739708314109, ACC = 0.4966642461650177\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_11 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.47438406563666247, 0.4531276292296044, 0.517541072887356]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 38s 114us/step - loss: 0.3689 - accuracy: 0.8746 - f1: 0.8724 - val_loss: 2.3945 - val_accuracy: 0.4942 - val_f1: 0.4916\n",
      "Score = 0.42774456373569025, F1 = 0.40296398898799535, ACC = 0.4780566397385858\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.2153 - accuracy: 0.9270 - f1: 0.9273 - val_loss: 2.7136 - val_accuracy: 0.4931 - val_f1: 0.4911\n",
      "Score = 0.4272630922943027, F1 = 0.40160829976553636, ACC = 0.4793500953072524\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.1790 - accuracy: 0.9392 - f1: 0.9396 - val_loss: 3.1358 - val_accuracy: 0.4738 - val_f1: 0.4715\n",
      "Score = 0.4124329399877681, F1 = 0.387984844296974, ACC = 0.46206998275392575\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.1620 - accuracy: 0.9448 - f1: 0.9452 - val_loss: 3.0192 - val_accuracy: 0.4988 - val_f1: 0.4977\n",
      "Score = 0.437954471199475, F1 = 0.4122677990466045, ACC = 0.4901061995098484\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.1532 - accuracy: 0.9485 - f1: 0.9487 - val_loss: 3.2831 - val_accuracy: 0.4921 - val_f1: 0.4925\n",
      "Score = 0.4300004269780736, F1 = 0.4033970504224051, ACC = 0.48401334301533994\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.1428 - accuracy: 0.9514 - f1: 0.9516 - val_loss: 3.6817 - val_accuracy: 0.4904 - val_f1: 0.4904\n",
      "Score = 0.42396336994630396, F1 = 0.3942915151073755, ACC = 0.48420622674049196\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.1399 - accuracy: 0.9529 - f1: 0.9531 - val_loss: 3.6689 - val_accuracy: 0.4767 - val_f1: 0.4772\n",
      "Score = 0.41385405035997036, F1 = 0.3858699137717683, ACC = 0.4706703276754107\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.1348 - accuracy: 0.9544 - f1: 0.9547 - val_loss: 3.5450 - val_accuracy: 0.4926 - val_f1: 0.4923\n",
      "Score = 0.4296318002877473, F1 = 0.40201419295960666, ACC = 0.4857039121357901\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 37s 113us/step - loss: 0.1321 - accuracy: 0.9555 - f1: 0.9560 - val_loss: 3.3606 - val_accuracy: 0.4984 - val_f1: 0.4972\n",
      "Score = 0.43514508610265035, F1 = 0.4075326142627471, ACC = 0.491206771353363\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 37s 112us/step - loss: 0.1275 - accuracy: 0.9572 - f1: 0.9575 - val_loss: 3.6985 - val_accuracy: 0.4815 - val_f1: 0.4810\n",
      "Score = 0.40544684927305463, F1 = 0.3709691451665937, ACC = 0.47544703639829355\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.1273 - accuracy: 0.9573 - f1: 0.9576 - val_loss: 3.7068 - val_accuracy: 0.4762 - val_f1: 0.4757\n",
      "Score = 0.41044794875781526, F1 = 0.3811047176026264, ACC = 0.47002359989107745\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 37s 114us/step - loss: 0.1263 - accuracy: 0.9576 - f1: 0.9578 - val_loss: 3.5458 - val_accuracy: 0.4800 - val_f1: 0.4794\n",
      "Score = 0.41031418716554025, F1 = 0.37939621128307216, ACC = 0.47308704729055095\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_12 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4427510016762215, 0.41516286708423916, 0.49876327493873107]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.9637 - accuracy: 0.6653 - f1: 0.6347 - val_loss: 1.6708 - val_accuracy: 0.5064 - val_f1: 0.4929\n",
      "Score = 0.43880794058082306, F1 = 0.4318323962531349, ACC = 0.4529704093673414\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.5860 - accuracy: 0.8007 - f1: 0.7980 - val_loss: 1.9344 - val_accuracy: 0.4946 - val_f1: 0.4902\n",
      "Score = 0.43362884115023914, F1 = 0.41822342308863025, ACC = 0.4649065081238087\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 70s 215us/step - loss: 0.4937 - accuracy: 0.8333 - f1: 0.8322 - val_loss: 2.0976 - val_accuracy: 0.4947 - val_f1: 0.4907\n",
      "Score = 0.43012679651924124, F1 = 0.4100514154180284, ACC = 0.47088590360352184\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 71s 217us/step - loss: 0.4369 - accuracy: 0.8523 - f1: 0.8520 - val_loss: 2.2615 - val_accuracy: 0.4921 - val_f1: 0.4885\n",
      "Score = 0.4255471931778142, F1 = 0.40227175061065445, ACC = 0.4728033947535627\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 70s 215us/step - loss: 0.3953 - accuracy: 0.8673 - f1: 0.8676 - val_loss: 2.3808 - val_accuracy: 0.4889 - val_f1: 0.4853\n",
      "Score = 0.41972288414171255, F1 = 0.39469642771744173, ACC = 0.47053417445765633\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.3652 - accuracy: 0.8774 - f1: 0.8777 - val_loss: 2.5292 - val_accuracy: 0.4854 - val_f1: 0.4833\n",
      "Score = 0.4149195995177918, F1 = 0.3878514721329603, ACC = 0.46987610057184354\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.3402 - accuracy: 0.8859 - f1: 0.8861 - val_loss: 2.6083 - val_accuracy: 0.4817 - val_f1: 0.4800\n",
      "Score = 0.41244457524376565, F1 = 0.3852694933421166, ACC = 0.46761822637741673\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 70s 214us/step - loss: 0.3177 - accuracy: 0.8938 - f1: 0.8941 - val_loss: 2.6885 - val_accuracy: 0.4878 - val_f1: 0.4856\n",
      "Score = 0.41844619177521086, F1 = 0.390823807546749, ACC = 0.4745280021784515\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 70s 212us/step - loss: 0.2975 - accuracy: 0.9009 - f1: 0.9013 - val_loss: 2.7866 - val_accuracy: 0.4849 - val_f1: 0.4829\n",
      "Score = 0.414250725899146, F1 = 0.3848748673665653, ACC = 0.4738926204955977\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_13 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.47107141023335963, 0.453654389829141, 0.5064332395388944]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 1.0913 - accuracy: 0.6193 - f1: 0.5772 - val_loss: 1.5709 - val_accuracy: 0.5054 - val_f1: 0.4870\n",
      "Score = 0.4271978291035059, F1 = 0.4216681726928565, ACC = 0.4384247072705818\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.6594 - accuracy: 0.7761 - f1: 0.7698 - val_loss: 1.7631 - val_accuracy: 0.5047 - val_f1: 0.4955\n",
      "Score = 0.44171534420849057, F1 = 0.4304660703668199, ACC = 0.4645547789779432\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 38s 115us/step - loss: 0.5568 - accuracy: 0.8114 - f1: 0.8093 - val_loss: 1.9517 - val_accuracy: 0.4963 - val_f1: 0.4903\n",
      "Score = 0.4332209276916076, F1 = 0.4171507616286961, ACC = 0.4658482345466098\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.4931 - accuracy: 0.8323 - f1: 0.8314 - val_loss: 2.1180 - val_accuracy: 0.4914 - val_f1: 0.4875\n",
      "Score = 0.42685422810737117, F1 = 0.40692732412986005, ACC = 0.46731188163746934\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.4530 - accuracy: 0.8464 - f1: 0.8466 - val_loss: 2.1718 - val_accuracy: 0.4929 - val_f1: 0.4890\n",
      "Score = 0.4274816222576159, F1 = 0.40627663386058094, ACC = 0.47053417445765633\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.4195 - accuracy: 0.8587 - f1: 0.8585 - val_loss: 2.2871 - val_accuracy: 0.4891 - val_f1: 0.4850\n",
      "Score = 0.4203029568701545, F1 = 0.39665194168557577, ACC = 0.4683216846691477\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.3925 - accuracy: 0.8676 - f1: 0.8676 - val_loss: 2.3543 - val_accuracy: 0.4914 - val_f1: 0.4879\n",
      "Score = 0.4236728891282461, F1 = 0.3993681026914831, ACC = 0.47301897068167376\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 39s 118us/step - loss: 0.3697 - accuracy: 0.8763 - f1: 0.8763 - val_loss: 2.4055 - val_accuracy: 0.4910 - val_f1: 0.4877\n",
      "Score = 0.42131183431911556, F1 = 0.39567648893957585, ACC = 0.47335935372605975\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 38s 116us/step - loss: 0.3483 - accuracy: 0.8830 - f1: 0.8830 - val_loss: 2.5062 - val_accuracy: 0.4873 - val_f1: 0.4841\n",
      "Score = 0.41563860779088035, F1 = 0.38807518530143087, ACC = 0.4716007079967323\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 38s 117us/step - loss: 0.3321 - accuracy: 0.8889 - f1: 0.8893 - val_loss: 2.5861 - val_accuracy: 0.4891 - val_f1: 0.4870\n",
      "Score = 0.4171637308335274, F1 = 0.3882334929590458, ACC = 0.4759008804574748\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_14 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4660067852047748, 0.4469614466382353, 0.504674593809567]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 71s 216us/step - loss: 0.5359 - accuracy: 0.8173 - f1: 0.8138 - val_loss: 2.5705 - val_accuracy: 0.4779 - val_f1: 0.4742\n",
      "Score = 0.40927488699213144, F1 = 0.3847578410018048, ACC = 0.45905191976037035\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 70s 213us/step - loss: 0.3668 - accuracy: 0.8765 - f1: 0.8765 - val_loss: 2.5681 - val_accuracy: 0.4855 - val_f1: 0.4837\n",
      "Score = 0.41775611600412477, F1 = 0.39262156314968344, ACC = 0.46878687482980846\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.3289 - accuracy: 0.8901 - f1: 0.8908 - val_loss: 2.7999 - val_accuracy: 0.4900 - val_f1: 0.4880\n",
      "Score = 0.4209037616782508, F1 = 0.39357532827953656, ACC = 0.47638876282109466\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.3085 - accuracy: 0.8970 - f1: 0.8975 - val_loss: 2.9629 - val_accuracy: 0.4959 - val_f1: 0.4940\n",
      "Score = 0.4329154352285165, F1 = 0.40763045306000173, ACC = 0.4842516111464101\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 69s 211us/step - loss: 0.2968 - accuracy: 0.9015 - f1: 0.9020 - val_loss: 3.1569 - val_accuracy: 0.4807 - val_f1: 0.4808\n",
      "Score = 0.4120228980636592, F1 = 0.38239918470197803, ACC = 0.4721680130707089\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 69s 210us/step - loss: 0.2875 - accuracy: 0.9042 - f1: 0.9048 - val_loss: 2.9982 - val_accuracy: 0.4891 - val_f1: 0.4883\n",
      "Score = 0.42450030461514254, F1 = 0.3979150411975286, ACC = 0.4784764454933285\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 69s 209us/step - loss: 0.2833 - accuracy: 0.9064 - f1: 0.9069 - val_loss: 3.1663 - val_accuracy: 0.4710 - val_f1: 0.4709\n",
      "Score = 0.4112065195625739, F1 = 0.38633319415731676, ACC = 0.4617069075065807\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 69s 210us/step - loss: 0.2770 - accuracy: 0.9088 - f1: 0.9093 - val_loss: 3.2990 - val_accuracy: 0.4719 - val_f1: 0.4709\n",
      "Score = 0.4062550052274615, F1 = 0.3786634553371307, ACC = 0.46227421258055734\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 68s 208us/step - loss: 0.2747 - accuracy: 0.9101 - f1: 0.9106 - val_loss: 3.2734 - val_accuracy: 0.4812 - val_f1: 0.4799\n",
      "Score = 0.4128029379540633, F1 = 0.38345724415589955, ACC = 0.47238358899882\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 69s 209us/step - loss: 0.2750 - accuracy: 0.9097 - f1: 0.9100 - val_loss: 3.3392 - val_accuracy: 0.4824 - val_f1: 0.4824\n",
      "Score = 0.4078816002952994, F1 = 0.37471486948302596, ACC = 0.47522011436870293\n",
      "Epoch 11/30\n",
      "327818/327818 [==============================] - 69s 210us/step - loss: 0.2726 - accuracy: 0.9103 - f1: 0.9107 - val_loss: 3.1753 - val_accuracy: 0.4865 - val_f1: 0.4859\n",
      "Score = 0.41889212014875277, F1 = 0.3892931395954974, ACC = 0.4789870200599074\n",
      "Epoch 12/30\n",
      "327818/327818 [==============================] - 69s 209us/step - loss: 0.2710 - accuracy: 0.9104 - f1: 0.9109 - val_loss: 3.2056 - val_accuracy: 0.4767 - val_f1: 0.4745\n",
      "Score = 0.4089389426181931, F1 = 0.3803613317850206, ACC = 0.4669601524916039\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_15 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.43984745994139524, 0.41225984755911166, 0.49585867295997094]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327818 samples, validate on 88136 samples\n",
      "Epoch 1/30\n",
      "327818/327818 [==============================] - 36s 110us/step - loss: 0.5707 - accuracy: 0.8058 - f1: 0.8006 - val_loss: 2.1939 - val_accuracy: 0.4861 - val_f1: 0.4797\n",
      "Score = 0.42487812204820097, F1 = 0.40678327802826153, ACC = 0.4616161386947445\n",
      "Epoch 2/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.3680 - accuracy: 0.8766 - f1: 0.8769 - val_loss: 2.4909 - val_accuracy: 0.4961 - val_f1: 0.4933\n",
      "Score = 0.4326019891557942, F1 = 0.40933650227523327, ACC = 0.4798379776708723\n",
      "Epoch 3/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.3166 - accuracy: 0.8943 - f1: 0.8947 - val_loss: 2.8268 - val_accuracy: 0.4881 - val_f1: 0.4875\n",
      "Score = 0.4233502022053951, F1 = 0.3968243688108659, ACC = 0.47720568212762093\n",
      "Epoch 4/30\n",
      "327818/327818 [==============================] - 36s 108us/step - loss: 0.2891 - accuracy: 0.9034 - f1: 0.9040 - val_loss: 3.0717 - val_accuracy: 0.4862 - val_f1: 0.4866\n",
      "Score = 0.41808905500422394, F1 = 0.3883516003058415, ACC = 0.47846509939184895\n",
      "Epoch 5/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.2747 - accuracy: 0.9090 - f1: 0.9095 - val_loss: 3.1330 - val_accuracy: 0.4848 - val_f1: 0.4848\n",
      "Score = 0.4154781071347273, F1 = 0.3858294042589933, ACC = 0.4756739584278842\n",
      "Epoch 6/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.2644 - accuracy: 0.9127 - f1: 0.9132 - val_loss: 3.1768 - val_accuracy: 0.4779 - val_f1: 0.4778\n",
      "Score = 0.4105321760138847, F1 = 0.3809677761431069, ACC = 0.4705568666606154\n",
      "Epoch 7/30\n",
      "327818/327818 [==============================] - 35s 106us/step - loss: 0.2549 - accuracy: 0.9155 - f1: 0.9160 - val_loss: 3.2686 - val_accuracy: 0.4695 - val_f1: 0.4680\n",
      "Score = 0.40731803518993936, F1 = 0.38068037235365715, ACC = 0.4614005627666334\n",
      "Epoch 8/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.2521 - accuracy: 0.9169 - f1: 0.9175 - val_loss: 3.2168 - val_accuracy: 0.4740 - val_f1: 0.4730\n",
      "Score = 0.4022913459092058, F1 = 0.3711995651065341, ACC = 0.46541708269038756\n",
      "Epoch 9/30\n",
      "327818/327818 [==============================] - 35s 107us/step - loss: 0.2465 - accuracy: 0.9188 - f1: 0.9193 - val_loss: 3.2624 - val_accuracy: 0.4690 - val_f1: 0.4675\n",
      "Score = 0.4012291726829813, F1 = 0.3718887019177154, ACC = 0.4607992193882182\n",
      "Epoch 10/30\n",
      "327818/327818 [==============================] - 35s 108us/step - loss: 0.2425 - accuracy: 0.9202 - f1: 0.9207 - val_loss: 3.4412 - val_accuracy: 0.4791 - val_f1: 0.4785\n",
      "Score = 0.40792836319957154, F1 = 0.37609234539425224, ACC = 0.4725651266224925\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_16 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4404984088901831, 0.41311405720916344, 0.49609694109104113]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 64, 0.3, 0.0001, 128, 0.434864176020188, 0.40424091901585085, 0.49703866751384224], [1, 64, 0.3, 0.0001, 256, 0.44119176328633136, 0.4119973888556914, 0.5004651901606608], [2, 64, 0.3, 0.001, 128, 0.4559386309735445, 0.43176669942050744, 0.505014976853953], [3, 64, 0.3, 0.001, 256, 0.4702918181733551, 0.4466621409810148, 0.5182672233820459], [4, 64, 0.5, 0.0001, 128, 0.44437442095900026, 0.41811677688149596, 0.49768539529817557], [5, 64, 0.5, 0.0001, 256, 0.4603825757312938, 0.43671735090974245, 0.508430153399292], [6, 64, 0.5, 0.001, 128, 0.4528409615204802, 0.42846216946552473, 0.5023372969047836], [7, 64, 0.5, 0.001, 256, 0.4728269562272036, 0.44980326561191086, 0.519572025052192], [8, 128, 0.3, 0.0001, 128, 0.4418098978428524, 0.42003398337368775, 0.486021602977217], [9, 128, 0.3, 0.0001, 256, 0.4263286768371177, 0.39555294229332494, 0.4888127439411818], [10, 128, 0.3, 0.001, 128, 0.47438406563666247, 0.4531276292296044, 0.517541072887356], [11, 128, 0.3, 0.001, 256, 0.4427510016762215, 0.41516286708423916, 0.49876327493873107], [12, 128, 0.5, 0.0001, 128, 0.47107141023335963, 0.453654389829141, 0.5064332395388944], [13, 128, 0.5, 0.0001, 256, 0.4660067852047748, 0.4469614466382353, 0.504674593809567], [14, 128, 0.5, 0.001, 128, 0.43984745994139524, 0.41225984755911166, 0.49585867295997094], [15, 128, 0.5, 0.001, 256, 0.4404984088901831, 0.41311405720916344, 0.49609694109104113]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>units</th>\n",
       "      <th>drop</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch</th>\n",
       "      <th>score</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.434864</td>\n",
       "      <td>0.404241</td>\n",
       "      <td>0.497039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.441192</td>\n",
       "      <td>0.411997</td>\n",
       "      <td>0.500465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.455939</td>\n",
       "      <td>0.431767</td>\n",
       "      <td>0.505015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.470292</td>\n",
       "      <td>0.446662</td>\n",
       "      <td>0.518267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.444374</td>\n",
       "      <td>0.418117</td>\n",
       "      <td>0.497685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.460383</td>\n",
       "      <td>0.436717</td>\n",
       "      <td>0.508430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.452841</td>\n",
       "      <td>0.428462</td>\n",
       "      <td>0.502337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.472827</td>\n",
       "      <td>0.449803</td>\n",
       "      <td>0.519572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.441810</td>\n",
       "      <td>0.420034</td>\n",
       "      <td>0.486022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.426329</td>\n",
       "      <td>0.395553</td>\n",
       "      <td>0.488813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.474384</td>\n",
       "      <td>0.453128</td>\n",
       "      <td>0.517541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.442751</td>\n",
       "      <td>0.415163</td>\n",
       "      <td>0.498763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.471071</td>\n",
       "      <td>0.453654</td>\n",
       "      <td>0.506433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.466007</td>\n",
       "      <td>0.446961</td>\n",
       "      <td>0.504675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.439847</td>\n",
       "      <td>0.412260</td>\n",
       "      <td>0.495859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.440498</td>\n",
       "      <td>0.413114</td>\n",
       "      <td>0.496097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  units  drop      lr  batch     score        f1       acc\n",
       "0    0     64   0.3  0.0001    128  0.434864  0.404241  0.497039\n",
       "1    1     64   0.3  0.0001    256  0.441192  0.411997  0.500465\n",
       "2    2     64   0.3  0.0010    128  0.455939  0.431767  0.505015\n",
       "3    3     64   0.3  0.0010    256  0.470292  0.446662  0.518267\n",
       "4    4     64   0.5  0.0001    128  0.444374  0.418117  0.497685\n",
       "5    5     64   0.5  0.0001    256  0.460383  0.436717  0.508430\n",
       "6    6     64   0.5  0.0010    128  0.452841  0.428462  0.502337\n",
       "7    7     64   0.5  0.0010    256  0.472827  0.449803  0.519572\n",
       "8    8    128   0.3  0.0001    128  0.441810  0.420034  0.486022\n",
       "9    9    128   0.3  0.0001    256  0.426329  0.395553  0.488813\n",
       "10  10    128   0.3  0.0010    128  0.474384  0.453128  0.517541\n",
       "11  11    128   0.3  0.0010    256  0.442751  0.415163  0.498763\n",
       "12  12    128   0.5  0.0001    128  0.471071  0.453654  0.506433\n",
       "13  13    128   0.5  0.0001    256  0.466007  0.446961  0.504675\n",
       "14  14    128   0.5  0.0010    128  0.439847  0.412260  0.495859\n",
       "15  15    128   0.5  0.0010    256  0.440498  0.413114  0.496097"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_11 (GRU)                 (None, 128)               279936    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 280,839\n",
      "Trainable params: 280,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:01<00:00,  4.37s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:09<00:00,  4.96s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:44<00:00,  3.20s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:55<00:00,  3.98s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:53<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243006, 10, 600)\n",
      "(243006, 7)\n",
      "5832144000 13608336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.516659463462555, 0.46437548546606505, 0.6228117824251254]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.767240</td>\n",
       "      <td>0.680740</td>\n",
       "      <td>0.721406</td>\n",
       "      <td>0.761088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.427654</td>\n",
       "      <td>0.488359</td>\n",
       "      <td>0.455995</td>\n",
       "      <td>0.966017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.226056</td>\n",
       "      <td>0.278730</td>\n",
       "      <td>0.249645</td>\n",
       "      <td>0.967421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.092292</td>\n",
       "      <td>0.320371</td>\n",
       "      <td>0.143302</td>\n",
       "      <td>0.955816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.751147</td>\n",
       "      <td>0.635307</td>\n",
       "      <td>0.688388</td>\n",
       "      <td>0.845679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.300260</td>\n",
       "      <td>0.515628</td>\n",
       "      <td>0.379519</td>\n",
       "      <td>0.838625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.649783</td>\n",
       "      <td>0.579038</td>\n",
       "      <td>0.612374</td>\n",
       "      <td>0.910978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all</td>\n",
       "      <td>0.459204</td>\n",
       "      <td>0.499739</td>\n",
       "      <td>0.464375</td>\n",
       "      <td>0.892232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class    recall  precision        f1  accuracy\n",
       "0     0  0.767240   0.680740  0.721406  0.761088\n",
       "1     1  0.427654   0.488359  0.455995  0.966017\n",
       "2     2  0.226056   0.278730  0.249645  0.967421\n",
       "3     3  0.092292   0.320371  0.143302  0.955816\n",
       "4     4  0.751147   0.635307  0.688388  0.845679\n",
       "5     5  0.300260   0.515628  0.379519  0.838625\n",
       "6     6  0.649783   0.579038  0.612374  0.910978\n",
       "7   all  0.459204   0.499739  0.464375  0.892232"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
