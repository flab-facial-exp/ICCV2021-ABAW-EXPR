{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.HIGHEST_PROTOCOL = 4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import func_proc_filepath as mFILE\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, GRU, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.utils import Sequence\n",
    "from keras import backend as K\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Callback(Callback):\n",
    "    def __init__(self, model, X_val, y_val, path):\n",
    "        self.model = model\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        self.path = path\n",
    "        self.best_score = -1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pred = self.model.predict(self.X_val)\n",
    "        f1_val = f1_score(self.y_val, np.round(pred), average='macro')\n",
    "        acc_val = accuracy_score(self.y_val, np.round(pred))\n",
    "        score = f1_val*0.67 + acc_val*0.33\n",
    "        log = \"Score = {0}, F1 = {1}, ACC = {2}\".format(score, f1_val, acc_val)\n",
    "        print(log)\n",
    "        # 以下チェックポイントなど必要なら書く\n",
    "        if score > self.best_score:\n",
    "            self.best_score = score\n",
    "            self.model.save(self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y: after one hot encoding\n",
    "def create_gru_model(np_train_x, np_train_y, np_val_x, np_val_y, n_class, n_units=64, drop=0.5, lr=1e-4, \n",
    "                     batch=128, model_path=\"\"):\n",
    "    # ** fix random seed **\n",
    "    FIX_SEED = 49\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(FIX_SEED)\n",
    "    random.seed(FIX_SEED)\n",
    "    session_conf = tf.compat.v1.ConfigProto()\n",
    "    tf.compat.v1.set_random_seed(FIX_SEED)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    # *********************\n",
    "    \n",
    "    #*********************************************    \n",
    "    # モデルの定義\n",
    "    model = Sequential()\n",
    "    \n",
    "    n_rnn = np_train_x.shape[1]\n",
    "    n_feat = np_train_x.shape[2]\n",
    "    adam = Adam(lr=lr)\n",
    "    \n",
    "    #model.add(Bidirectional(GRU(units=n_units, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=False)))\n",
    "    #model.add(GRU(units=128, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=True))\n",
    "    #model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(GRU(units=n_units, input_shape=(n_rnn, n_feat), dropout=drop, return_sequences=False))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=[\"accuracy\", f1])\n",
    "\n",
    "    #model_path = dir_out + \"\\\\model_multi_image\" + footer + \".h5\"\n",
    "    #cb_early = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "    cb_early = EarlyStopping(monitor='val_f1', patience=8, verbose=0, mode='max')\n",
    "    \n",
    "    model.fit(np_train_x, np_train_y,\n",
    "              epochs=30,\n",
    "              batch_size=batch,\n",
    "              validation_data=(np_val_x, np_val_y),\n",
    "              callbacks=[F1Callback(model, np_val_x, np_val_y, model_path), cb_early])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # bestモデルを読み込んで、重みやオプティマイザーを含むモデル全体を再作成\n",
    "    new_model = keras.models.load_model(model_path, custom_objects={'f1':f1})\n",
    "    \n",
    "    pred_nn = new_model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    \n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    del model\n",
    "    del new_model\n",
    "    \n",
    "    return scores_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predict data\n",
    "def eval_pred_each_class(np_true, np_pred, num_class):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    # calc\n",
    "    for i in range(num_class):\n",
    "        # i以外を0、iを1に置き換える\n",
    "        y_true_i = np.where(np_true == i, 1, 0)\n",
    "        y_pred_i = np.where(np_pred == i, 1, 0)\n",
    "\n",
    "        recall_i = recall_score(y_true_i, y_pred_i, average='binary')\n",
    "        precision_i = precision_score(y_true_i, y_pred_i, average='binary')\n",
    "        f1_i = f1_score(y_true_i, y_pred_i, average='binary')\n",
    "        acc_i = accuracy_score(y_true_i, y_pred_i)\n",
    "\n",
    "        df_reslut = pd.DataFrame({\"class\":[i], \"recall\":[recall_i], \"precision\":[precision_i], \n",
    "                                 \"f1\":[f1_i], \"accuracy\":[acc_i]})\n",
    "        #result_i = [recall_i, precision_i, f1_i, acc_i]\n",
    "\n",
    "        result.append(df_reslut)\n",
    "\n",
    "    df_out = pd.concat([x for x in result], axis=0, ignore_index=True)\n",
    "    f1_all = df_out.loc[:, \"f1\"].mean()\n",
    "    recall_all = df_out.loc[:, \"recall\"].mean()\n",
    "    precision_all = df_out.loc[:, \"precision\"].mean()\n",
    "    accuracy_all = df_out.loc[:, \"accuracy\"].mean()\n",
    "    df_all = pd.DataFrame({\"class\":[\"all\"], \"recall\":[recall_all], \"precision\":[precision_all], \n",
    "                                 \"f1\":[f1_all], \"accuracy\":[accuracy_all]})\n",
    "    df_out = pd.concat([df_out, df_all], axis=0, ignore_index=True)\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_train_balance(np_x, np_y):\n",
    "    \n",
    "    ny = np_y.ravel()\n",
    "    \n",
    "    np_x0 = np_x[ny==0,:,:]\n",
    "    np_x0 = np_x0[::2,:,:]\n",
    "    \n",
    "    np_y0 = ny[ny==0]\n",
    "    np_y0 = np_y0[::2]\n",
    "    \n",
    "    np_x1 = np_x[ny==1,:,:]\n",
    "    np_x1 = np.append(np_x1, np_x1, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x1, axis=0)\n",
    "    np_x1 = None\n",
    "    \n",
    "    \n",
    "    np_y1 = ny[ny==1]\n",
    "    np_y1 = np.append(np_y1, np_y1)\n",
    "    np_y0 =  np.append(np_y0, np_y1)\n",
    "    np_y1 = None\n",
    "    \n",
    "    np_x2 = np_x[ny==2,:,:]\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x2, axis=0)\n",
    "    np_x2 = None\n",
    "    \n",
    "    np_y2 = ny[ny==2]\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y0 =  np.append(np_y0, np_y2)\n",
    "    np_y2 = None\n",
    "    \n",
    "    np_x3 = np_x[ny==3,:,:]\n",
    "    np_x3 = np.append(np_x3, np_x3, axis=0)\n",
    "    np_x3 = np.append(np_x3, np_x3, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x3, axis=0)\n",
    "    np_x3 = None\n",
    "    \n",
    "    np_y3 = ny[ny==3]\n",
    "    np_y3 = np.append(np_y3, np_y3)\n",
    "    np_y3 = np.append(np_y3, np_y3)\n",
    "    np_y0 =  np.append(np_y0, np_y3)\n",
    "    np_y3 = None\n",
    "    \n",
    "    np_x4 = np_x[ny==4,:,:]\n",
    "    np_x4 = np_x4[::3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x4, axis=0)\n",
    "    np_x4 = None\n",
    "    \n",
    "    np_y4 = ny[ny==4]\n",
    "    np_y4 = np_y4[::3]\n",
    "    np_y0 =  np.append(np_y0, np_y4)\n",
    "    np_y4 = None\n",
    "    \n",
    "    np_x5 = np_x[ny==5,:,:]\n",
    "    np_x5 = np_x5[::2,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x5, axis=0)\n",
    "    np_x5 = None\n",
    "    \n",
    "    np_y5 = ny[ny==5]\n",
    "    np_y5 = np_y5[::2]\n",
    "    np_y0 =  np.append(np_y0, np_y5)\n",
    "    np_y5 = None\n",
    "    \n",
    "    np_x6 = np_x[ny==6,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x6, axis=0)\n",
    "    np_x6 = None\n",
    "    \n",
    "    np_y6 = ny[ny==6]\n",
    "    np_y0 =  np.append(np_y0, np_y6)\n",
    "    np_y6 = None\n",
    "    \n",
    "    np_x = None\n",
    "    np_y = None\n",
    "    ny = None\n",
    "    \n",
    "    p =np.random.RandomState(seed=49).permutation(len(np_x0))\n",
    "    np_x0 = np_x0[p]\n",
    "    np_y0 = np_y0[p]\n",
    "    \n",
    "    \n",
    "    return np_x0, np_y0.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_val_balance(np_x, np_y): #::7, 1, *2, 1, ::4, ::3, ::2\n",
    "    \n",
    "    ny = np_y.ravel()\n",
    "    \n",
    "    np_x0 = np_x[ny==0,:,:]\n",
    "    np_x0 = np_x0[::3,:,:]\n",
    "    \n",
    "    np_y0 = ny[ny==0]\n",
    "    np_y0 = np_y0[::3]\n",
    "    \n",
    "    np_x1 = np_x[ny==1,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x1, axis=0)\n",
    "    np_x1 = None\n",
    "    \n",
    "    \n",
    "    np_y1 = ny[ny==1]\n",
    "    np_y0 =  np.append(np_y0, np_y1)\n",
    "    np_y1 = None\n",
    "    \n",
    "    np_x2 = np_x[ny==2,:,:]\n",
    "    np_x2 = np.append(np_x2, np_x2, axis=0)\n",
    "    np_x0 =  np.append(np_x0, np_x2, axis=0)\n",
    "    np_x2 = None\n",
    "    \n",
    "    np_y2 = ny[ny==2]\n",
    "    np_y2 = np.append(np_y2, np_y2)\n",
    "    np_y0 =  np.append(np_y0, np_y2)\n",
    "    np_y2 = None\n",
    "    \n",
    "    np_x3 = np_x[ny==3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x3, axis=0)\n",
    "    np_x3 = None\n",
    "    \n",
    "    np_y3 = ny[ny==3]\n",
    "    np_y0 =  np.append(np_y0, np_y3)\n",
    "    np_y3 = None\n",
    "    \n",
    "    np_x4 = np_x[ny==4,:,:]\n",
    "    np_x4 = np_x4[::4,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x4, axis=0)\n",
    "    np_x4 = None\n",
    "    \n",
    "    np_y4 = ny[ny==4]\n",
    "    np_y4 = np_y4[::4]\n",
    "    np_y0 =  np.append(np_y0, np_y4)\n",
    "    np_y4 = None\n",
    "    \n",
    "    np_x5 = np_x[ny==5,:,:]\n",
    "    np_x5 = np_x5[::3,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x5, axis=0)\n",
    "    np_x5 = None\n",
    "    \n",
    "    np_y5 = ny[ny==5]\n",
    "    np_y5 = np_y5[::3]\n",
    "    np_y0 =  np.append(np_y0, np_y5)\n",
    "    np_y5 = None\n",
    "    \n",
    "    np_x6 = np_x[ny==6,:,:]\n",
    "    np_x6 = np_x6[::2,:,:]\n",
    "    np_x0 =  np.append(np_x0, np_x6, axis=0)\n",
    "    np_x6 = None\n",
    "    \n",
    "    np_y6 = ny[ny==6]\n",
    "    np_y6 = np_y6[::2]\n",
    "    np_y0 =  np.append(np_y0, np_y6)\n",
    "    np_y6 = None\n",
    "    \n",
    "    np_x = None\n",
    "    np_y = None\n",
    "    ny = None\n",
    "    \n",
    "    #p = np.random.permutation(len(np_x0))\n",
    "    p =np.random.RandomState(seed=49).permutation(len(np_x0))\n",
    "    np_x0 = np_x0[p]\n",
    "    np_y0 = np_y0[p]\n",
    "    \n",
    "    \n",
    "    return np_x0, np_y0.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_read_separate2(file_list, dir_data, dir_audio, pre_model, transformer, balance=0, sep_num=5, ignore_feat=False):\n",
    "    \n",
    "    step = -(-len(file_list) // sep_num)\n",
    "    \n",
    "    np_x_out_list = []\n",
    "    np_y_out_list = []\n",
    "    \n",
    "    for s in range(sep_num):\n",
    "        \n",
    "        start = step*s\n",
    "        stop = step*(s+1)\n",
    "        if stop>len(file_list):\n",
    "            stop = len(file_list)\n",
    "            \n",
    "        file_list_sep = file_list[start:stop]\n",
    "        \n",
    "        np_x_list = []\n",
    "        np_y_list = []\n",
    "\n",
    "        for i in tqdm(range(len(file_list_sep))):\n",
    "            name = os.path.splitext(os.path.basename(file_list_sep[i]))[0]\n",
    "\n",
    "            df_label = pd.read_csv(file_list_sep[i])\n",
    "            #display(df_label)\n",
    "            df_label = df_label.drop([\"Anger\",\"Disgust\",\"Fear\",\"Happiness\",\"Sadness\",\"Surprise\"],axis=1)\n",
    "            df_label.columns = [\"expr\"]\n",
    "            #df_label[\"frame\"] = df_label.index\n",
    "            df_label.index.name = \"frame\"\n",
    "\n",
    "            df_data = pd.read_hdf(dir_data + \"\\\\\" + name + \".h5\")\n",
    "            df_data.set_index(\"frame\", drop=True, inplace=True)\n",
    "            #display(df_data)\n",
    "            df_audio = pd.read_hdf(dir_audio + \"\\\\\" + name + \".h5\")\n",
    "            df_audio.set_index(\"frame\", drop=True, inplace=True)\n",
    "\n",
    "            #df_merge = pd.merge(df_label, df_data, on=\"frame\", how=\"outer\")\n",
    "            #df_merge = pd.merge(df_merge, df_audio, on=\"frame\", how=\"outer\")\n",
    "            df_merge = df_label.join([df_data, df_audio], how=\"outer\")\n",
    "            # interpolate 30 frame back\n",
    "            df_merge.interpolate(method=\"index\", limit=30, limit_direction='backward', inplace=True)\n",
    "            #df_merge.fillna(0, inplace=True)\n",
    "            #df_merge = df_merge.loc[df_merge.loc[:,\"expr\"]>=0,:]\n",
    "\n",
    "            np_x = df_merge.loc[:, df_merge.columns.str.contains(\"AU|pose_R|gaze|vgg-\")].values\n",
    "            np_y = df_merge.loc[:, df_merge.columns.str.contains(\"expr\")].values\n",
    "            pre_x = pre_model.predict(np_x)\n",
    "            \n",
    "            # normalize by single subject\n",
    "            np_mean_sub = np.nanmean(pre_x, axis=0)\n",
    "            np_std_sub = np.nanstd(pre_x, axis=0, ddof=1)\n",
    "            np_x_sub = (pre_x - np_mean_sub)/np_std_sub\n",
    "            df_sub = pd.DataFrame(np_x_sub)\n",
    "            df_sub.replace(np.inf, 9999, inplace=True)\n",
    "            df_sub.fillna(0, inplace=True)\n",
    "            df_sub.mask(df_sub > 5, 5, inplace=True)\n",
    "            df_sub.mask(df_sub < -5, -5, inplace=True)\n",
    "            df_sub.columns = [\"sub-\" + str(n) for n in df_sub.columns.values]\n",
    "            \n",
    "            np_audio = df_merge.loc[:, df_merge.columns.str.contains(\"audio\")].values\n",
    "            np_audio_mean = np.nanmean(np_audio, axis=0)\n",
    "            np_audio_std = np.nanstd(np_audio, axis=0, ddof=1)\n",
    "            np_audio_sub = (np_audio - np_audio_mean)/np_audio_std\n",
    "            df_audio_sub = pd.DataFrame(np_audio_sub)\n",
    "            df_audio_sub.replace(np.inf, 9999, inplace=True)\n",
    "            df_audio_sub.fillna(0, inplace=True)\n",
    "            df_audio_sub.mask(df_audio_sub > 5, 5, inplace=True)\n",
    "            df_audio_sub.mask(df_audio_sub < -5, -5, inplace=True)\n",
    "            df_audio_sub.columns = [\"subau-\" + str(n) for n in df_audio_sub.columns.values]\n",
    "            \n",
    "            # ***************\n",
    "            \n",
    "            df = pd.DataFrame(pre_x)\n",
    "            #df = pd.concat([df, df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "            #df = pd.concat([df, df_merge.loc[:, df_merge.columns.str.contains(\"audio\")],\n",
    "            #                df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "            df = pd.concat([df, df_sub, \n",
    "                            df_merge.loc[:, df_merge.columns.str.contains(\"audio\")], df_audio_sub, \n",
    "                            df_merge.loc[:, df_merge.columns.str.contains(\"expr\")]], axis=1)\n",
    "            \n",
    "            batch_length = 90\n",
    "            feat_size = 1200\n",
    "            np_x_tmp_list = []\n",
    "            np_y_tmp_list = []\n",
    "            for i in range(len(df)):\n",
    "                label = df.at[i, \"expr\"]\n",
    "                if label >= 0:         \n",
    "                    if ignore_feat==True:\n",
    "                        np_tmp = np.zeros((batch_length, feat_size))\n",
    "                        #np_tmp2 = df_feat.iloc[i-batch_length+1:i+1, :].values\n",
    "                        if i-batch_length+1 < 0:\n",
    "                            np_tmp = np.zeros((batch_length-i-1, feat_size))\n",
    "                            np_tmp2 = df.iloc[0:i+1, 0:feat_size].values\n",
    "                            np_tmp = np.append(np_tmp, np_tmp2, axis=0)\n",
    "                        else:\n",
    "                            np_tmp = df.iloc[i-batch_length+1:i+1, 0:feat_size].values\n",
    "\n",
    "                        np_tmp = np_tmp.astype(np.float32)\n",
    "                        #np_tmp = np_tmp[::5,:]\n",
    "                        np_tmp = np_tmp[np.newaxis, ::6, :]\n",
    "                        np_tmp = np.nan_to_num(np_tmp)\n",
    "\n",
    "                        np_x_tmp_list.append(np_tmp)\n",
    "                        np_y_tmp_list.append(label)\n",
    "                    else:\n",
    "                        if df.at[i,0]!=np.nan:\n",
    "                            np_tmp = np.zeros((batch_length, feat_size))\n",
    "                            #np_tmp2 = df_feat.iloc[i-batch_length+1:i+1, :].values\n",
    "                            if i-batch_length+1 < 0:\n",
    "                                np_tmp = np.zeros((batch_length-i-1, feat_size))\n",
    "                                np_tmp2 = df.iloc[0:i+1, 0:feat_size].values\n",
    "                                np_tmp = np.append(np_tmp, np_tmp2, axis=0)\n",
    "                            else:\n",
    "                                np_tmp = df.iloc[i-batch_length+1:i+1, 0:feat_size].values\n",
    "\n",
    "                            np_tmp = np_tmp.astype(np.float32)\n",
    "                            #np_tmp = np_tmp[::5,:]\n",
    "                            np_tmp = np_tmp[np.newaxis, ::6, :]\n",
    "                            np_tmp = np.nan_to_num(np_tmp)\n",
    "\n",
    "                            np_x_tmp_list.append(np_tmp)\n",
    "                            np_y_tmp_list.append(label)\n",
    "\n",
    "            if len(np_x_tmp_list) > 0:\n",
    "                np_x_tmp = np.concatenate([x for x in np_x_tmp_list], 0)\n",
    "                np_y_tmp = np.array(np_y_tmp_list)\n",
    "                np_x_list.append(np_x_tmp)\n",
    "                np_y_list.append(np_y_tmp)\n",
    "\n",
    "        # finish\n",
    "        np_data_x = np.concatenate([x for x in np_x_list], 0)\n",
    "        np_data_y = np.concatenate([x for x in np_y_list], 0).reshape(-1,1)\n",
    "        #np_data_y = np.concatenate([x for x in np_y_list], 0)\n",
    "\n",
    "        if balance == 1:\n",
    "            # balance and shuffle\n",
    "            np_data_x, np_data_y = np_train_balance(np_data_x, np_data_y)\n",
    "        elif balance == 2:\n",
    "            # balance and shuffle\n",
    "            np_data_x, np_data_y = np_val_balance(np_data_x, np_data_y)\n",
    "        \n",
    "        np_x_out_list.append(np_data_x)\n",
    "        np_y_out_list.append(np_data_y)\n",
    "        \n",
    "    np_data_x = np.concatenate([x for x in np_x_out_list], 0)\n",
    "    np_data_y = np.concatenate([x for x in np_y_out_list], 0).reshape(-1,1) \n",
    "        \n",
    "    np_data_y = transformer.transform(np_data_y).toarray()\n",
    "    \n",
    "    return np_data_x, np_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # root folder\n",
    "    dir_root = str(Path(Path().resolve()).parent)\n",
    "\n",
    "    # input: folder path including original images\n",
    "    dir_data = dir_root + \"\\\\dataset\\\\aff2_images\\\\dataset\"\n",
    "    dir_audio = dir_root + \"\\\\dataset\\\\aff2_audio\\\\dataset\"\n",
    "\n",
    "    # input: expr labels\n",
    "    dir_label_train = dir_root + \"\\\\src\\\\annotations\\\\EXPR_Set\\\\Train_Set\"\n",
    "    dir_label_val = dir_root + \"\\\\src\\\\annotations\\\\EXPR_Set\\\\Validation_Set\"\n",
    "    \n",
    "    dir_model = dir_root + \"\\\\model_expr4\\\\model_image\"\n",
    "    \n",
    "    # output: folder path\n",
    "    dir_out = dir_root + \"\\\\model_expr4\\\\model_mix\"\n",
    "    if os.path.isdir(dir_out) == False:\n",
    "        os.makedirs(dir_out)\n",
    "    \n",
    "    model_path_base = \"model_modal_multi_norm\"\n",
    "    model_path_base_pre = \"model_image_single_pseudo\"\n",
    "    \n",
    "    # pre_model\n",
    "    file_pre_model = dir_model + \"\\\\\" + model_path_base_pre + \"_best.h5\"\n",
    "    base_model = keras.models.load_model(file_pre_model, custom_objects={'f1':f1})\n",
    "    layer_name = 'vgg_au'\n",
    "    pre_model = Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)  \n",
    "    # *****\n",
    "    \n",
    "    train_list = mFILE.search_files(dir_label_train, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)    \n",
    "    val_list = mFILE.search_files(dir_label_val, valid_names=[\".txt\"], invalid_names=[\"wuert\"], ext=None, recursive=False)\n",
    "    \n",
    "    dummy = [[0],[1],[2],[3],[4],[5],[6]]\n",
    "    transformer = OneHotEncoder().fit(dummy)\n",
    "    #np_train_y_hot = transformer.transform(np_train_y).toarray()\n",
    "    #np_val_y_hot = transformer.transform(np_val_y).toarray()\n",
    "    \n",
    "    len_train = len(train_list)\n",
    "    len_val = len(val_list)\n",
    "    #len_train = 2\n",
    "    #len_val = 1\n",
    "    \n",
    "    np_train_x, np_train_y = data_read_separate2(train_list, dir_data, dir_audio,\n",
    "                                            pre_model, transformer, balance=1, sep_num=5, ignore_feat=False)\n",
    "    \n",
    "    print(np_train_x.shape)\n",
    "    print(np_train_y.shape)\n",
    "    print(np_train_x.nbytes, np_train_y.nbytes)\n",
    "    \n",
    "    np_val_x, np_val_y = data_read_separate2(val_list, dir_data, dir_audio,\n",
    "                                            pre_model, transformer, balance=2, sep_num=5, ignore_feat=False)\n",
    "    \n",
    "    print(np_val_x.shape)\n",
    "    print(np_val_y.shape)\n",
    "    print(np_val_x.nbytes, np_val_y.nbytes)\n",
    "    \n",
    "\n",
    "    len_feat = np_val_x.shape[2]\n",
    "    len_class = np_val_y.shape[1]\n",
    "    display(len_class)\n",
    "    \n",
    "    # search parameter\n",
    "    score_list = []\n",
    "    #***\n",
    "    \n",
    "    l_units = [64, 128]\n",
    "    l_drop = [0.3, 0.5]\n",
    "    l_lr = [1e-4, 1e-3]\n",
    "    l_batch = [128, 256]\n",
    "    MAX_COUNT = len(l_units)*len(l_drop)*len(l_lr)*len(l_batch)\n",
    "    COUNT = 0\n",
    "    \n",
    "    for _units in l_units:\n",
    "        for _drop in l_drop:\n",
    "            for _lr in l_lr:\n",
    "                for _batch in l_batch:\n",
    "                    model_path = dir_out + \"\\\\\" + model_path_base + \"_{0:02d}.h5\".format(COUNT)\n",
    "                    scores = create_gru_model(np_train_x, np_train_y, np_val_x, np_val_y, len_class,\n",
    "                                              n_units=_units, drop=_drop, lr=_lr, batch=_batch,\n",
    "                                              model_path=model_path)\n",
    "                    param = [COUNT, _units, _drop, _lr, _batch]\n",
    "                    param.extend(scores)\n",
    "                    score_list.append(param)\n",
    "                    COUNT = COUNT + 1\n",
    "        \n",
    "        \n",
    "    # ******************* validation balances frames  ********************\n",
    "    print(score_list)\n",
    "    \n",
    "    df_res = pd.DataFrame(score_list, columns = [\"id\", \"units\", \"drop\", \"lr\", \"batch\", \"score\", \"f1\", \"acc\"])\n",
    "    display(df_res)\n",
    "    file_out = dir_out + \"\\\\res0_\" + model_path_base + \".csv\"\n",
    "    df_res.to_csv(file_out, index=False)\n",
    "    \n",
    "    best_id = df_res.loc[:,\"score\"].idxmax()\n",
    "    \n",
    "    best_path = dir_out + \"\\\\\" + model_path_base + \"_{0:02d}.h5\".format(best_id)\n",
    "    out_path = dir_out + \"\\\\\" + model_path_base + \"_best.h5\"\n",
    "    #best_path = dir_out + \"\\\\model_image_multi_b2\" + \"_{0:02d}.h5\".format(best_id)\n",
    "    #out_path = dir_out + \"\\\\model_image_multi_b2_best.h5\"\n",
    "    shutil.copy(best_path, out_path)\n",
    "    \n",
    "    \n",
    "    np_x_list = None\n",
    "    np_y_list = None\n",
    "    np_train_x = None\n",
    "    np_train_y = None\n",
    "    np_val_x = None\n",
    "    np_val_y = None\n",
    "    \n",
    "    # ******************* validation all frames  ********************\n",
    "    \n",
    "    #file_model = dir_out + \"\\\\model_image_multi_best.h5\"\n",
    "    model = keras.models.load_model(out_path, custom_objects={'f1':f1})\n",
    "    model.summary()\n",
    "    # ******\n",
    "    \n",
    "    np_val_x, np_val_y = data_read_separate2(val_list, dir_data, dir_audio,\n",
    "                                            pre_model, transformer, balance=0, sep_num=5, ignore_feat=True)\n",
    "    \n",
    "    print(np_val_x.shape)\n",
    "    print(np_val_y.shape)\n",
    "    print(np_val_x.nbytes, np_val_y.nbytes)\n",
    "\n",
    "    len_feat = np_val_x.shape[2]\n",
    "    len_class = np_val_y.shape[1]\n",
    "    display(len_class)\n",
    "    \n",
    "    pred_nn = model.predict(np_val_x)\n",
    "    score_nn_f = f1_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), average='macro')\n",
    "    score_nn_a = accuracy_score(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1))\n",
    "    score_nn = score_nn_f*0.67 + score_nn_a*0.33\n",
    "    \n",
    "    scores_nn = [score_nn, score_nn_f, score_nn_a]\n",
    "    display([\"0.67*F1+0.33*ACC\", \"F1 score\", \"ACC score\"])\n",
    "    display(scores_nn)\n",
    "    \n",
    "    df_out = eval_pred_each_class(np.argmax(np_val_y, axis=1), np.argmax(pred_nn, axis=1), 7)\n",
    "    display(df_out)\n",
    "    \n",
    "    file_out = dir_out + \"\\\\res1_\" + model_path_base + \".csv\"\n",
    "    df_out.to_csv(file_out, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [04:03<00:00,  4.78s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [02:28<00:00,  2.91s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [01:56<00:00,  2.28s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [03:26<00:00,  4.04s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [03:59<00:00,  4.89s/it]\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(394390, 10, 1200)\n",
      "(394390, 7)\n",
      "18930720000 22085840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:18<00:00,  5.64s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:27<00:00,  6.27s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:57<00:00,  4.09s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:08<00:00,  4.90s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:10<00:00,  5.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102388, 10, 1200)\n",
      "(102388, 7)\n",
      "4914624000 5733728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 136s 345us/step - loss: 0.6292 - accuracy: 0.7924 - f1: 0.7674 - val_loss: 1.7085 - val_accuracy: 0.5337 - val_f1: 0.5270\n",
      "Score = 0.44568372015466856, F1 = 0.4206723260362864, ACC = 0.49646442942532326\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 91s 231us/step - loss: 0.3106 - accuracy: 0.8987 - f1: 0.8978 - val_loss: 1.9842 - val_accuracy: 0.5396 - val_f1: 0.5368\n",
      "Score = 0.45945481305581815, F1 = 0.43012356565745963, ACC = 0.5190061335312732\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 91s 230us/step - loss: 0.2301 - accuracy: 0.9247 - f1: 0.9246 - val_loss: 2.2410 - val_accuracy: 0.5388 - val_f1: 0.5369\n",
      "Score = 0.455106981732571, F1 = 0.42108470100615925, ACC = 0.5241825213892253\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 90s 227us/step - loss: 0.1866 - accuracy: 0.9384 - f1: 0.9386 - val_loss: 2.3684 - val_accuracy: 0.5356 - val_f1: 0.5349\n",
      "Score = 0.4556588498425419, F1 = 0.42224511964260886, ACC = 0.5234988475211939\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 90s 228us/step - loss: 0.1570 - accuracy: 0.9484 - f1: 0.9485 - val_loss: 2.5358 - val_accuracy: 0.5356 - val_f1: 0.5356\n",
      "Score = 0.45410683688873876, F1 = 0.41873086828861383, ACC = 0.525930773137477\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 91s 230us/step - loss: 0.1353 - accuracy: 0.9555 - f1: 0.9555 - val_loss: 2.6631 - val_accuracy: 0.5392 - val_f1: 0.5398\n",
      "Score = 0.4569794825855904, F1 = 0.42022349959057453, ACC = 0.5316052662421378\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 92s 233us/step - loss: 0.1205 - accuracy: 0.9606 - f1: 0.9607 - val_loss: 2.7936 - val_accuracy: 0.5293 - val_f1: 0.5295\n",
      "Score = 0.4427162300911009, F1 = 0.4036156780057545, ACC = 0.5221021994765012\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 91s 231us/step - loss: 0.1056 - accuracy: 0.9653 - f1: 0.9653 - val_loss: 2.9433 - val_accuracy: 0.5371 - val_f1: 0.5364\n",
      "Score = 0.4480419242423594, F1 = 0.4076342980276766, ACC = 0.530081650193382\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 91s 232us/step - loss: 0.0986 - accuracy: 0.9676 - f1: 0.9676 - val_loss: 2.9562 - val_accuracy: 0.5303 - val_f1: 0.5300\n",
      "Score = 0.446129386843515, F1 = 0.4078199996054489, ACC = 0.5239090518420128\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 90s 229us/step - loss: 0.0898 - accuracy: 0.9708 - f1: 0.9709 - val_loss: 3.1193 - val_accuracy: 0.5327 - val_f1: 0.5322\n",
      "Score = 0.44643622607092937, F1 = 0.40659429415046755, ACC = 0.5273274211821698\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 91s 230us/step - loss: 0.0827 - accuracy: 0.9729 - f1: 0.9731 - val_loss: 3.2700 - val_accuracy: 0.5293 - val_f1: 0.5289\n",
      "Score = 0.4437180978638061, F1 = 0.40429321830624065, ACC = 0.5237625502988631\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 92s 234us/step - loss: 0.0781 - accuracy: 0.9746 - f1: 0.9746 - val_loss: 3.3217 - val_accuracy: 0.5302 - val_f1: 0.5297\n",
      "Score = 0.44211400686477176, F1 = 0.4014228132912941, ACC = 0.5247294604836504\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 92s 232us/step - loss: 0.0734 - accuracy: 0.9759 - f1: 0.9759 - val_loss: 3.3928 - val_accuracy: 0.5292 - val_f1: 0.5292\n",
      "Score = 0.44290460000190773, F1 = 0.40278560198862107, ACC = 0.5243583232410048\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 91s 231us/step - loss: 0.0697 - accuracy: 0.9770 - f1: 0.9770 - val_loss: 3.3964 - val_accuracy: 0.5290 - val_f1: 0.5291\n",
      "Score = 0.4448583550841221, F1 = 0.40587964279211075, ACC = 0.5239969527679025\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 64)                242880    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,335\n",
      "Trainable params: 243,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.47080836471166954, 0.4369238239511863, 0.5396042504981052]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 47s 120us/step - loss: 0.7407 - accuracy: 0.7541 - f1: 0.7179 - val_loss: 1.5899 - val_accuracy: 0.5290 - val_f1: 0.5194\n",
      "Score = 0.43292902913803716, F1 = 0.4103280444388794, ACC = 0.4788158768605696\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 47s 119us/step - loss: 0.3713 - accuracy: 0.8794 - f1: 0.8778 - val_loss: 1.8318 - val_accuracy: 0.5410 - val_f1: 0.5361\n",
      "Score = 0.4581027327787026, F1 = 0.4308715719913802, ACC = 0.5133902410438723\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 47s 118us/step - loss: 0.2818 - accuracy: 0.9080 - f1: 0.9076 - val_loss: 2.0390 - val_accuracy: 0.5401 - val_f1: 0.5380\n",
      "Score = 0.46121989195561564, F1 = 0.43158906065763836, ACC = 0.5213794585302965\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 46s 118us/step - loss: 0.2307 - accuracy: 0.9246 - f1: 0.9248 - val_loss: 2.1938 - val_accuracy: 0.5418 - val_f1: 0.5405\n",
      "Score = 0.46343060782555306, F1 = 0.4320889264956237, ACC = 0.5270637184045005\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 46s 118us/step - loss: 0.1955 - accuracy: 0.9358 - f1: 0.9360 - val_loss: 2.3317 - val_accuracy: 0.5393 - val_f1: 0.5379\n",
      "Score = 0.46094758301480016, F1 = 0.4286426862307114, ACC = 0.526536312849162\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 46s 118us/step - loss: 0.1700 - accuracy: 0.9441 - f1: 0.9443 - val_loss: 2.5120 - val_accuracy: 0.5367 - val_f1: 0.5359\n",
      "Score = 0.45534674376115647, F1 = 0.4204996970875389, ACC = 0.5260968082197133\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 47s 118us/step - loss: 0.1504 - accuracy: 0.9507 - f1: 0.9509 - val_loss: 2.6277 - val_accuracy: 0.5267 - val_f1: 0.5266\n",
      "Score = 0.4463813073206261, F1 = 0.4113468767903692, ACC = 0.5175118177911474\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 46s 118us/step - loss: 0.1330 - accuracy: 0.9561 - f1: 0.9563 - val_loss: 2.7314 - val_accuracy: 0.5399 - val_f1: 0.5398\n",
      "Score = 0.4598063418514721, F1 = 0.4240722841454795, ACC = 0.5323573074969723\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 47s 118us/step - loss: 0.1211 - accuracy: 0.9602 - f1: 0.9603 - val_loss: 2.8117 - val_accuracy: 0.5329 - val_f1: 0.5330\n",
      "Score = 0.4527742805586228, F1 = 0.41669868375777874, ACC = 0.5260186740633668\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 47s 118us/step - loss: 0.1107 - accuracy: 0.9637 - f1: 0.9638 - val_loss: 2.9714 - val_accuracy: 0.5314 - val_f1: 0.5308\n",
      "Score = 0.4495621831432052, F1 = 0.4125779782913356, ACC = 0.5246513263273039\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 47s 118us/step - loss: 0.1016 - accuracy: 0.9665 - f1: 0.9667 - val_loss: 3.0282 - val_accuracy: 0.5319 - val_f1: 0.5312\n",
      "Score = 0.4498642910756892, F1 = 0.41283165521754916, ACC = 0.5250517638785795\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 47s 118us/step - loss: 0.0955 - accuracy: 0.9689 - f1: 0.9689 - val_loss: 3.1381 - val_accuracy: 0.5252 - val_f1: 0.5254\n",
      "Score = 0.4396215952274784, F1 = 0.3999492986898397, ACC = 0.5201683791069266\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 64)                242880    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,335\n",
      "Trainable params: 243,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4715146855705208, 0.43688605104426415, 0.5418213071844357]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 81s 207us/step - loss: 0.3066 - accuracy: 0.8982 - f1: 0.8959 - val_loss: 2.3547 - val_accuracy: 0.5417 - val_f1: 0.5403\n",
      "Score = 0.466978340722347, F1 = 0.43716276729431996, ACC = 0.5275129898034926\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 82s 209us/step - loss: 0.1858 - accuracy: 0.9376 - f1: 0.9378 - val_loss: 2.6341 - val_accuracy: 0.5273 - val_f1: 0.5269\n",
      "Score = 0.4497722682314964, F1 = 0.41723060771006937, ACC = 0.5158417001992421\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 82s 209us/step - loss: 0.1619 - accuracy: 0.9459 - f1: 0.9461 - val_loss: 2.8597 - val_accuracy: 0.5269 - val_f1: 0.5267\n",
      "Score = 0.4458731875439509, F1 = 0.4099390717756984, ACC = 0.5188303316794937\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 82s 207us/step - loss: 0.1508 - accuracy: 0.9492 - f1: 0.9497 - val_loss: 2.9290 - val_accuracy: 0.5261 - val_f1: 0.5263\n",
      "Score = 0.44061948811177554, F1 = 0.4024633272204308, ACC = 0.5180880571942025\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 84s 213us/step - loss: 0.1434 - accuracy: 0.9521 - f1: 0.9523 - val_loss: 2.9701 - val_accuracy: 0.5276 - val_f1: 0.5283\n",
      "Score = 0.4497727455877594, F1 = 0.4149319019317141, ACC = 0.5205102160409423\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 84s 212us/step - loss: 0.1388 - accuracy: 0.9537 - f1: 0.9539 - val_loss: 3.0735 - val_accuracy: 0.5223 - val_f1: 0.5235\n",
      "Score = 0.441051066302136, F1 = 0.4043870663560604, ACC = 0.5154900964956831\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 84s 213us/step - loss: 0.1343 - accuracy: 0.9550 - f1: 0.9552 - val_loss: 3.3221 - val_accuracy: 0.5114 - val_f1: 0.5119\n",
      "Score = 0.42454673562263956, F1 = 0.3848913493088162, ACC = 0.5050591866234324\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 84s 212us/step - loss: 0.1326 - accuracy: 0.9560 - f1: 0.9562 - val_loss: 3.1331 - val_accuracy: 0.5248 - val_f1: 0.5250\n",
      "Score = 0.4419985047473986, F1 = 0.40418963661315027, ACC = 0.5187619642926905\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 84s 213us/step - loss: 0.1320 - accuracy: 0.9564 - f1: 0.9565 - val_loss: 3.1016 - val_accuracy: 0.5211 - val_f1: 0.5216\n",
      "Score = 0.43613140366634406, F1 = 0.39723670623991086, ACC = 0.5150994257139508\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 64)                242880    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,335\n",
      "Trainable params: 243,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4741528055445948, 0.4408620275303363, 0.5417431730280893]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 50s 126us/step - loss: 0.3249 - accuracy: 0.8920 - f1: 0.8889 - val_loss: 2.4678 - val_accuracy: 0.5264 - val_f1: 0.5259\n",
      "Score = 0.4440277652986194, F1 = 0.4091281515819403, ACC = 0.5148845567839981\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 49s 124us/step - loss: 0.1722 - accuracy: 0.9425 - f1: 0.9428 - val_loss: 2.8532 - val_accuracy: 0.5152 - val_f1: 0.5152\n",
      "Score = 0.4453787617708166, F1 = 0.415397044840702, ACC = 0.5062507325077158\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 49s 124us/step - loss: 0.1439 - accuracy: 0.9519 - f1: 0.9522 - val_loss: 3.0115 - val_accuracy: 0.5311 - val_f1: 0.5310\n",
      "Score = 0.45400404094917873, F1 = 0.4197079086446189, ACC = 0.5236355822948001\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 51s 129us/step - loss: 0.1301 - accuracy: 0.9568 - f1: 0.9570 - val_loss: 3.2416 - val_accuracy: 0.5112 - val_f1: 0.5116\n",
      "Score = 0.4246481855001675, F1 = 0.3854420384063073, ACC = 0.5042485447513381\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 52s 132us/step - loss: 0.1224 - accuracy: 0.9590 - f1: 0.9591 - val_loss: 3.1453 - val_accuracy: 0.5100 - val_f1: 0.5102\n",
      "Score = 0.43325000726988894, F1 = 0.3991849520662896, ACC = 0.5024123920771966\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 51s 128us/step - loss: 0.1173 - accuracy: 0.9610 - f1: 0.9613 - val_loss: 3.3857 - val_accuracy: 0.5128 - val_f1: 0.5130\n",
      "Score = 0.4275988854837537, F1 = 0.3887444640916783, ACC = 0.5064851349767551\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 50s 128us/step - loss: 0.1144 - accuracy: 0.9621 - f1: 0.9623 - val_loss: 3.4106 - val_accuracy: 0.5138 - val_f1: 0.5136\n",
      "Score = 0.4394481067671986, F1 = 0.40627112254409364, ACC = 0.5068074383716842\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 50s 127us/step - loss: 0.1100 - accuracy: 0.9636 - f1: 0.9638 - val_loss: 3.4582 - val_accuracy: 0.5038 - val_f1: 0.5031\n",
      "Score = 0.4230297338525823, F1 = 0.38691332166517584, ACC = 0.4963569949603469\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 50s 127us/step - loss: 0.1090 - accuracy: 0.9640 - f1: 0.9643 - val_loss: 3.5486 - val_accuracy: 0.5019 - val_f1: 0.5024\n",
      "Score = 0.419692967706443, F1 = 0.3818272427203643, ACC = 0.49657186389029967\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 49s 125us/step - loss: 0.1068 - accuracy: 0.9646 - f1: 0.9649 - val_loss: 3.6234 - val_accuracy: 0.5051 - val_f1: 0.5053\n",
      "Score = 0.4238033312817257, F1 = 0.3862591972833997, ACC = 0.5000293003086299\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 50s 126us/step - loss: 0.1045 - accuracy: 0.9653 - f1: 0.9655 - val_loss: 3.6220 - val_accuracy: 0.4974 - val_f1: 0.4972\n",
      "Score = 0.4269633849716399, F1 = 0.3954302168758737, ACC = 0.49098527171152867\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 64)                242880    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,335\n",
      "Trainable params: 243,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.45813433994012603, 0.4222021237007955, 0.5310876274563425]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 89s 226us/step - loss: 0.9380 - accuracy: 0.6782 - f1: 0.6395 - val_loss: 1.6141 - val_accuracy: 0.5376 - val_f1: 0.5286\n",
      "Score = 0.4450771504764243, F1 = 0.42193653295104155, ACC = 0.49205961636129236\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 88s 224us/step - loss: 0.5479 - accuracy: 0.8198 - f1: 0.8161 - val_loss: 1.8471 - val_accuracy: 0.5418 - val_f1: 0.5359\n",
      "Score = 0.45779520783759325, F1 = 0.43076374592748296, ACC = 0.512677266867211\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 89s 225us/step - loss: 0.4461 - accuracy: 0.8530 - f1: 0.8517 - val_loss: 1.9927 - val_accuracy: 0.5431 - val_f1: 0.5393\n",
      "Score = 0.46557224468695646, F1 = 0.4377483746201616, ACC = 0.5220631323983279\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 88s 224us/step - loss: 0.3853 - accuracy: 0.8733 - f1: 0.8731 - val_loss: 2.1192 - val_accuracy: 0.5481 - val_f1: 0.5454\n",
      "Score = 0.4718211802793564, F1 = 0.4425099811493002, ACC = 0.5313317966949251\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 89s 225us/step - loss: 0.3398 - accuracy: 0.8886 - f1: 0.8887 - val_loss: 2.2790 - val_accuracy: 0.5456 - val_f1: 0.5435\n",
      "Score = 0.46679506918788766, F1 = 0.43461867243085045, ACC = 0.5321229050279329\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 89s 225us/step - loss: 0.3064 - accuracy: 0.9001 - f1: 0.9002 - val_loss: 2.4103 - val_accuracy: 0.5422 - val_f1: 0.5409\n",
      "Score = 0.46287541617019, F1 = 0.4293072198705861, ACC = 0.5310290268390827\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 88s 223us/step - loss: 0.2765 - accuracy: 0.9093 - f1: 0.9098 - val_loss: 2.4899 - val_accuracy: 0.5406 - val_f1: 0.5398\n",
      "Score = 0.46225393263774583, F1 = 0.42865864141777227, ACC = 0.530462554205571\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 88s 224us/step - loss: 0.2546 - accuracy: 0.9169 - f1: 0.9172 - val_loss: 2.6362 - val_accuracy: 0.5400 - val_f1: 0.5391\n",
      "Score = 0.4567167050555284, F1 = 0.419773568340644, ACC = 0.5317224674766574\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 87s 220us/step - loss: 0.2353 - accuracy: 0.9234 - f1: 0.9237 - val_loss: 2.7333 - val_accuracy: 0.5326 - val_f1: 0.5313\n",
      "Score = 0.44956458898930396, F1 = 0.41262967409072615, ACC = 0.5245536586318709\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 87s 220us/step - loss: 0.2203 - accuracy: 0.9287 - f1: 0.9288 - val_loss: 2.7912 - val_accuracy: 0.5369 - val_f1: 0.5354\n",
      "Score = 0.45469292182443743, F1 = 0.4179027054791358, ACC = 0.5293882095558073\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 87s 220us/step - loss: 0.2066 - accuracy: 0.9332 - f1: 0.9333 - val_loss: 2.9165 - val_accuracy: 0.5378 - val_f1: 0.5369\n",
      "Score = 0.4545209468596888, F1 = 0.41686191518289245, ACC = 0.5309801929913662\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 87s 220us/step - loss: 0.1973 - accuracy: 0.9364 - f1: 0.9364 - val_loss: 3.0103 - val_accuracy: 0.5384 - val_f1: 0.5382\n",
      "Score = 0.45344161755432366, F1 = 0.414029109319482, ACC = 0.5334609524553658\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 64)                242880    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,335\n",
      "Trainable params: 243,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4818261848320189, 0.44916395596412517, 0.5481404070789546]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 1.0630 - accuracy: 0.6311 - f1: 0.5799 - val_loss: 1.5140 - val_accuracy: 0.5331 - val_f1: 0.5190\n",
      "Score = 0.4296640964580006, F1 = 0.4094284822927267, ACC = 0.470748525217799\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 53s 135us/step - loss: 0.6260 - accuracy: 0.7933 - f1: 0.7862 - val_loss: 1.7046 - val_accuracy: 0.5402 - val_f1: 0.5344\n",
      "Score = 0.4561465995643794, F1 = 0.4322092612910806, ACC = 0.5047466499980466\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 53s 135us/step - loss: 0.5125 - accuracy: 0.8316 - f1: 0.8290 - val_loss: 1.8343 - val_accuracy: 0.5482 - val_f1: 0.5449\n",
      "Score = 0.4709951146574397, F1 = 0.44510620413694013, ACC = 0.5235574481384537\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 0.4471 - accuracy: 0.8531 - f1: 0.8521 - val_loss: 1.9475 - val_accuracy: 0.5524 - val_f1: 0.5496\n",
      "Score = 0.476353533654836, F1 = 0.4492602561845714, ACC = 0.531361097003555\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 53s 135us/step - loss: 0.3995 - accuracy: 0.8690 - f1: 0.8685 - val_loss: 2.0645 - val_accuracy: 0.5499 - val_f1: 0.5477\n",
      "Score = 0.47189476949256487, F1 = 0.4418549465452273, ACC = 0.5328847130523108\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 53s 136us/step - loss: 0.3604 - accuracy: 0.8819 - f1: 0.8821 - val_loss: 2.1397 - val_accuracy: 0.5498 - val_f1: 0.5480\n",
      "Score = 0.47500336198429405, F1 = 0.44554215814189824, ACC = 0.5348185334218853\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 53s 135us/step - loss: 0.3302 - accuracy: 0.8926 - f1: 0.8929 - val_loss: 2.2613 - val_accuracy: 0.5441 - val_f1: 0.5425\n",
      "Score = 0.46599035094811736, F1 = 0.43399486024300654, ACC = 0.5309508926827362\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 53s 134us/step - loss: 0.3047 - accuracy: 0.9007 - f1: 0.9008 - val_loss: 2.3563 - val_accuracy: 0.5472 - val_f1: 0.5462\n",
      "Score = 0.4681503177738675, F1 = 0.4345344332012839, ACC = 0.5364007500879009\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 0.2829 - accuracy: 0.9075 - f1: 0.9077 - val_loss: 2.4464 - val_accuracy: 0.5441 - val_f1: 0.5428\n",
      "Score = 0.4645688369907961, F1 = 0.4304396690874692, ACC = 0.5338613900066415\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 53s 135us/step - loss: 0.2629 - accuracy: 0.9145 - f1: 0.9147 - val_loss: 2.5241 - val_accuracy: 0.5427 - val_f1: 0.5410\n",
      "Score = 0.4629452020175825, F1 = 0.4283674996920732, ACC = 0.5331484158299801\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 0.2476 - accuracy: 0.9197 - f1: 0.9201 - val_loss: 2.6089 - val_accuracy: 0.5411 - val_f1: 0.5398\n",
      "Score = 0.46128054156451986, F1 = 0.4264313286729039, ACC = 0.5320350041020432\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 53s 135us/step - loss: 0.2344 - accuracy: 0.9240 - f1: 0.9243 - val_loss: 2.6960 - val_accuracy: 0.5392 - val_f1: 0.5377\n",
      "Score = 0.4576148079670427, F1 = 0.4215613968015369, ACC = 0.53081415790913\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 64)                242880    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,335\n",
      "Trainable params: 243,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4880220860492912, 0.45631419240499305, 0.5523987185998359]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 92s 233us/step - loss: 0.5154 - accuracy: 0.8277 - f1: 0.8228 - val_loss: 2.1223 - val_accuracy: 0.5376 - val_f1: 0.5353\n",
      "Score = 0.46129975193928124, F1 = 0.43229994597021815, ACC = 0.5201781458764699\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 91s 230us/step - loss: 0.3550 - accuracy: 0.8829 - f1: 0.8828 - val_loss: 2.5476 - val_accuracy: 0.5331 - val_f1: 0.5330\n",
      "Score = 0.45052107956629905, F1 = 0.4150001296594666, ACC = 0.522639371801383\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 91s 231us/step - loss: 0.3211 - accuracy: 0.8957 - f1: 0.8958 - val_loss: 2.6491 - val_accuracy: 0.5271 - val_f1: 0.5264\n",
      "Score = 0.444406496101414, F1 = 0.4089093101924778, ACC = 0.516476540219557\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 90s 229us/step - loss: 0.3058 - accuracy: 0.9008 - f1: 0.9009 - val_loss: 2.6664 - val_accuracy: 0.5409 - val_f1: 0.5399\n",
      "Score = 0.46434652838776824, F1 = 0.43209941155310894, ACC = 0.5298179474157128\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 91s 230us/step - loss: 0.2979 - accuracy: 0.9032 - f1: 0.9036 - val_loss: 2.7857 - val_accuracy: 0.5322 - val_f1: 0.5324\n",
      "Score = 0.4535129506740251, F1 = 0.41875846565525815, ACC = 0.524075086924249\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 91s 231us/step - loss: 0.2937 - accuracy: 0.9053 - f1: 0.9055 - val_loss: 2.8151 - val_accuracy: 0.5283 - val_f1: 0.5279\n",
      "Score = 0.45020534471119333, F1 = 0.41555833027147043, ACC = 0.5205492831191155\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 92s 234us/step - loss: 0.2897 - accuracy: 0.9062 - f1: 0.9065 - val_loss: 2.9180 - val_accuracy: 0.5109 - val_f1: 0.5107\n",
      "Score = 0.4320647707821019, F1 = 0.3973822688940029, ACC = 0.5024807594639997\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 91s 231us/step - loss: 0.2859 - accuracy: 0.9079 - f1: 0.9083 - val_loss: 2.8306 - val_accuracy: 0.5348 - val_f1: 0.5355\n",
      "Score = 0.4467926783022125, F1 = 0.40645765312409704, ACC = 0.5286850021486893\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 91s 230us/step - loss: 0.2843 - accuracy: 0.9083 - f1: 0.9085 - val_loss: 2.8605 - val_accuracy: 0.5242 - val_f1: 0.5238\n",
      "Score = 0.4416670023240896, F1 = 0.4052823213593548, ACC = 0.5155389303433996\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 91s 232us/step - loss: 0.2811 - accuracy: 0.9092 - f1: 0.9098 - val_loss: 2.8126 - val_accuracy: 0.5294 - val_f1: 0.5279\n",
      "Score = 0.4477543402372949, F1 = 0.412183934046261, ACC = 0.5199730437160605\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 92s 232us/step - loss: 0.2794 - accuracy: 0.9101 - f1: 0.9105 - val_loss: 2.8518 - val_accuracy: 0.5272 - val_f1: 0.5269\n",
      "Score = 0.4440132834974637, F1 = 0.407134232596321, ACC = 0.5188889322967535\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 90s 229us/step - loss: 0.2796 - accuracy: 0.9106 - f1: 0.9107 - val_loss: 2.7913 - val_accuracy: 0.5308 - val_f1: 0.5303\n",
      "Score = 0.4575477865515096, F1 = 0.42564649847370123, ACC = 0.5223170684064539\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 64)                242880    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,335\n",
      "Trainable params: 243,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4698464526205203, 0.4348483379714774, 0.5409032308473649]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 51s 129us/step - loss: 0.5430 - accuracy: 0.8183 - f1: 0.8113 - val_loss: 2.1456 - val_accuracy: 0.5329 - val_f1: 0.5311\n",
      "Score = 0.45074726605808574, F1 = 0.4192342251679925, ACC = 0.5147282884713053\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 52s 131us/step - loss: 0.3407 - accuracy: 0.8880 - f1: 0.8884 - val_loss: 2.6080 - val_accuracy: 0.5299 - val_f1: 0.5296\n",
      "Score = 0.4457009446548109, F1 = 0.4091143540217338, ACC = 0.5199828104856038\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 51s 130us/step - loss: 0.2971 - accuracy: 0.9026 - f1: 0.9031 - val_loss: 2.7867 - val_accuracy: 0.5346 - val_f1: 0.5348\n",
      "Score = 0.44986106974613727, F1 = 0.4113548347428701, ACC = 0.5280403953588311\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 51s 129us/step - loss: 0.2757 - accuracy: 0.9110 - f1: 0.9113 - val_loss: 2.8181 - val_accuracy: 0.5352 - val_f1: 0.5345\n",
      "Score = 0.45631364337059344, F1 = 0.42131265553840436, ACC = 0.5273762550298863\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 51s 129us/step - loss: 0.2676 - accuracy: 0.9133 - f1: 0.9137 - val_loss: 2.9092 - val_accuracy: 0.5250 - val_f1: 0.5250\n",
      "Score = 0.4432933871276646, F1 = 0.40625699083829375, ACC = 0.518488494745478\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 51s 130us/step - loss: 0.2604 - accuracy: 0.9159 - f1: 0.9161 - val_loss: 2.9224 - val_accuracy: 0.5243 - val_f1: 0.5239\n",
      "Score = 0.4385193282277403, F1 = 0.39921811876540264, ACC = 0.5183126928936985\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 52s 131us/step - loss: 0.2557 - accuracy: 0.9180 - f1: 0.9183 - val_loss: 2.8724 - val_accuracy: 0.5303 - val_f1: 0.5291\n",
      "Score = 0.45309158748220774, F1 = 0.41865872019645906, ACC = 0.5230007422744853\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 52s 131us/step - loss: 0.2488 - accuracy: 0.9199 - f1: 0.9204 - val_loss: 2.9168 - val_accuracy: 0.5387 - val_f1: 0.5388\n",
      "Score = 0.46553069315755247, F1 = 0.43239961963557233, ACC = 0.532796812126421\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 51s 129us/step - loss: 0.2486 - accuracy: 0.9202 - f1: 0.9207 - val_loss: 2.8491 - val_accuracy: 0.5350 - val_f1: 0.5341\n",
      "Score = 0.4613542502077582, F1 = 0.4291149582342606, ACC = 0.5268097823963745\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 50s 128us/step - loss: 0.2475 - accuracy: 0.9204 - f1: 0.9206 - val_loss: 3.0241 - val_accuracy: 0.5181 - val_f1: 0.5173\n",
      "Score = 0.44492365578192616, F1 = 0.4124809003999398, ACC = 0.510792280345353\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 51s 130us/step - loss: 0.2445 - accuracy: 0.9216 - f1: 0.9220 - val_loss: 2.9731 - val_accuracy: 0.5306 - val_f1: 0.5302\n",
      "Score = 0.45743477895180207, F1 = 0.42464561418573865, ACC = 0.5240067195374458\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 51s 129us/step - loss: 0.2420 - accuracy: 0.9233 - f1: 0.9236 - val_loss: 3.0023 - val_accuracy: 0.5231 - val_f1: 0.5233\n",
      "Score = 0.44539247405904936, F1 = 0.4102462251283812, ACC = 0.5167500097667695\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 51s 128us/step - loss: 0.2433 - accuracy: 0.9223 - f1: 0.9226 - val_loss: 2.8619 - val_accuracy: 0.5334 - val_f1: 0.5330\n",
      "Score = 0.45991877196251585, F1 = 0.42761706018047346, ACC = 0.5255010352775716\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 51s 128us/step - loss: 0.2416 - accuracy: 0.9226 - f1: 0.9230 - val_loss: 3.0427 - val_accuracy: 0.5344 - val_f1: 0.5338\n",
      "Score = 0.4547145971597929, F1 = 0.4185556110236343, ACC = 0.5281282962847209\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 51s 128us/step - loss: 0.2391 - accuracy: 0.9235 - f1: 0.9240 - val_loss: 3.0833 - val_accuracy: 0.5273 - val_f1: 0.5265\n",
      "Score = 0.44916171622341694, F1 = 0.41413536976819243, ACC = 0.520275813571903\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 50s 128us/step - loss: 0.2403 - accuracy: 0.9231 - f1: 0.9234 - val_loss: 3.0820 - val_accuracy: 0.5281 - val_f1: 0.52836 - \n",
      "Score = 0.4454306985242405, F1 = 0.4072053155789003, ACC = 0.5230398093526585\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_8 (GRU)                  (None, 64)                242880    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,335\n",
      "Trainable params: 243,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.46820207083568277, 0.4334908304425234, 0.5386764073914911]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 90s 229us/step - loss: 0.5077 - accuracy: 0.8301 - f1: 0.8175 - val_loss: 1.9216 - val_accuracy: 0.5305 - val_f1: 0.5277\n",
      "Score = 0.45853742314453544, F1 = 0.4352436893683712, ACC = 0.5058307614173536\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 89s 227us/step - loss: 0.2314 - accuracy: 0.9230 - f1: 0.9234 - val_loss: 2.3782 - val_accuracy: 0.5295 - val_f1: 0.5279\n",
      "Score = 0.45541046214289593, F1 = 0.4261749773306985, ACC = 0.5147673555494785\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 89s 226us/step - loss: 0.1625 - accuracy: 0.9459 - f1: 0.9461 - val_loss: 2.6583 - val_accuracy: 0.5268 - val_f1: 0.5265\n",
      "Score = 0.45038832217152613, F1 = 0.4173226854723853, ACC = 0.5175215845606908\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 87s 221us/step - loss: 0.1231 - accuracy: 0.9589 - f1: 0.9589 - val_loss: 2.9608 - val_accuracy: 0.5200 - val_f1: 0.5208\n",
      "Score = 0.44050280827649235, F1 = 0.4042759140648697, ACC = 0.5140543813728171\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 88s 222us/step - loss: 0.0998 - accuracy: 0.9671 - f1: 0.9670 - val_loss: 2.9939 - val_accuracy: 0.5210 - val_f1: 0.5213\n",
      "Score = 0.44706727158026627, F1 = 0.4138475270621193, ACC = 0.5145134195413525\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 89s 225us/step - loss: 0.0835 - accuracy: 0.9722 - f1: 0.9723 - val_loss: 3.2706 - val_accuracy: 0.5206 - val_f1: 0.5211\n",
      "Score = 0.4419642665949184, F1 = 0.4059569033002425, ACC = 0.5150701254053209\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 90s 227us/step - loss: 0.0734 - accuracy: 0.9754 - f1: 0.9753 - val_loss: 3.4300 - val_accuracy: 0.5204 - val_f1: 0.5213\n",
      "Score = 0.4432744735934717, F1 = 0.4074313862907264, ACC = 0.5160468023596515\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 89s 227us/step - loss: 0.0647 - accuracy: 0.9781 - f1: 0.9782 - val_loss: 3.5774 - val_accuracy: 0.5219 - val_f1: 0.5223\n",
      "Score = 0.4403608995643432, F1 = 0.4022264996159469, ACC = 0.5177852873383599\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 89s 225us/step - loss: 0.0584 - accuracy: 0.9805 - f1: 0.9805 - val_loss: 3.5674 - val_accuracy: 0.5159 - val_f1: 0.5142\n",
      "Score = 0.4399910483652811, F1 = 0.4061049519565959, ACC = 0.5087900925889752\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 90s 227us/step - loss: 0.0539 - accuracy: 0.9820 - f1: 0.9821 - val_loss: 3.6102 - val_accuracy: 0.5222 - val_f1: 0.5223\n",
      "Score = 0.44411768687686115, F1 = 0.40771338239771643, ACC = 0.5180294565769427\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_9 (GRU)                  (None, 128)               510336    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 511,239\n",
      "Trainable params: 511,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.47126610569114236, 0.44210964597508046, 0.530462554205571]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 55s 140us/step - loss: 0.6020 - accuracy: 0.7972 - f1: 0.7786 - val_loss: 1.7452 - val_accuracy: 0.5279 - val_f1: 0.5242\n",
      "Score = 0.4544661346700467, F1 = 0.43452122416101613, ACC = 0.49496034691565416\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.2840 - accuracy: 0.9060 - f1: 0.9058 - val_loss: 2.0947 - val_accuracy: 0.5303 - val_f1: 0.5282\n",
      "Score = 0.4544486193425801, F1 = 0.42681271588566655, ACC = 0.5105578778763137\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 55s 139us/step - loss: 0.2049 - accuracy: 0.9321 - f1: 0.9323 - val_loss: 2.3419 - val_accuracy: 0.5312 - val_f1: 0.5295\n",
      "Score = 0.4565013351247256, F1 = 0.42654279537116935, ACC = 0.5173262491698246\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.1594 - accuracy: 0.9463 - f1: 0.9466 - val_loss: 2.6228 - val_accuracy: 0.5298 - val_f1: 0.5301\n",
      "Score = 0.453338727909275, F1 = 0.42016286413541415, ACC = 0.5206957846622651\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 0.1292 - accuracy: 0.9571 - f1: 0.9573 - val_loss: 2.7700 - val_accuracy: 0.5268 - val_f1: 0.5271\n",
      "Score = 0.4481974337850568, F1 = 0.41321086558045206, ACC = 0.5192307692307693\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 0.1078 - accuracy: 0.9642 - f1: 0.9643 - val_loss: 3.0290 - val_accuracy: 0.5251 - val_f1: 0.5252\n",
      "Score = 0.4435957463815877, F1 = 0.4064485063915198, ACC = 0.5190159003008165\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 54s 138us/step - loss: 0.0931 - accuracy: 0.9689 - f1: 0.9689 - val_loss: 3.1198 - val_accuracy: 0.5230 - val_f1: 0.5232\n",
      "Score = 0.4395429310225387, F1 = 0.40120769198022416, ACC = 0.5173750830175411\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.0812 - accuracy: 0.9729 - f1: 0.9731 - val_loss: 3.3083 - val_accuracy: 0.5258 - val_f1: 0.5261\n",
      "Score = 0.44419775061208683, F1 = 0.40643783596477817, ACC = 0.5208618197445013\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 0.0726 - accuracy: 0.9757 - f1: 0.9757 - val_loss: 3.3549 - val_accuracy: 0.5198 - val_f1: 0.5184\n",
      "Score = 0.4407734644640816, F1 = 0.4057093251883585, ACC = 0.5119642926905497\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.0658 - accuracy: 0.9779 - f1: 0.9780 - val_loss: 3.5512 - val_accuracy: 0.5172 - val_f1: 0.5180\n",
      "Score = 0.43964975991889027, F1 = 0.40342122092455057, ACC = 0.5132046724225495\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.0602 - accuracy: 0.9800 - f1: 0.9800 - val_loss: 3.5675 - val_accuracy: 0.5206 - val_f1: 0.5210\n",
      "Score = 0.44695840793126, F1 = 0.412583439863024, ACC = 0.5167500097667695\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.0566 - accuracy: 0.9811 - f1: 0.9812 - val_loss: 3.6823 - val_accuracy: 0.5189 - val_f1: 0.5192\n",
      "Score = 0.4410805852605017, F1 = 0.4045129029762152, ACC = 0.5153240614134469\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 128)               510336    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 511,239\n",
      "Trainable params: 511,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4644596316113856, 0.43160918404947385, 0.5311559948431457]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 90s 227us/step - loss: 0.2458 - accuracy: 0.9168 - f1: 0.9160 - val_loss: 3.0519 - val_accuracy: 0.5140 - val_f1: 0.5136\n",
      "Score = 0.43509217894407404, F1 = 0.4005538489778398, ACC = 0.5052154549361253\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 87s 222us/step - loss: 0.1385 - accuracy: 0.9525 - f1: 0.9527 - val_loss: 3.2173 - val_accuracy: 0.5111 - val_f1: 0.5110\n",
      "Score = 0.4351477816429081, F1 = 0.40118042440336804, ACC = 0.5041118099777318\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 92s 233us/step - loss: 0.1183 - accuracy: 0.9598 - f1: 0.9601 - val_loss: 3.3717 - val_accuracy: 0.5147 - val_f1: 0.5145\n",
      "Score = 0.44038893407011126, F1 = 0.40699225162187486, ACC = 0.5081943196468336\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 93s 235us/step - loss: 0.1089 - accuracy: 0.9632 - f1: 0.9633 - val_loss: 3.4027 - val_accuracy: 0.5212 - val_f1: 0.5213\n",
      "Score = 0.4385272853457592, F1 = 0.4004181881736023, ACC = 0.515900300816502\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 90s 227us/step - loss: 0.1032 - accuracy: 0.9651 - f1: 0.9653 - val_loss: 3.4264 - val_accuracy: 0.5206 - val_f1: 0.5204\n",
      "Score = 0.44872303306379846, F1 = 0.41609752993057425, ACC = 0.5149626909403445\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 90s 228us/step - loss: 0.0975 - accuracy: 0.9669 - f1: 0.9671 - val_loss: 3.5109 - val_accuracy: 0.5210 - val_f1: 0.5210\n",
      "Score = 0.4449707816335795, F1 = 0.4098284953795736, ACC = 0.5163202719068641\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 89s 227us/step - loss: 0.0943 - accuracy: 0.9681 - f1: 0.9682 - val_loss: 3.4971 - val_accuracy: 0.5169 - val_f1: 0.5168\n",
      "Score = 0.4430374616259243, F1 = 0.40942516032013915, ACC = 0.5112806188225183\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 90s 228us/step - loss: 0.0920 - accuracy: 0.9690 - f1: 0.9691 - val_loss: 3.7836 - val_accuracy: 0.5160 - val_f1: 0.5163\n",
      "Score = 0.43615792165044587, F1 = 0.3989503387749184, ACC = 0.5117005899128804\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 90s 228us/step - loss: 0.0905 - accuracy: 0.9697 - f1: 0.9697 - val_loss: 3.5705 - val_accuracy: 0.5186 - val_f1: 0.5180\n",
      "Score = 0.44310038049072364, F1 = 0.408869651785281, ACC = 0.5125991327108645\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 90s 228us/step - loss: 0.0897 - accuracy: 0.9700 - f1: 0.9701 - val_loss: 3.8290 - val_accuracy: 0.5150 - val_f1: 0.5144\n",
      "Score = 0.4319089571386071, F1 = 0.3935225953995848, ACC = 0.5098449036996523\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 89s 226us/step - loss: 0.0874 - accuracy: 0.9706 - f1: 0.9707 - val_loss: 3.6912 - val_accuracy: 0.5285 - val_f1: 0.5282\n",
      "Score = 0.4524564383904838, F1 = 0.4172826021170399, ACC = 0.5238699847638395\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 88s 224us/step - loss: 0.0863 - accuracy: 0.9710 - f1: 0.9712 - val_loss: 3.8514 - val_accuracy: 0.5135 - val_f1: 0.5130\n",
      "Score = 0.43878966520439205, F1 = 0.4044561577141924, ACC = 0.5084970895026761\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 88s 223us/step - loss: 0.0865 - accuracy: 0.9709 - f1: 0.9710 - val_loss: 3.7991 - val_accuracy: 0.5228 - val_f1: 0.5233\n",
      "Score = 0.4522439055146837, F1 = 0.41962559450235, ACC = 0.5184689612063914\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 91s 230us/step - loss: 0.0853 - accuracy: 0.9714 - f1: 0.9716 - val_loss: 3.8172 - val_accuracy: 0.5204 - val_f1: 0.5204\n",
      "Score = 0.4448357080508203, F1 = 0.40968461899842773, ACC = 0.5162030706723444\n",
      "Epoch 15/30\n",
      "394390/394390 [==============================] - 91s 232us/step - loss: 0.0842 - accuracy: 0.9715 - f1: 0.9717 - val_loss: 3.9324 - val_accuracy: 0.5102 - val_f1: 0.5105\n",
      "Score = 0.4300602067968676, F1 = 0.3926153084275512, ACC = 0.5060846974254796\n",
      "Epoch 16/30\n",
      "394390/394390 [==============================] - 93s 235us/step - loss: 0.0828 - accuracy: 0.9723 - f1: 0.9724 - val_loss: 4.0014 - val_accuracy: 0.5028 - val_f1: 0.5030\n",
      "Score = 0.4243427182116295, F1 = 0.38769442769722195, ACC = 0.49874985349845685\n",
      "Epoch 17/30\n",
      "394390/394390 [==============================] - 91s 231us/step - loss: 0.0817 - accuracy: 0.9723 - f1: 0.9724 - val_loss: 4.0311 - val_accuracy: 0.5092 - val_f1: 0.5099\n",
      "Score = 0.4231013167797504, F1 = 0.3823299258839958, ACC = 0.5058795952650701\n",
      "Epoch 18/30\n",
      "394390/394390 [==============================] - 91s 231us/step - loss: 0.0841 - accuracy: 0.9719 - f1: 0.9720 - val_loss: 3.9879 - val_accuracy: 0.5108 - val_f1: 0.5109\n",
      "Score = 0.4322742221335324, F1 = 0.3954195170931311, ACC = 0.5071004414579834\n",
      "Epoch 19/30\n",
      "394390/394390 [==============================] - 91s 231us/step - loss: 0.0821 - accuracy: 0.9725 - f1: 0.9725 - val_loss: 3.7780 - val_accuracy: 0.5169 - val_f1: 0.5167\n",
      "Score = 0.4412801190819333, F1 = 0.40607106523911946, ACC = 0.5127651677931008\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_11 (GRU)                 (None, 128)               510336    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 511,239\n",
      "Trainable params: 511,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4553429608939489, 0.4193347208950214, 0.5284505996796499]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.2572 - accuracy: 0.9135 - f1: 0.9120 - val_loss: 2.7869 - val_accuracy: 0.5233 - val_f1: 0.5237\n",
      "Score = 0.4420562116685304, F1 = 0.4072438438785895, ACC = 0.5127358674844709\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 52s 133us/step - loss: 0.1232 - accuracy: 0.9582 - f1: 0.9585 - val_loss: 3.0954 - val_accuracy: 0.5128 - val_f1: 0.5136\n",
      "Score = 0.43082766184981747, F1 = 0.39411193011598117, ACC = 0.5053717232488182\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 53s 134us/step - loss: 0.1012 - accuracy: 0.9662 - f1: 0.9663 - val_loss: 3.2693 - val_accuracy: 0.5165 - val_f1: 0.5161\n",
      "Score = 0.4327780463322912, F1 = 0.3947139124843605, ACC = 0.510059772629605\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 53s 134us/step - loss: 0.0915 - accuracy: 0.9693 - f1: 0.9694 - val_loss: 3.6044 - val_accuracy: 0.5231 - val_f1: 0.5232\n",
      "Score = 0.43520095611384796, F1 = 0.3939959366533838, ACC = 0.5188596319881236\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 52s 132us/step - loss: 0.0839 - accuracy: 0.9719 - f1: 0.9721 - val_loss: 3.4501 - val_accuracy: 0.5172 - val_f1: 0.5173\n",
      "Score = 0.437422687363381, F1 = 0.40050612440243194, ACC = 0.5123744970113685\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 52s 132us/step - loss: 0.0794 - accuracy: 0.9733 - f1: 0.9734 - val_loss: 3.6697 - val_accuracy: 0.5140 - val_f1: 0.5145\n",
      "Score = 0.42966848581773076, F1 = 0.3901593663597736, ACC = 0.5098839707778255\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 52s 131us/step - loss: 0.0772 - accuracy: 0.9742 - f1: 0.9742 - val_loss: 3.5668 - val_accuracy: 0.5189 - val_f1: 0.5194\n",
      "Score = 0.4387391510731762, F1 = 0.4015233274200212, ACC = 0.5142985506113997\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 50s 128us/step - loss: 0.0731 - accuracy: 0.9755 - f1: 0.9756 - val_loss: 3.7246 - val_accuracy: 0.5091 - val_f1: 0.5094\n",
      "Score = 0.43146733482907096, F1 = 0.395364916808682, ACC = 0.5047661835371332\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 50s 128us/step - loss: 0.0730 - accuracy: 0.9754 - f1: 0.9755 - val_loss: 3.6774 - val_accuracy: 0.5185 - val_f1: 0.5188\n",
      "Score = 0.4386839612610866, F1 = 0.40126777662261226, ACC = 0.5146501543149588\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_12 (GRU)                 (None, 128)               510336    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 511,239\n",
      "Trainable params: 511,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4469866434175415, 0.4094025484305711, 0.5232937453607844]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 84s 212us/step - loss: 0.7862 - accuracy: 0.7293 - f1: 0.7104 - val_loss: 1.7719 - val_accuracy: 0.5398 - val_f1: 0.5340\n",
      "Score = 0.46474422954232925, F1 = 0.443559911323272, ACC = 0.5077548150173848\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 82s 207us/step - loss: 0.4391 - accuracy: 0.8518 - f1: 0.8509 - val_loss: 2.0113 - val_accuracy: 0.5374 - val_f1: 0.5355\n",
      "Score = 0.4636507484632505, F1 = 0.4368431531688253, ACC = 0.5180782904246591\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 82s 209us/step - loss: 0.3438 - accuracy: 0.8843 - f1: 0.8841 - val_loss: 2.2839 - val_accuracy: 0.5340 - val_f1: 0.5337\n",
      "Score = 0.45809579546532925, F1 = 0.427065734529643, ACC = 0.5210962222135407\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 83s 209us/step - loss: 0.2837 - accuracy: 0.9044 - f1: 0.9048 - val_loss: 2.5203 - val_accuracy: 0.5365 - val_f1: 0.5366\n",
      "Score = 0.4570466875130371, F1 = 0.4226184132043932, ACC = 0.5269465171699809\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 82s 208us/step - loss: 0.2411 - accuracy: 0.9188 - f1: 0.9191 - val_loss: 2.7192 - val_accuracy: 0.5289 - val_f1: 0.5289\n",
      "Score = 0.44720328323948655, F1 = 0.4107505276143681, ACC = 0.5212134234480603\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 82s 208us/step - loss: 0.2096 - accuracy: 0.9293 - f1: 0.9296 - val_loss: 2.8986 - val_accuracy: 0.5316 - val_f1: 0.5317\n",
      "Score = 0.4497015341345474, F1 = 0.41242517746319435, ACC = 0.5253838340430519\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 83s 209us/step - loss: 0.1860 - accuracy: 0.9379 - f1: 0.9381 - val_loss: 3.0716 - val_accuracy: 0.5237 - val_f1: 0.5232\n",
      "Score = 0.44149875342010575, F1 = 0.40390554695917874, ACC = 0.5178243544165332\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 83s 211us/step - loss: 0.1662 - accuracy: 0.9443 - f1: 0.9446 - val_loss: 3.3313 - val_accuracy: 0.5172 - val_f1: 0.5171\n",
      "Score = 0.4315804849750985, F1 = 0.3915555154205685, ACC = 0.5128433019494472\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 85s 215us/step - loss: 0.1514 - accuracy: 0.9492 - f1: 0.9496 - val_loss: 3.3394 - val_accuracy: 0.5208 - val_f1: 0.5209\n",
      "Score = 0.4370205441570123, F1 = 0.3975631979253075, ACC = 0.5171309137789585\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 86s 217us/step - loss: 0.1399 - accuracy: 0.9536 - f1: 0.9537 - val_loss: 3.5470 - val_accuracy: 0.5144 - val_f1: 0.5147\n",
      "Score = 0.4288664984728034, F1 = 0.3884813204793908, ACC = 0.5108606477321561\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 87s 221us/step - loss: 0.1292 - accuracy: 0.9571 - f1: 0.9571 - val_loss: 3.5585 - val_accuracy: 0.5180 - val_f1: 0.5182\n",
      "Score = 0.43418910266244465, F1 = 0.39459270593455714, ACC = 0.5145817869281556\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 88s 222us/step - loss: 0.1219 - accuracy: 0.9598 - f1: 0.9600 - val_loss: 3.6412 - val_accuracy: 0.5176 - val_f1: 0.5177\n",
      "Score = 0.4370649438819095, F1 = 0.39897640573232035, ACC = 0.5143962183068328\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_13 (GRU)                 (None, 128)               510336    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 511,239\n",
      "Trainable params: 511,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.48311247090227216, 0.45516789908830624, 0.5398484197366878]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 57s 145us/step - loss: 0.8992 - accuracy: 0.6897 - f1: 0.6626 - val_loss: 1.6683 - val_accuracy: 0.5394 - val_f1: 0.5299\n",
      "Score = 0.45895832607369247, F1 = 0.440504412685273, ACC = 0.49642536234715007\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 56s 142us/step - loss: 0.5081 - accuracy: 0.8286 - f1: 0.8268 - val_loss: 1.9143 - val_accuracy: 0.5374 - val_f1: 0.5343\n",
      "Score = 0.46466732975718406, F1 = 0.4405828889576401, ACC = 0.5135660428956519\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 55s 140us/step - loss: 0.4063 - accuracy: 0.8631 - f1: 0.8628 - val_loss: 2.1134 - val_accuracy: 0.5358 - val_f1: 0.5339\n",
      "Score = 0.46324106243185503, F1 = 0.4361017980225174, ACC = 0.5183419932023284\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 55s 140us/step - loss: 0.3433 - accuracy: 0.8845 - f1: 0.8847 - val_loss: 2.2996 - val_accuracy: 0.5306 - val_f1: 0.5294\n",
      "Score = 0.4542796050644382, F1 = 0.42395797611744523, ACC = 0.5158417001992421\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 55s 141us/step - loss: 0.2953 - accuracy: 0.9010 - f1: 0.9012 - val_loss: 2.4851 - val_accuracy: 0.5253 - val_f1: 0.5250\n",
      "Score = 0.4472165934939852, F1 = 0.4142628155273291, ACC = 0.5141227487596203\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 56s 143us/step - loss: 0.2608 - accuracy: 0.9125 - f1: 0.9127 - val_loss: 2.6970 - val_accuracy: 0.5261 - val_f1: 0.5253\n",
      "Score = 0.44689100879235105, F1 = 0.4125742436035128, ACC = 0.5165644411454468\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 55s 139us/step - loss: 0.2325 - accuracy: 0.9220 - f1: 0.9222 - val_loss: 2.8404 - val_accuracy: 0.5250 - val_f1: 0.5250\n",
      "Score = 0.4424598154416769, F1 = 0.40538807287121464, ACC = 0.5177266867211001\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 55s 141us/step - loss: 0.2079 - accuracy: 0.9301 - f1: 0.9304 - val_loss: 3.0116 - val_accuracy: 0.5241 - val_f1: 0.5239\n",
      "Score = 0.44097492880128647, F1 = 0.40308523518244205, ACC = 0.5179024885728797\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 56s 141us/step - loss: 0.1899 - accuracy: 0.9362 - f1: 0.9366 - val_loss: 3.0815 - val_accuracy: 0.5232 - val_f1: 0.5234\n",
      "Score = 0.44320661624239294, F1 = 0.40636319647746333, ACC = 0.518009923037856\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 55s 140us/step - loss: 0.1745 - accuracy: 0.9418 - f1: 0.9422 - val_loss: 3.3469 - val_accuracy: 0.5189 - val_f1: 0.5191\n",
      "Score = 0.4336215342755793, F1 = 0.39351949551294213, ACC = 0.515040825096691\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_14 (GRU)                 (None, 128)               510336    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 511,239\n",
      "Trainable params: 511,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4782944503393387, 0.4491842587276174, 0.5373969605813181]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 88s 222us/step - loss: 0.4146 - accuracy: 0.8590 - f1: 0.8575 - val_loss: 2.5504 - val_accuracy: 0.5281 - val_f1: 0.5278\n",
      "Score = 0.44496340718555927, F1 = 0.4095144273395355, ACC = 0.5169355783880923\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 87s 221us/step - loss: 0.2616 - accuracy: 0.9121 - f1: 0.9123 - val_loss: 2.9789 - val_accuracy: 0.5255 - val_f1: 0.5266\n",
      "Score = 0.434766372069662, F1 = 0.3930875368362977, ACC = 0.5193870375434622\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 87s 219us/step - loss: 0.2330 - accuracy: 0.9215 - f1: 0.9218 - val_loss: 3.0503 - val_accuracy: 0.5154 - val_f1: 0.5160\n",
      "Score = 0.4295950986947408, F1 = 0.3910263645220364, ACC = 0.5079013165605344\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 88s 222us/step - loss: 0.2176 - accuracy: 0.9272 - f1: 0.9276 - val_loss: 3.2514 - val_accuracy: 0.5252 - val_f1: 0.5249\n",
      "Score = 0.4348984926352696, F1 = 0.3936599505880175, ACC = 0.5186252295190843\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 89s 225us/step - loss: 0.2070 - accuracy: 0.9311 - f1: 0.9314 - val_loss: 3.2702 - val_accuracy: 0.5236 - val_f1: 0.5229\n",
      "Score = 0.4380347525940633, F1 = 0.3988123644474567, ACC = 0.5176680861038403\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 89s 226us/step - loss: 0.2012 - accuracy: 0.9333 - f1: 0.9335 - val_loss: 3.3828 - val_accuracy: 0.5157 - val_f1: 0.5163\n",
      "Score = 0.43075924943741817, F1 = 0.3913977213893181, ACC = 0.5106750791108333\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 89s 226us/step - loss: 0.1970 - accuracy: 0.9348 - f1: 0.9352 - val_loss: 3.6156 - val_accuracy: 0.5160 - val_f1: 0.5166\n",
      "Score = 0.42428472243978765, F1 = 0.38120509343103076, ACC = 0.511749423760597\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 86s 217us/step - loss: 0.1942 - accuracy: 0.9356 - f1: 0.9359 - val_loss: 3.6493 - val_accuracy: 0.5081 - val_f1: 0.5088\n",
      "Score = 0.41362776140166335, F1 = 0.3691668221729795, ACC = 0.503896941047779\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 89s 225us/step - loss: 0.1899 - accuracy: 0.9372 - f1: 0.9376 - val_loss: 3.3108 - val_accuracy: 0.5214 - val_f1: 0.5213\n",
      "Score = 0.437172292572937, F1 = 0.3981456649822809, ACC = 0.5164081728327539\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_15 (GRU)                 (None, 128)               510336    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 511,239\n",
      "Trainable params: 511,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.450356077829505, 0.4120840317808837, 0.5280599288979178]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394390 samples, validate on 102388 samples\n",
      "Epoch 1/30\n",
      "394390/394390 [==============================] - 55s 140us/step - loss: 0.4362 - accuracy: 0.8515 - f1: 0.8489 - val_loss: 2.5168 - val_accuracy: 0.5314 - val_f1: 0.5304\n",
      "Score = 0.4523560262631561, F1 = 0.4193311310536044, ACC = 0.5194065710825487\n",
      "Epoch 2/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.2484 - accuracy: 0.9163 - f1: 0.9166 - val_loss: 2.9835 - val_accuracy: 0.5207 - val_f1: 0.5205\n",
      "Score = 0.432566302151689, F1 = 0.3923678460556993, ACC = 0.5141813493768801\n",
      "Epoch 3/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 0.2098 - accuracy: 0.9298 - f1: 0.9302 - val_loss: 3.1914 - val_accuracy: 0.5244 - val_f1: 0.5249\n",
      "Score = 0.44330275899576355, F1 = 0.40599196979208496, ACC = 0.5190549673789897\n",
      "Epoch 4/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.1920 - accuracy: 0.9359 - f1: 0.9362 - val_loss: 3.2346 - val_accuracy: 0.5244 - val_f1: 0.5246\n",
      "Score = 0.44288349818322836, F1 = 0.40502466199665976, ACC = 0.5197484080165644\n",
      "Epoch 5/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.1811 - accuracy: 0.9396 - f1: 0.9399 - val_loss: 3.3500 - val_accuracy: 0.5217 - val_f1: 0.5214\n",
      "Score = 0.43768412451251204, F1 = 0.398678689325578, ACC = 0.5168769777708325\n",
      "Epoch 6/30\n",
      "394390/394390 [==============================] - 54s 138us/step - loss: 0.1720 - accuracy: 0.9432 - f1: 0.9435 - val_loss: 3.3121 - val_accuracy: 0.5316 - val_f1: 0.5318\n",
      "Score = 0.4470264529374395, F1 = 0.4073549673113301, ACC = 0.5275715904207524\n",
      "Epoch 7/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 0.1703 - accuracy: 0.9439 - f1: 0.9441 - val_loss: 3.5024 - val_accuracy: 0.5136 - val_f1: 0.5136\n",
      "Score = 0.4384884970559666, F1 = 0.40382385407464244, ACC = 0.5088682267453217\n",
      "Epoch 8/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 0.1652 - accuracy: 0.9453 - f1: 0.9456 - val_loss: 3.5933 - val_accuracy: 0.5144 - val_f1: 0.5153\n",
      "Score = 0.4297430973177403, F1 = 0.39005425437811897, ACC = 0.5103234754072743\n",
      "Epoch 9/30\n",
      "394390/394390 [==============================] - 55s 139us/step - loss: 0.1605 - accuracy: 0.9471 - f1: 0.9474 - val_loss: 3.3375 - val_accuracy: 0.5268 - val_f1: 0.5271\n",
      "Score = 0.44307931545911294, F1 = 0.40397960802349814, ACC = 0.5224635699496035\n",
      "Epoch 10/30\n",
      "394390/394390 [==============================] - 53s 135us/step - loss: 0.1598 - accuracy: 0.9473 - f1: 0.9476 - val_loss: 3.6533 - val_accuracy: 0.5213 - val_f1: 0.5217\n",
      "Score = 0.440465860743234, F1 = 0.4021330121734509, ACC = 0.5182931593546118\n",
      "Epoch 11/30\n",
      "394390/394390 [==============================] - 55s 139us/step - loss: 0.1592 - accuracy: 0.9475 - f1: 0.9477 - val_loss: 3.5556 - val_accuracy: 0.5156 - val_f1: 0.5157\n",
      "Score = 0.43759811112633407, F1 = 0.40094593935627787, ACC = 0.5120131265382662\n",
      "Epoch 12/30\n",
      "394390/394390 [==============================] - 54s 136us/step - loss: 0.1567 - accuracy: 0.9485 - f1: 0.9488 - val_loss: 3.6530 - val_accuracy: 0.5048 - val_f1: 0.5048\n",
      "Score = 0.433304857094453, F1 = 0.3999402872565356, ACC = 0.5010450443411337\n",
      "Epoch 13/30\n",
      "394390/394390 [==============================] - 53s 135us/step - loss: 0.1553 - accuracy: 0.9490 - f1: 0.9493 - val_loss: 3.7407 - val_accuracy: 0.5110 - val_f1: 0.5113\n",
      "Score = 0.43377213118515234, F1 = 0.3972944148624194, ACC = 0.5078329491737313\n",
      "Epoch 14/30\n",
      "394390/394390 [==============================] - 54s 137us/step - loss: 0.1555 - accuracy: 0.9491 - f1: 0.9493 - val_loss: 3.8015 - val_accuracy: 0.5016 - val_f1: 0.5011\n",
      "Score = 0.4252856167400608, F1 = 0.3894240423286157, ACC = 0.49809547993905534\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_16 (GRU)                 (None, 128)               510336    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 511,239\n",
      "Trainable params: 511,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.45794685084276987, 0.42174911128358555, 0.5314392311599015]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 64, 0.3, 0.0001, 128, 0.47080836471166954, 0.4369238239511863, 0.5396042504981052], [1, 64, 0.3, 0.0001, 256, 0.4715146855705208, 0.43688605104426415, 0.5418213071844357], [2, 64, 0.3, 0.001, 128, 0.4741528055445948, 0.4408620275303363, 0.5417431730280893], [3, 64, 0.3, 0.001, 256, 0.45813433994012603, 0.4222021237007955, 0.5310876274563425], [4, 64, 0.5, 0.0001, 128, 0.4818261848320189, 0.44916395596412517, 0.5481404070789546], [5, 64, 0.5, 0.0001, 256, 0.4880220860492912, 0.45631419240499305, 0.5523987185998359], [6, 64, 0.5, 0.001, 128, 0.4698464526205203, 0.4348483379714774, 0.5409032308473649], [7, 64, 0.5, 0.001, 256, 0.46820207083568277, 0.4334908304425234, 0.5386764073914911], [8, 128, 0.3, 0.0001, 128, 0.47126610569114236, 0.44210964597508046, 0.530462554205571], [9, 128, 0.3, 0.0001, 256, 0.4644596316113856, 0.43160918404947385, 0.5311559948431457], [10, 128, 0.3, 0.001, 128, 0.4553429608939489, 0.4193347208950214, 0.5284505996796499], [11, 128, 0.3, 0.001, 256, 0.4469866434175415, 0.4094025484305711, 0.5232937453607844], [12, 128, 0.5, 0.0001, 128, 0.48311247090227216, 0.45516789908830624, 0.5398484197366878], [13, 128, 0.5, 0.0001, 256, 0.4782944503393387, 0.4491842587276174, 0.5373969605813181], [14, 128, 0.5, 0.001, 128, 0.450356077829505, 0.4120840317808837, 0.5280599288979178], [15, 128, 0.5, 0.001, 256, 0.45794685084276987, 0.42174911128358555, 0.5314392311599015]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>units</th>\n",
       "      <th>drop</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch</th>\n",
       "      <th>score</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.470808</td>\n",
       "      <td>0.436924</td>\n",
       "      <td>0.539604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.471515</td>\n",
       "      <td>0.436886</td>\n",
       "      <td>0.541821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.474153</td>\n",
       "      <td>0.440862</td>\n",
       "      <td>0.541743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.458134</td>\n",
       "      <td>0.422202</td>\n",
       "      <td>0.531088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.481826</td>\n",
       "      <td>0.449164</td>\n",
       "      <td>0.548140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.488022</td>\n",
       "      <td>0.456314</td>\n",
       "      <td>0.552399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.469846</td>\n",
       "      <td>0.434848</td>\n",
       "      <td>0.540903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.468202</td>\n",
       "      <td>0.433491</td>\n",
       "      <td>0.538676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.471266</td>\n",
       "      <td>0.442110</td>\n",
       "      <td>0.530463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.464460</td>\n",
       "      <td>0.431609</td>\n",
       "      <td>0.531156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.455343</td>\n",
       "      <td>0.419335</td>\n",
       "      <td>0.528451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.446987</td>\n",
       "      <td>0.409403</td>\n",
       "      <td>0.523294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.483112</td>\n",
       "      <td>0.455168</td>\n",
       "      <td>0.539848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.478294</td>\n",
       "      <td>0.449184</td>\n",
       "      <td>0.537397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.450356</td>\n",
       "      <td>0.412084</td>\n",
       "      <td>0.528060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.457947</td>\n",
       "      <td>0.421749</td>\n",
       "      <td>0.531439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  units  drop      lr  batch     score        f1       acc\n",
       "0    0     64   0.3  0.0001    128  0.470808  0.436924  0.539604\n",
       "1    1     64   0.3  0.0001    256  0.471515  0.436886  0.541821\n",
       "2    2     64   0.3  0.0010    128  0.474153  0.440862  0.541743\n",
       "3    3     64   0.3  0.0010    256  0.458134  0.422202  0.531088\n",
       "4    4     64   0.5  0.0001    128  0.481826  0.449164  0.548140\n",
       "5    5     64   0.5  0.0001    256  0.488022  0.456314  0.552399\n",
       "6    6     64   0.5  0.0010    128  0.469846  0.434848  0.540903\n",
       "7    7     64   0.5  0.0010    256  0.468202  0.433491  0.538676\n",
       "8    8    128   0.3  0.0001    128  0.471266  0.442110  0.530463\n",
       "9    9    128   0.3  0.0001    256  0.464460  0.431609  0.531156\n",
       "10  10    128   0.3  0.0010    128  0.455343  0.419335  0.528451\n",
       "11  11    128   0.3  0.0010    256  0.446987  0.409403  0.523294\n",
       "12  12    128   0.5  0.0001    128  0.483112  0.455168  0.539848\n",
       "13  13    128   0.5  0.0001    256  0.478294  0.449184  0.537397\n",
       "14  14    128   0.5  0.0010    128  0.450356  0.412084  0.528060\n",
       "15  15    128   0.5  0.0010    256  0.457947  0.421749  0.531439"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 64)                242880    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,335\n",
      "Trainable params: 243,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:23<00:00,  5.94s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:36<00:00,  6.89s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:00<00:00,  4.34s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:12<00:00,  5.20s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:14<00:00,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243006, 10, 1200)\n",
      "(243006, 7)\n",
      "11664288000 13608336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['0.67*F1+0.33*ACC', 'F1 score', 'ACC score']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.534098443722562, 0.4730863866345471, 0.65797140811338]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.848691</td>\n",
       "      <td>0.686459</td>\n",
       "      <td>0.759003</td>\n",
       "      <td>0.782713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.423329</td>\n",
       "      <td>0.455464</td>\n",
       "      <td>0.438809</td>\n",
       "      <td>0.963939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.083248</td>\n",
       "      <td>0.147731</td>\n",
       "      <td>0.106488</td>\n",
       "      <td>0.966507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.135868</td>\n",
       "      <td>0.481778</td>\n",
       "      <td>0.211961</td>\n",
       "      <td>0.959548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.748717</td>\n",
       "      <td>0.691858</td>\n",
       "      <td>0.719165</td>\n",
       "      <td>0.867304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.338992</td>\n",
       "      <td>0.572540</td>\n",
       "      <td>0.425846</td>\n",
       "      <td>0.849753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.634345</td>\n",
       "      <td>0.667147</td>\n",
       "      <td>0.650332</td>\n",
       "      <td>0.926179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all</td>\n",
       "      <td>0.459027</td>\n",
       "      <td>0.528997</td>\n",
       "      <td>0.473086</td>\n",
       "      <td>0.902278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class    recall  precision        f1  accuracy\n",
       "0     0  0.848691   0.686459  0.759003  0.782713\n",
       "1     1  0.423329   0.455464  0.438809  0.963939\n",
       "2     2  0.083248   0.147731  0.106488  0.966507\n",
       "3     3  0.135868   0.481778  0.211961  0.959548\n",
       "4     4  0.748717   0.691858  0.719165  0.867304\n",
       "5     5  0.338992   0.572540  0.425846  0.849753\n",
       "6     6  0.634345   0.667147  0.650332  0.926179\n",
       "7   all  0.459027   0.528997  0.473086  0.902278"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
